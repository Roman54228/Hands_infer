{
 "runs":[
  {
   "tool":{
    "driver":{
     "name":"torch.onnx.dynamo_export",
     "contents":[
      "localizedData",
      "nonLocalizedData"
     ],
     "language":"en-US",
     "rules":[
      {
       "id":"FXE0014",
       "fullDescription":{
        "text":"Find the OnnxFunction that matches the input dtypes by comparing them with their opschemas. A warning will be issued if the matched OnnxFunction is not an exact match.",
        "markdown":"When an ATen/Custom operator is registered and needs to be dispatched to an OnnxFunction, the input/attribute\ndtypes of the ATen/Custom operator are compared with the input/attribute dtypes of the OnnxFunction opschemas\nto find a match. However, if a perfect/exact match is not found, the dispatcher will attempt to find\nthe nearest match with the highest number of input/attribute dtypes matching the OnnxFunction opschemas, while\nissuing a warning.\n\nThere are two types of level that can be triggered in this rule:\n\n1. NOTE: A perfect match is found, and no warning is issued.\n2. WARNING: The matched OnnxFunction is not a perfect/exact match.\n\nHere are some suggestions based on the WARNING situation:\n\n1. If there are NO errors or mismatches in the results, it is safe to disregard this warning,\n  as the definition of OnnxFunction schema is usually more stringent.\n2. If there are errors or mismatches in the results, it is recommended to:\n  (a) Enable op_level_debugging to determine if the OnnxFunction might be incorrect.\n  (b) Report the issue to the PyTorch-ONNX team.\n  (c) Create/register a custom symbolic function to replace the default one.\n"
       },
       "name":"find-opschema-matched-symbolic-function",
       "shortDescription":{
        "text":"Find the OnnxFunction that matches the input/attribute dtypes by comparing them with their opschemas."
       }
      },
      {
       "id":"FXE0010",
       "fullDescription":{
        "text":"FX graph transformation during ONNX export before converting from FX IR to ONNX IR.",
        "markdown":"This diagnostic tracks the FX passes executed during the ONNX export process prior\nto converting from FX IR (Intermediate Representation) to ONNX IR.\n\nUnder the scope of ONNX export, an FX pass refers to a specific transformation applied to the FX GraphModule.\nThe primary aim of these passes is to streamline the graph into a format that aligns more with the ONNX IR.\nMoreover, these passes work to substitute unsupported FX IR features with those recognized and endorsed by\nONNX IR. Common transformations include, but aren't limited to, decomposition, functionalization and\ntype promotion.\n\nFor those who are interested in a comprehensive log detailing the modifications made during these passes,\nthere are a couple of options:\n\n- Set DiagnosticOptions.verbosity_level to logging.DEBUG.\n- Activate the environment variable TORCH_LOGS='onnx_diagnostics'.\n\nHowever, it's noteworthy that by default, such detailed logging is turned off. The primary reason being\nits considerable impact on performance.\n\nFor an in-depth understanding of each specific pass, please refer to the directory: torch/onnx/_internal/fx/passes.\n"
       },
       "name":"fx-pass",
       "shortDescription":{
        "text":"FX graph transformation during ONNX export before converting from FX IR to ONNX IR."
       }
      },
      {
       "id":"FXE0016",
       "fullDescription":{
        "text":"This rule involves finding the list of OnnxFunction for the PyTorch operator overload in the ONNX registry. If the operator overload is not supported but its default overload is, a warning will be issued. If both the operator overload and its default overload are not supported, an error will be issued.",
        "markdown":"The operator overload name serves the purpose of verifying whether a PyTorch operator is registered in the ONNX registry.\nIf it's not found, the dispatcher takes a fallback approach and tries to locate the default overload of the PyTorch\noperator in the registry. If even the default overload is absent, it signifies that the operator is officially unsupported.\n\nThere are three types of level that can be triggered in this rule:\n\n1. NOTE: The op overload is supported.\n2. WARNING: The op overload is not supported, but it's default overload is supported.\n3. ERROR: The op overload is not supported, and it's default overload is also not supported.\n\nHere are some suggestions based on the WARNING situation:\n\n1. If there are NO errors or mismatches in the results, it is safe to disregard this warning.\n2. If there are errors or mismatches in the results, it is recommended to:\n  (a) Enable op_level_debugging to determine if the OnnxFunction might be incorrect.\n  (b) Report the unsupported overload to the PyTorch-ONNX team.\n  (c) Create/register a custom symbolic function to replace the default one.\n\nHere are some suggestions based on the ERROR situation:\n\n1. Report the unsupported operator to the PyTorch-ONNX team.\n2. Create/register a custom symbolic function to replace the default one.\n"
       },
       "name":"find-operator-overloads-in-onnx-registry",
       "shortDescription":{
        "text":"Find the list of OnnxFunction of the PyTorch operator in onnx registry."
       }
      },
      {
       "id":"FXE0008",
       "fullDescription":{
        "text":"Transforms an FX node to an ONNX node.",
        "markdown":"This diagnostic tracks the transformation process from an FX Node to ONNX [Operators](https://onnx.ai/onnx/operators/).\n\nThe process of converting FX Node to ONNX Node involves dealing with six distinct node types:\n  1. `placeholder`: Represents a module input, maps to an ONNX graph input.\n  2. `call_module`: Symbolizes a call to a submodule, maps to an ONNX\n  3. `call_method`: Symbolizes a method call. Not yet implemented.\n  4. `call_function`: Symbolizes a function call. [Core ATen](https://pytorch.org/docs/stable/ir.html#core-aten-ir) is expected\n    as the function call target. The mapping from ATen to ONNX is implemented by [ONNXScript torchlib](https://github.com/microsoft/onnxscript/tree/main/onnxscript/function_libs/torch_lib/ops).\n    This [guide](https://pytorch.org/docs/stable/onnx.html#onnx-script-functions) shows how to write and register a custom symbolic function for call_function FX node.\n  5. `get_attr`: Indicates an attribute access within the current module. Maps to an ONNX graph initializer.\n  6. `output`: Represents the module's output. Maps to an ONNX graph output.\n\nFor a granular understanding of how each node type is transformed, refer to the implementation details in `FxOnnxInterpreter`.\n"
       },
       "name":"fx-node-to-onnx",
       "shortDescription":{
        "text":"Transforms an FX node to an ONNX node."
       }
      },
      {
       "id":"FXE0007",
       "fullDescription":{
        "text":"Transforms graph from FX IR to ONNX IR.",
        "markdown":"This diagnostic tracks the transformation process from an FX Graph (in FX IR) to an ONNX Graph (in ONNX IR).\n\n## Key Representations:\n\n- **FX Graph**: The graph in FX IR produced by dynamo or symbolic tracing.\n- **ONNX Graph**: The graph in ONNX IR and [operators](https://onnx.ai/onnx/operators/).\n\n## Additional Notes:\n\n- Prior to this transformation step, the FX graph undergoes preprocessing through multiple FX passes.\n  To gain insight into these transformations, refer to diagnostic `FXE0010`.\n- To enable a detailed view of the graph transformation in progress within this diagnostic, switch to the DEBUG mode.\n\n  - Set DiagnosticOptions.verbosity_level to logging.DEBUG.\n  - Activate the environment variable TORCH_LOGS='onnx_diagnostics'.\n\n- For specific information related to node-level FX to ONNX transformations, explore the diagnostic `FXE0008`.\n"
       },
       "name":"fx-graph-to-onnx",
       "shortDescription":{
        "text":"Transforms graph from FX IR to ONNX IR."
       }
      },
      {
       "id":"FXE0015",
       "fullDescription":{
        "text":"Determine if type promotion is required for the FX node. Insert cast nodes if needed.",
        "markdown":"This diagnostic monitors the node-level type promotion insertion process. In PyTorch, there is an automatic process called implicit type promotion,\nwhere the input types of an operator are promoted to a common type. The determination of the common type is based on the type promotion rule specific to each operator.\nTo learn more about PyTorch's type promotion rules, refer to the [elementwise_dtypes doc](https://github.com/pytorch/pytorch/blob/f044613f78df713fb57f70c608483c9f10ad332e/torch/_prims_common/__init__.py#L1252-L1335)\nand [torch._refs ops](https://github.com/pytorch/pytorch/blob/a475ea4542dfe961c9d097e33ab5041f61c8c17f/torch/_refs/__init__.py#L484).\n\nHowever, implicit type promotion is not supported in ONNX. Therefore, to replicate the PyTorch behavior, we need to explicitly insert cast nodes.\nThis diagnostic tracks the process of node-level type promotion insertion.\n\nThe type promotion rules used by this process can be found in `torch/onnx/_internal/fx/passes/type_promotion.py.`\nTo update or add new type promotion rules, please refer to the [Note: Update type promotion rule] section.\n"
       },
       "name":"fx-node-insert-type-promotion",
       "shortDescription":{
        "text":"Determine if type promotion is required for the FX node. Insert cast nodes if needed."
       }
      }
     ],
     "version":"2.6.0+cu124"
    }
   },
   "language":"en-US",
   "newlineSequences":[
    "\r\n",
    "\n"
   ],
   "results":[
    {
     "message":{
      "markdown":"Running Decompose pass. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature Transform.run\n- self: <class 'torch.onnx._internal.fx.passes.decomp.Decompose'>\n- args: Tuple[length=1](\nTensor(f32[1, 3, 400, 400]),\n)\nFor detailed logging of graph modifications by this pass, either set `DiagnosticOptions.verbosity_level` to `logging.DEBUG` or use the environment variable `TORCH_LOGS='onnx_diagnostics'`.\n## Return values\ntorch.fx.GraphModule(<lambda>)",
      "text":"Running Decompose pass. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"Transform.run"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/_pass.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":240
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0010",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Running Functionalize pass. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature Transform.run\n- self: <class 'torch.onnx._internal.fx.passes.functionalization.Functionalize'>\n- args: Tuple[length=1](\nTensor(f32[1, 3, 400, 400]),\n)\nFor detailed logging of graph modifications by this pass, either set `DiagnosticOptions.verbosity_level` to `logging.DEBUG` or use the environment variable `TORCH_LOGS='onnx_diagnostics'`.\n## Return values\ntorch.fx.GraphModule(<lambda>)",
      "text":"Running Functionalize pass. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"Transform.run"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/_pass.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":240
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0010",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Running RemoveInputMutation pass. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature Transform.run\n- self: <class 'torch.onnx._internal.fx.passes.functionalization.RemoveInputMutation'>\n- args: Tuple[length=1](\nTensor(f32[1, 3, 400, 400]),\n)\nFor detailed logging of graph modifications by this pass, either set `DiagnosticOptions.verbosity_level` to `logging.DEBUG` or use the environment variable `TORCH_LOGS='onnx_diagnostics'`.\n## Return values\ntorch.fx.GraphModule(<lambda>)",
      "text":"Running RemoveInputMutation pass. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"Transform.run"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/_pass.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":240
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0010",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped l_x_: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(arg0)[placeholder]:Tensor(f32[1, 3, 400, 400])\n## Return values\nTensor(f32[1, 3, 400, 400])",
      "text":"Skipped l_x_: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant0: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant0)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64, 3, 1, 1]))",
      "text":"Skipped _param_constant0: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 200, 200]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 200, 200])\n## Return values\nTensor(f32[1, 64, 200, 200])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 200, 200]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant1: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant1)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64]))",
      "text":"Skipped _param_constant1: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant2: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant2)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64]))",
      "text":"Skipped _param_constant2: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant0: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant0)[get_attr]:None\n## Return values\nTensor(f32[64])",
      "text":"Skipped _tensor_constant0: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant1: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant1)[get_attr]:None\n## Return values\nTensor(f32[64])",
      "text":"Skipped _tensor_constant1: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 200, 200]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 200, 200]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 64, 200, 200]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 200, 200]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 200, 200]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 200, 200])\n## Return values\nTensor(f32[1, 64, 200, 200])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 200, 200]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Applied type promotion for add. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 64, 200, 200])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument getitem is not promoted. Already torch.float32.\nArgument 0(Scalar of equivalent dtype: torch.int64) is promoted to torch.float32.\n## Return values\nTensor(f32[1, 64, 200, 200])",
      "text":"Applied type promotion for add. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant3: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant3)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64, 3, 3, 3]))",
      "text":"Skipped _param_constant3: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 200, 200]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 200, 200])\n## Return values\nTensor(f32[1, 64, 200, 200])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 200, 200]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant4: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant4)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64]))",
      "text":"Skipped _param_constant4: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant5: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant5)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64]))",
      "text":"Skipped _param_constant5: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant2: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant2)[get_attr]:None\n## Return values\nTensor(f32[64])",
      "text":"Skipped _tensor_constant2: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant3: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant3)[get_attr]:None\n## Return values\nTensor(f32[64])",
      "text":"Skipped _tensor_constant3: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 200, 200]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 200, 200]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 64, 200, 200]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 200, 200]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 200, 200]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 200, 200])\n## Return values\nTensor(f32[1, 64, 200, 200])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 200, 200]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_1. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 64, 200, 200])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add is not promoted. Already torch.float32.\nArgument getitem_3 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 64, 200, 200])",
      "text":"Type promotion not needed for add_1. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for gelu. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.gelu.default)[call_function]:Tensor(f32[1, 64, 200, 200])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'gelu', [0], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_1 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 64, 200, 200])",
      "text":"Type promotion not needed for gelu. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant6: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant6)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64, 1, 1, 1]))",
      "text":"Skipped _param_constant6: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 100, 100]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 100, 100])\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 100, 100]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant7: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant7)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64]))",
      "text":"Skipped _param_constant7: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant8: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant8)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64]))",
      "text":"Skipped _param_constant8: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant4: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant4)[get_attr]:None\n## Return values\nTensor(f32[64])",
      "text":"Skipped _tensor_constant4: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant5: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant5)[get_attr]:None\n## Return values\nTensor(f32[64])",
      "text":"Skipped _tensor_constant5: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100])\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Applied type promotion for add_2. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 64, 100, 100])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument getitem_6 is not promoted. Already torch.float32.\nArgument 0(Scalar of equivalent dtype: torch.int64) is promoted to torch.float32.\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Applied type promotion for add_2. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant9: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant9)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64, 1, 3, 3]))",
      "text":"Skipped _param_constant9: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 100, 100]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 100, 100])\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 100, 100]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant10: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant10)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64]))",
      "text":"Skipped _param_constant10: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant11: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant11)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64]))",
      "text":"Skipped _param_constant11: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant6: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant6)[get_attr]:None\n## Return values\nTensor(f32[64])",
      "text":"Skipped _tensor_constant6: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant7: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant7)[get_attr]:None\n## Return values\nTensor(f32[64])",
      "text":"Skipped _tensor_constant7: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100])\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_3. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 64, 100, 100])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_2 is not promoted. Already torch.float32.\nArgument getitem_9 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Type promotion not needed for add_3. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for gelu_1. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.gelu.default)[call_function]:Tensor(f32[1, 64, 100, 100])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'gelu', [0], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_3 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Type promotion not needed for gelu_1. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant12: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant12)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64]))",
      "text":"Skipped _param_constant12: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant13: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant13)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64]))",
      "text":"Skipped _param_constant13: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant8: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant8)[get_attr]:None\n## Return values\nTensor(f32[64])",
      "text":"Skipped _tensor_constant8: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant9: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant9)[get_attr]:None\n## Return values\nTensor(f32[64])",
      "text":"Skipped _tensor_constant9: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100])\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Applied type promotion for add_4. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 64, 100, 100])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument getitem_12 is not promoted. Already torch.float32.\nArgument 0(Scalar of equivalent dtype: torch.int64) is promoted to torch.float32.\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Applied type promotion for add_4. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant14: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant14)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64, 64, 1, 1]))",
      "text":"Skipped _param_constant14: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 100, 100]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 100, 100])\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 100, 100]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant15: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant15)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64]))",
      "text":"Skipped _param_constant15: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant16: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant16)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64]))",
      "text":"Skipped _param_constant16: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant10: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant10)[get_attr]:None\n## Return values\nTensor(f32[64])",
      "text":"Skipped _tensor_constant10: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant11: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant11)[get_attr]:None\n## Return values\nTensor(f32[64])",
      "text":"Skipped _tensor_constant11: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100])\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_5. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 64, 100, 100])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_4 is not promoted. Already torch.float32.\nArgument getitem_15 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Type promotion not needed for add_5. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for gelu_2. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.gelu.default)[call_function]:Tensor(f32[1, 64, 100, 100])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'gelu', [0], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_5 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Type promotion not needed for gelu_2. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant17: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant17)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64]))",
      "text":"Skipped _param_constant17: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant18: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant18)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64]))",
      "text":"Skipped _param_constant18: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant12: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant12)[get_attr]:None\n## Return values\nTensor(f32[64])",
      "text":"Skipped _tensor_constant12: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant13: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant13)[get_attr]:None\n## Return values\nTensor(f32[64])",
      "text":"Skipped _tensor_constant13: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100])\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant19: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant19)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64, 1, 1, 1]))",
      "text":"Skipped _param_constant19: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 100, 100]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 100, 100])\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 100, 100]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant20: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant20)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64]))",
      "text":"Skipped _param_constant20: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant21: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant21)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64]))",
      "text":"Skipped _param_constant21: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant14: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant14)[get_attr]:None\n## Return values\nTensor(f32[64])",
      "text":"Skipped _tensor_constant14: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant15: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant15)[get_attr]:None\n## Return values\nTensor(f32[64])",
      "text":"Skipped _tensor_constant15: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100])\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_6. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 64, 100, 100])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument getitem_21 is not promoted. Already torch.float32.\nArgument getitem_18 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Type promotion not needed for add_6. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant22: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant22)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64, 1, 3, 3]))",
      "text":"Skipped _param_constant22: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 100, 100]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 100, 100])\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 100, 100]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant23: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant23)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64]))",
      "text":"Skipped _param_constant23: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant24: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant24)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64]))",
      "text":"Skipped _param_constant24: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant16: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant16)[get_attr]:None\n## Return values\nTensor(f32[64])",
      "text":"Skipped _tensor_constant16: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant17: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant17)[get_attr]:None\n## Return values\nTensor(f32[64])",
      "text":"Skipped _tensor_constant17: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100])\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_7. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 64, 100, 100])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_6 is not promoted. Already torch.float32.\nArgument getitem_24 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Type promotion not needed for add_7. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant25: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant25)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64]))",
      "text":"Skipped _param_constant25: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant26: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant26)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64]))",
      "text":"Skipped _param_constant26: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant18: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant18)[get_attr]:None\n## Return values\nTensor(f32[64])",
      "text":"Skipped _tensor_constant18: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant19: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant19)[get_attr]:None\n## Return values\nTensor(f32[64])",
      "text":"Skipped _tensor_constant19: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100])\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Applied type promotion for add_8. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 64, 100, 100])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument getitem_27 is not promoted. Already torch.float32.\nArgument 0(Scalar of equivalent dtype: torch.int64) is promoted to torch.float32.\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Applied type promotion for add_8. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for sub. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.sub.Tensor)[call_function]:Tensor(f32[1, 64, 100, 100])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'sub', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_7 is not promoted. Already torch.float32.\nArgument add_8 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Type promotion not needed for sub. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant27: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant27)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64, 1, 1]))",
      "text":"Skipped _param_constant27: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for mul. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.mul.Tensor)[call_function]:Tensor(f32[1, 64, 100, 100])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'mul', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument sub is not promoted. Already torch.float32.\nArgument _param_constant27 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Type promotion not needed for mul. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_9. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 64, 100, 100])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument gelu_2 is not promoted. Already torch.float32.\nArgument mul is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Type promotion not needed for add_9. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant28: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant28)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64, 1, 7, 7]))",
      "text":"Skipped _param_constant28: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 100, 100]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 100, 100])\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 100, 100]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant29: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant29)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64]))",
      "text":"Skipped _param_constant29: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant30: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant30)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64]))",
      "text":"Skipped _param_constant30: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant20: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant20)[get_attr]:None\n## Return values\nTensor(f32[64])",
      "text":"Skipped _tensor_constant20: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant21: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant21)[get_attr]:None\n## Return values\nTensor(f32[64])",
      "text":"Skipped _tensor_constant21: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100])\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant31: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant31)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 64, 1, 1]))",
      "text":"Skipped _param_constant31: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant32: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant32)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant32: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 100, 100]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 100, 100])\n## Return values\nTensor(f32[1, 256, 100, 100])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 100, 100]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for gelu_3. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.gelu.default)[call_function]:Tensor(f32[1, 256, 100, 100])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'gelu', [0], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument convolution_8 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 100, 100])",
      "text":"Type promotion not needed for gelu_3. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 256, 100, 100]): Cannot find type promotion rule for op: aten.clone.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 256, 100, 100])\n## Return values\nTensor(f32[1, 256, 100, 100])",
      "text":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 256, 100, 100]): Cannot find type promotion rule for op: aten.clone.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant33: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant33)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64, 256, 1, 1]))",
      "text":"Skipped _param_constant33: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant34: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant34)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64]))",
      "text":"Skipped _param_constant34: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 100, 100]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 100, 100])\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 100, 100]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 64, 100, 100]): Cannot find type promotion rule for op: aten.clone.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 64, 100, 100])\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 64, 100, 100]): Cannot find type promotion rule for op: aten.clone.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant35: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant35)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64, 1, 1]))",
      "text":"Skipped _param_constant35: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for mul_1. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.mul.Tensor)[call_function]:Tensor(f32[1, 64, 100, 100])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'mul', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument clone_1 is not promoted. Already torch.float32.\nArgument _param_constant35 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Type promotion not needed for mul_1. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_10. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 64, 100, 100])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_9 is not promoted. Already torch.float32.\nArgument mul_1 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Type promotion not needed for add_10. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant36: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant36)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64]))",
      "text":"Skipped _param_constant36: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant37: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant37)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64]))",
      "text":"Skipped _param_constant37: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant22: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant22)[get_attr]:None\n## Return values\nTensor(f32[64])",
      "text":"Skipped _tensor_constant22: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant23: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant23)[get_attr]:None\n## Return values\nTensor(f32[64])",
      "text":"Skipped _tensor_constant23: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100])\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant38: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant38)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64, 1, 1, 1]))",
      "text":"Skipped _param_constant38: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 100, 100]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 100, 100])\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 100, 100]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant39: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant39)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64]))",
      "text":"Skipped _param_constant39: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant40: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant40)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64]))",
      "text":"Skipped _param_constant40: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant24: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant24)[get_attr]:None\n## Return values\nTensor(f32[64])",
      "text":"Skipped _tensor_constant24: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant25: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant25)[get_attr]:None\n## Return values\nTensor(f32[64])",
      "text":"Skipped _tensor_constant25: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100])\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_11. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 64, 100, 100])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument getitem_36 is not promoted. Already torch.float32.\nArgument getitem_33 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Type promotion not needed for add_11. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant41: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant41)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64, 1, 3, 3]))",
      "text":"Skipped _param_constant41: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 100, 100]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 100, 100])\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 100, 100]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant42: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant42)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64]))",
      "text":"Skipped _param_constant42: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant43: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant43)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64]))",
      "text":"Skipped _param_constant43: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant26: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant26)[get_attr]:None\n## Return values\nTensor(f32[64])",
      "text":"Skipped _tensor_constant26: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant27: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant27)[get_attr]:None\n## Return values\nTensor(f32[64])",
      "text":"Skipped _tensor_constant27: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100])\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_12. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 64, 100, 100])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_11 is not promoted. Already torch.float32.\nArgument getitem_39 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Type promotion not needed for add_12. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant44: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant44)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64]))",
      "text":"Skipped _param_constant44: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant45: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant45)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64]))",
      "text":"Skipped _param_constant45: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant28: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant28)[get_attr]:None\n## Return values\nTensor(f32[64])",
      "text":"Skipped _tensor_constant28: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant29: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant29)[get_attr]:None\n## Return values\nTensor(f32[64])",
      "text":"Skipped _tensor_constant29: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100])\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Applied type promotion for add_13. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 64, 100, 100])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument getitem_42 is not promoted. Already torch.float32.\nArgument 0(Scalar of equivalent dtype: torch.int64) is promoted to torch.float32.\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Applied type promotion for add_13. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for sub_1. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.sub.Tensor)[call_function]:Tensor(f32[1, 64, 100, 100])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'sub', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_12 is not promoted. Already torch.float32.\nArgument add_13 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Type promotion not needed for sub_1. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant46: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant46)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64, 1, 1]))",
      "text":"Skipped _param_constant46: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for mul_2. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.mul.Tensor)[call_function]:Tensor(f32[1, 64, 100, 100])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'mul', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument sub_1 is not promoted. Already torch.float32.\nArgument _param_constant46 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Type promotion not needed for mul_2. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_14. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 64, 100, 100])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_10 is not promoted. Already torch.float32.\nArgument mul_2 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Type promotion not needed for add_14. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant47: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant47)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64, 1, 7, 7]))",
      "text":"Skipped _param_constant47: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 100, 100]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 100, 100])\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 100, 100]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant48: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant48)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64]))",
      "text":"Skipped _param_constant48: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant49: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant49)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64]))",
      "text":"Skipped _param_constant49: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant30: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant30)[get_attr]:None\n## Return values\nTensor(f32[64])",
      "text":"Skipped _tensor_constant30: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant31: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant31)[get_attr]:None\n## Return values\nTensor(f32[64])",
      "text":"Skipped _tensor_constant31: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100])\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant50: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant50)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 64, 1, 1]))",
      "text":"Skipped _param_constant50: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant51: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant51)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant51: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 100, 100]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 100, 100])\n## Return values\nTensor(f32[1, 256, 100, 100])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 100, 100]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for gelu_4. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.gelu.default)[call_function]:Tensor(f32[1, 256, 100, 100])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'gelu', [0], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument convolution_13 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 100, 100])",
      "text":"Type promotion not needed for gelu_4. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 256, 100, 100]): Cannot find type promotion rule for op: aten.clone.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 256, 100, 100])\n## Return values\nTensor(f32[1, 256, 100, 100])",
      "text":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 256, 100, 100]): Cannot find type promotion rule for op: aten.clone.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant52: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant52)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64, 256, 1, 1]))",
      "text":"Skipped _param_constant52: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant53: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant53)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64]))",
      "text":"Skipped _param_constant53: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 100, 100]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 100, 100])\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 100, 100]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 64, 100, 100]): Cannot find type promotion rule for op: aten.clone.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 64, 100, 100])\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 64, 100, 100]): Cannot find type promotion rule for op: aten.clone.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant54: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant54)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64, 1, 1]))",
      "text":"Skipped _param_constant54: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for mul_3. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.mul.Tensor)[call_function]:Tensor(f32[1, 64, 100, 100])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'mul', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument clone_3 is not promoted. Already torch.float32.\nArgument _param_constant54 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Type promotion not needed for mul_3. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_15. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 64, 100, 100])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_14 is not promoted. Already torch.float32.\nArgument mul_3 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Type promotion not needed for add_15. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant55: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant55)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64]))",
      "text":"Skipped _param_constant55: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant56: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant56)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64]))",
      "text":"Skipped _param_constant56: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant32: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant32)[get_attr]:None\n## Return values\nTensor(f32[64])",
      "text":"Skipped _tensor_constant32: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant33: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant33)[get_attr]:None\n## Return values\nTensor(f32[64])",
      "text":"Skipped _tensor_constant33: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100])\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant57: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant57)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64, 1, 1, 1]))",
      "text":"Skipped _param_constant57: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 100, 100]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 100, 100])\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 100, 100]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant58: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant58)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64]))",
      "text":"Skipped _param_constant58: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant59: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant59)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64]))",
      "text":"Skipped _param_constant59: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant34: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant34)[get_attr]:None\n## Return values\nTensor(f32[64])",
      "text":"Skipped _tensor_constant34: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant35: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant35)[get_attr]:None\n## Return values\nTensor(f32[64])",
      "text":"Skipped _tensor_constant35: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100])\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_16. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 64, 100, 100])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument getitem_51 is not promoted. Already torch.float32.\nArgument getitem_48 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Type promotion not needed for add_16. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant60: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant60)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64, 1, 3, 3]))",
      "text":"Skipped _param_constant60: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 100, 100]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 100, 100])\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 100, 100]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant61: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant61)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64]))",
      "text":"Skipped _param_constant61: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant62: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant62)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64]))",
      "text":"Skipped _param_constant62: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant36: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant36)[get_attr]:None\n## Return values\nTensor(f32[64])",
      "text":"Skipped _tensor_constant36: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant37: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant37)[get_attr]:None\n## Return values\nTensor(f32[64])",
      "text":"Skipped _tensor_constant37: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100])\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_17. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 64, 100, 100])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_16 is not promoted. Already torch.float32.\nArgument getitem_54 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Type promotion not needed for add_17. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant63: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant63)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64]))",
      "text":"Skipped _param_constant63: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant64: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant64)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64]))",
      "text":"Skipped _param_constant64: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant38: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant38)[get_attr]:None\n## Return values\nTensor(f32[64])",
      "text":"Skipped _tensor_constant38: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant39: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant39)[get_attr]:None\n## Return values\nTensor(f32[64])",
      "text":"Skipped _tensor_constant39: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100])\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Applied type promotion for add_18. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 64, 100, 100])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument getitem_57 is not promoted. Already torch.float32.\nArgument 0(Scalar of equivalent dtype: torch.int64) is promoted to torch.float32.\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Applied type promotion for add_18. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for sub_2. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.sub.Tensor)[call_function]:Tensor(f32[1, 64, 100, 100])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'sub', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_17 is not promoted. Already torch.float32.\nArgument add_18 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Type promotion not needed for sub_2. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant65: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant65)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64, 1, 1]))",
      "text":"Skipped _param_constant65: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for mul_4. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.mul.Tensor)[call_function]:Tensor(f32[1, 64, 100, 100])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'mul', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument sub_2 is not promoted. Already torch.float32.\nArgument _param_constant65 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Type promotion not needed for mul_4. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_19. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 64, 100, 100])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_15 is not promoted. Already torch.float32.\nArgument mul_4 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Type promotion not needed for add_19. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant66: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant66)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64, 1, 7, 7]))",
      "text":"Skipped _param_constant66: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 100, 100]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 100, 100])\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 100, 100]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant67: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant67)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64]))",
      "text":"Skipped _param_constant67: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant68: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant68)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64]))",
      "text":"Skipped _param_constant68: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant40: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant40)[get_attr]:None\n## Return values\nTensor(f32[64])",
      "text":"Skipped _tensor_constant40: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant41: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant41)[get_attr]:None\n## Return values\nTensor(f32[64])",
      "text":"Skipped _tensor_constant41: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100])\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant69: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant69)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 64, 1, 1]))",
      "text":"Skipped _param_constant69: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant70: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant70)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant70: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 100, 100]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 100, 100])\n## Return values\nTensor(f32[1, 256, 100, 100])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 100, 100]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for gelu_5. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.gelu.default)[call_function]:Tensor(f32[1, 256, 100, 100])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'gelu', [0], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument convolution_18 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 100, 100])",
      "text":"Type promotion not needed for gelu_5. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 256, 100, 100]): Cannot find type promotion rule for op: aten.clone.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 256, 100, 100])\n## Return values\nTensor(f32[1, 256, 100, 100])",
      "text":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 256, 100, 100]): Cannot find type promotion rule for op: aten.clone.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant71: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant71)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64, 256, 1, 1]))",
      "text":"Skipped _param_constant71: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant72: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant72)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64]))",
      "text":"Skipped _param_constant72: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 100, 100]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 100, 100])\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 100, 100]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 64, 100, 100]): Cannot find type promotion rule for op: aten.clone.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 64, 100, 100])\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 64, 100, 100]): Cannot find type promotion rule for op: aten.clone.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant73: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant73)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64, 1, 1]))",
      "text":"Skipped _param_constant73: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for mul_5. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.mul.Tensor)[call_function]:Tensor(f32[1, 64, 100, 100])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'mul', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument clone_5 is not promoted. Already torch.float32.\nArgument _param_constant73 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Type promotion not needed for mul_5. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_20. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 64, 100, 100])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_19 is not promoted. Already torch.float32.\nArgument mul_5 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Type promotion not needed for add_20. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant74: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant74)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64]))",
      "text":"Skipped _param_constant74: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant75: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant75)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64]))",
      "text":"Skipped _param_constant75: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant42: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant42)[get_attr]:None\n## Return values\nTensor(f32[64])",
      "text":"Skipped _tensor_constant42: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant43: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant43)[get_attr]:None\n## Return values\nTensor(f32[64])",
      "text":"Skipped _tensor_constant43: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100])\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant76: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant76)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64, 1, 1, 1]))",
      "text":"Skipped _param_constant76: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 100, 100]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 100, 100])\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 100, 100]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant77: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant77)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64]))",
      "text":"Skipped _param_constant77: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant78: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant78)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64]))",
      "text":"Skipped _param_constant78: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant44: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant44)[get_attr]:None\n## Return values\nTensor(f32[64])",
      "text":"Skipped _tensor_constant44: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant45: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant45)[get_attr]:None\n## Return values\nTensor(f32[64])",
      "text":"Skipped _tensor_constant45: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100])\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_21. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 64, 100, 100])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument getitem_66 is not promoted. Already torch.float32.\nArgument getitem_63 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Type promotion not needed for add_21. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant79: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant79)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64, 1, 3, 3]))",
      "text":"Skipped _param_constant79: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 100, 100]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 100, 100])\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 100, 100]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant80: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant80)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64]))",
      "text":"Skipped _param_constant80: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant81: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant81)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64]))",
      "text":"Skipped _param_constant81: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant46: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant46)[get_attr]:None\n## Return values\nTensor(f32[64])",
      "text":"Skipped _tensor_constant46: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant47: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant47)[get_attr]:None\n## Return values\nTensor(f32[64])",
      "text":"Skipped _tensor_constant47: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100])\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_22. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 64, 100, 100])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_21 is not promoted. Already torch.float32.\nArgument getitem_69 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Type promotion not needed for add_22. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant82: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant82)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64]))",
      "text":"Skipped _param_constant82: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant83: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant83)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64]))",
      "text":"Skipped _param_constant83: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant48: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant48)[get_attr]:None\n## Return values\nTensor(f32[64])",
      "text":"Skipped _tensor_constant48: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant49: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant49)[get_attr]:None\n## Return values\nTensor(f32[64])",
      "text":"Skipped _tensor_constant49: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100])\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Applied type promotion for add_23. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 64, 100, 100])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument getitem_72 is not promoted. Already torch.float32.\nArgument 0(Scalar of equivalent dtype: torch.int64) is promoted to torch.float32.\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Applied type promotion for add_23. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for sub_3. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.sub.Tensor)[call_function]:Tensor(f32[1, 64, 100, 100])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'sub', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_22 is not promoted. Already torch.float32.\nArgument add_23 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Type promotion not needed for sub_3. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant84: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant84)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64, 1, 1]))",
      "text":"Skipped _param_constant84: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for mul_6. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.mul.Tensor)[call_function]:Tensor(f32[1, 64, 100, 100])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'mul', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument sub_3 is not promoted. Already torch.float32.\nArgument _param_constant84 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Type promotion not needed for mul_6. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_24. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 64, 100, 100])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_20 is not promoted. Already torch.float32.\nArgument mul_6 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Type promotion not needed for add_24. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant85: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant85)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64, 1, 7, 7]))",
      "text":"Skipped _param_constant85: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 100, 100]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 100, 100])\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 100, 100]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant86: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant86)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64]))",
      "text":"Skipped _param_constant86: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant87: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant87)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64]))",
      "text":"Skipped _param_constant87: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant50: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant50)[get_attr]:None\n## Return values\nTensor(f32[64])",
      "text":"Skipped _tensor_constant50: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant51: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant51)[get_attr]:None\n## Return values\nTensor(f32[64])",
      "text":"Skipped _tensor_constant51: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 100, 100]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100])\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 100, 100]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant88: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant88)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 64, 1, 1]))",
      "text":"Skipped _param_constant88: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant89: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant89)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant89: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 100, 100]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 100, 100])\n## Return values\nTensor(f32[1, 256, 100, 100])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 100, 100]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for gelu_6. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.gelu.default)[call_function]:Tensor(f32[1, 256, 100, 100])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'gelu', [0], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument convolution_23 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 100, 100])",
      "text":"Type promotion not needed for gelu_6. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 256, 100, 100]): Cannot find type promotion rule for op: aten.clone.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 256, 100, 100])\n## Return values\nTensor(f32[1, 256, 100, 100])",
      "text":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 256, 100, 100]): Cannot find type promotion rule for op: aten.clone.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant90: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant90)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64, 256, 1, 1]))",
      "text":"Skipped _param_constant90: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant91: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant91)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64]))",
      "text":"Skipped _param_constant91: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 100, 100]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 100, 100])\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 100, 100]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 64, 100, 100]): Cannot find type promotion rule for op: aten.clone.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 64, 100, 100])\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 64, 100, 100]): Cannot find type promotion rule for op: aten.clone.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant92: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant92)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64, 1, 1]))",
      "text":"Skipped _param_constant92: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for mul_7. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.mul.Tensor)[call_function]:Tensor(f32[1, 64, 100, 100])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'mul', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument clone_7 is not promoted. Already torch.float32.\nArgument _param_constant92 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Type promotion not needed for mul_7. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_25. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 64, 100, 100])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_24 is not promoted. Already torch.float32.\nArgument mul_7 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 64, 100, 100])",
      "text":"Type promotion not needed for add_25. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant93: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant93)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128, 1, 7, 7]))",
      "text":"Skipped _param_constant93: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 128, 50, 50]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 128, 50, 50])\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 128, 50, 50]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant94: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant94)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128]))",
      "text":"Skipped _param_constant94: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant95: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant95)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128]))",
      "text":"Skipped _param_constant95: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant52: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant52)[get_attr]:None\n## Return values\nTensor(f32[128])",
      "text":"Skipped _tensor_constant52: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant53: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant53)[get_attr]:None\n## Return values\nTensor(f32[128])",
      "text":"Skipped _tensor_constant53: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50])\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant96: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant96)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128, 1, 3, 3]))",
      "text":"Skipped _param_constant96: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 128, 50, 50]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 128, 50, 50])\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 128, 50, 50]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant97: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant97)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128]))",
      "text":"Skipped _param_constant97: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant98: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant98)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128]))",
      "text":"Skipped _param_constant98: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant54: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant54)[get_attr]:None\n## Return values\nTensor(f32[128])",
      "text":"Skipped _tensor_constant54: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant55: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant55)[get_attr]:None\n## Return values\nTensor(f32[128])",
      "text":"Skipped _tensor_constant55: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50])\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_26. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 128, 50, 50])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument getitem_78 is not promoted. Already torch.float32.\nArgument getitem_81 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Type promotion not needed for add_26. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant99: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant99)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128]))",
      "text":"Skipped _param_constant99: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant100: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant100)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128]))",
      "text":"Skipped _param_constant100: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant56: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant56)[get_attr]:None\n## Return values\nTensor(f32[128])",
      "text":"Skipped _tensor_constant56: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant57: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant57)[get_attr]:None\n## Return values\nTensor(f32[128])",
      "text":"Skipped _tensor_constant57: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50])\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Applied type promotion for add_27. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 128, 50, 50])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument getitem_84 is not promoted. Already torch.float32.\nArgument 0(Scalar of equivalent dtype: torch.int64) is promoted to torch.float32.\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Applied type promotion for add_27. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant101: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant101)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128, 128, 1, 1]))",
      "text":"Skipped _param_constant101: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 128, 50, 50]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 128, 50, 50])\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 128, 50, 50]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant102: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant102)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128]))",
      "text":"Skipped _param_constant102: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant103: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant103)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128]))",
      "text":"Skipped _param_constant103: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant58: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant58)[get_attr]:None\n## Return values\nTensor(f32[128])",
      "text":"Skipped _tensor_constant58: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant59: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant59)[get_attr]:None\n## Return values\nTensor(f32[128])",
      "text":"Skipped _tensor_constant59: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50])\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_28. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 128, 50, 50])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_27 is not promoted. Already torch.float32.\nArgument getitem_87 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Type promotion not needed for add_28. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for gelu_7. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.gelu.default)[call_function]:Tensor(f32[1, 128, 50, 50])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'gelu', [0], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_28 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Type promotion not needed for gelu_7. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant104: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant104)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128]))",
      "text":"Skipped _param_constant104: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant105: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant105)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128]))",
      "text":"Skipped _param_constant105: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant60: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant60)[get_attr]:None\n## Return values\nTensor(f32[128])",
      "text":"Skipped _tensor_constant60: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant61: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant61)[get_attr]:None\n## Return values\nTensor(f32[128])",
      "text":"Skipped _tensor_constant61: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50])\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant106: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant106)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128, 1, 1, 1]))",
      "text":"Skipped _param_constant106: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 128, 50, 50]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 128, 50, 50])\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 128, 50, 50]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant107: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant107)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128]))",
      "text":"Skipped _param_constant107: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant108: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant108)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128]))",
      "text":"Skipped _param_constant108: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant62: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant62)[get_attr]:None\n## Return values\nTensor(f32[128])",
      "text":"Skipped _tensor_constant62: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant63: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant63)[get_attr]:None\n## Return values\nTensor(f32[128])",
      "text":"Skipped _tensor_constant63: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50])\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_29. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 128, 50, 50])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument getitem_93 is not promoted. Already torch.float32.\nArgument getitem_90 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Type promotion not needed for add_29. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant109: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant109)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128, 1, 3, 3]))",
      "text":"Skipped _param_constant109: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 128, 50, 50]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 128, 50, 50])\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 128, 50, 50]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant110: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant110)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128]))",
      "text":"Skipped _param_constant110: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant111: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant111)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128]))",
      "text":"Skipped _param_constant111: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant64: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant64)[get_attr]:None\n## Return values\nTensor(f32[128])",
      "text":"Skipped _tensor_constant64: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant65: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant65)[get_attr]:None\n## Return values\nTensor(f32[128])",
      "text":"Skipped _tensor_constant65: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50])\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_30. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 128, 50, 50])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_29 is not promoted. Already torch.float32.\nArgument getitem_96 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Type promotion not needed for add_30. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant112: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant112)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128]))",
      "text":"Skipped _param_constant112: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant113: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant113)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128]))",
      "text":"Skipped _param_constant113: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant66: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant66)[get_attr]:None\n## Return values\nTensor(f32[128])",
      "text":"Skipped _tensor_constant66: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant67: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant67)[get_attr]:None\n## Return values\nTensor(f32[128])",
      "text":"Skipped _tensor_constant67: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50])\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Applied type promotion for add_31. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 128, 50, 50])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument getitem_99 is not promoted. Already torch.float32.\nArgument 0(Scalar of equivalent dtype: torch.int64) is promoted to torch.float32.\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Applied type promotion for add_31. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for sub_4. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.sub.Tensor)[call_function]:Tensor(f32[1, 128, 50, 50])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'sub', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_30 is not promoted. Already torch.float32.\nArgument add_31 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Type promotion not needed for sub_4. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant114: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant114)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128, 1, 1]))",
      "text":"Skipped _param_constant114: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for mul_8. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.mul.Tensor)[call_function]:Tensor(f32[1, 128, 50, 50])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'mul', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument sub_4 is not promoted. Already torch.float32.\nArgument _param_constant114 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Type promotion not needed for mul_8. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_32. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 128, 50, 50])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument gelu_7 is not promoted. Already torch.float32.\nArgument mul_8 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Type promotion not needed for add_32. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant115: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant115)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128, 1, 7, 7]))",
      "text":"Skipped _param_constant115: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 128, 50, 50]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 128, 50, 50])\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 128, 50, 50]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant116: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant116)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128]))",
      "text":"Skipped _param_constant116: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant117: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant117)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128]))",
      "text":"Skipped _param_constant117: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant68: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant68)[get_attr]:None\n## Return values\nTensor(f32[128])",
      "text":"Skipped _tensor_constant68: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant69: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant69)[get_attr]:None\n## Return values\nTensor(f32[128])",
      "text":"Skipped _tensor_constant69: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50])\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant118: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant118)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512, 128, 1, 1]))",
      "text":"Skipped _param_constant118: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant119: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant119)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512]))",
      "text":"Skipped _param_constant119: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 512, 50, 50]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 512, 50, 50])\n## Return values\nTensor(f32[1, 512, 50, 50])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 512, 50, 50]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for gelu_8. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.gelu.default)[call_function]:Tensor(f32[1, 512, 50, 50])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'gelu', [0], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument convolution_31 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 512, 50, 50])",
      "text":"Type promotion not needed for gelu_8. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 512, 50, 50]): Cannot find type promotion rule for op: aten.clone.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 512, 50, 50])\n## Return values\nTensor(f32[1, 512, 50, 50])",
      "text":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 512, 50, 50]): Cannot find type promotion rule for op: aten.clone.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant120: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant120)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128, 512, 1, 1]))",
      "text":"Skipped _param_constant120: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant121: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant121)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128]))",
      "text":"Skipped _param_constant121: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 128, 50, 50]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 128, 50, 50])\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 128, 50, 50]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 128, 50, 50]): Cannot find type promotion rule for op: aten.clone.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 128, 50, 50])\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 128, 50, 50]): Cannot find type promotion rule for op: aten.clone.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant122: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant122)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128, 1, 1]))",
      "text":"Skipped _param_constant122: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for mul_9. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.mul.Tensor)[call_function]:Tensor(f32[1, 128, 50, 50])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'mul', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument clone_9 is not promoted. Already torch.float32.\nArgument _param_constant122 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Type promotion not needed for mul_9. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_33. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 128, 50, 50])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_32 is not promoted. Already torch.float32.\nArgument mul_9 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Type promotion not needed for add_33. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant123: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant123)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128]))",
      "text":"Skipped _param_constant123: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant124: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant124)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128]))",
      "text":"Skipped _param_constant124: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant70: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant70)[get_attr]:None\n## Return values\nTensor(f32[128])",
      "text":"Skipped _tensor_constant70: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant71: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant71)[get_attr]:None\n## Return values\nTensor(f32[128])",
      "text":"Skipped _tensor_constant71: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50])\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant125: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant125)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128, 1, 1, 1]))",
      "text":"Skipped _param_constant125: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 128, 50, 50]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 128, 50, 50])\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 128, 50, 50]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant126: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant126)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128]))",
      "text":"Skipped _param_constant126: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant127: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant127)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128]))",
      "text":"Skipped _param_constant127: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant72: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant72)[get_attr]:None\n## Return values\nTensor(f32[128])",
      "text":"Skipped _tensor_constant72: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant73: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant73)[get_attr]:None\n## Return values\nTensor(f32[128])",
      "text":"Skipped _tensor_constant73: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50])\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_34. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 128, 50, 50])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument getitem_108 is not promoted. Already torch.float32.\nArgument getitem_105 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Type promotion not needed for add_34. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant128: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant128)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128, 1, 3, 3]))",
      "text":"Skipped _param_constant128: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 128, 50, 50]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 128, 50, 50])\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 128, 50, 50]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant129: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant129)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128]))",
      "text":"Skipped _param_constant129: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant130: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant130)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128]))",
      "text":"Skipped _param_constant130: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant74: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant74)[get_attr]:None\n## Return values\nTensor(f32[128])",
      "text":"Skipped _tensor_constant74: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant75: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant75)[get_attr]:None\n## Return values\nTensor(f32[128])",
      "text":"Skipped _tensor_constant75: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50])\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_35. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 128, 50, 50])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_34 is not promoted. Already torch.float32.\nArgument getitem_111 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Type promotion not needed for add_35. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant131: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant131)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128]))",
      "text":"Skipped _param_constant131: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant132: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant132)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128]))",
      "text":"Skipped _param_constant132: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant76: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant76)[get_attr]:None\n## Return values\nTensor(f32[128])",
      "text":"Skipped _tensor_constant76: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant77: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant77)[get_attr]:None\n## Return values\nTensor(f32[128])",
      "text":"Skipped _tensor_constant77: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50])\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Applied type promotion for add_36. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 128, 50, 50])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument getitem_114 is not promoted. Already torch.float32.\nArgument 0(Scalar of equivalent dtype: torch.int64) is promoted to torch.float32.\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Applied type promotion for add_36. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for sub_5. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.sub.Tensor)[call_function]:Tensor(f32[1, 128, 50, 50])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'sub', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_35 is not promoted. Already torch.float32.\nArgument add_36 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Type promotion not needed for sub_5. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant133: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant133)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128, 1, 1]))",
      "text":"Skipped _param_constant133: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for mul_10. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.mul.Tensor)[call_function]:Tensor(f32[1, 128, 50, 50])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'mul', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument sub_5 is not promoted. Already torch.float32.\nArgument _param_constant133 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Type promotion not needed for mul_10. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_37. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 128, 50, 50])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_33 is not promoted. Already torch.float32.\nArgument mul_10 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Type promotion not needed for add_37. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant134: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant134)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128, 1, 7, 7]))",
      "text":"Skipped _param_constant134: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 128, 50, 50]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 128, 50, 50])\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 128, 50, 50]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant135: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant135)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128]))",
      "text":"Skipped _param_constant135: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant136: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant136)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128]))",
      "text":"Skipped _param_constant136: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant78: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant78)[get_attr]:None\n## Return values\nTensor(f32[128])",
      "text":"Skipped _tensor_constant78: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant79: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant79)[get_attr]:None\n## Return values\nTensor(f32[128])",
      "text":"Skipped _tensor_constant79: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50])\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant137: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant137)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512, 128, 1, 1]))",
      "text":"Skipped _param_constant137: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant138: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant138)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512]))",
      "text":"Skipped _param_constant138: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 512, 50, 50]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 512, 50, 50])\n## Return values\nTensor(f32[1, 512, 50, 50])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 512, 50, 50]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for gelu_9. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.gelu.default)[call_function]:Tensor(f32[1, 512, 50, 50])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'gelu', [0], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument convolution_36 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 512, 50, 50])",
      "text":"Type promotion not needed for gelu_9. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 512, 50, 50]): Cannot find type promotion rule for op: aten.clone.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 512, 50, 50])\n## Return values\nTensor(f32[1, 512, 50, 50])",
      "text":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 512, 50, 50]): Cannot find type promotion rule for op: aten.clone.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant139: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant139)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128, 512, 1, 1]))",
      "text":"Skipped _param_constant139: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant140: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant140)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128]))",
      "text":"Skipped _param_constant140: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 128, 50, 50]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 128, 50, 50])\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 128, 50, 50]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 128, 50, 50]): Cannot find type promotion rule for op: aten.clone.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 128, 50, 50])\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 128, 50, 50]): Cannot find type promotion rule for op: aten.clone.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant141: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant141)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128, 1, 1]))",
      "text":"Skipped _param_constant141: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for mul_11. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.mul.Tensor)[call_function]:Tensor(f32[1, 128, 50, 50])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'mul', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument clone_11 is not promoted. Already torch.float32.\nArgument _param_constant141 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Type promotion not needed for mul_11. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_38. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 128, 50, 50])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_37 is not promoted. Already torch.float32.\nArgument mul_11 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Type promotion not needed for add_38. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant142: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant142)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128]))",
      "text":"Skipped _param_constant142: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant143: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant143)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128]))",
      "text":"Skipped _param_constant143: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant80: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant80)[get_attr]:None\n## Return values\nTensor(f32[128])",
      "text":"Skipped _tensor_constant80: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant81: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant81)[get_attr]:None\n## Return values\nTensor(f32[128])",
      "text":"Skipped _tensor_constant81: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50])\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant144: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant144)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128, 1, 1, 1]))",
      "text":"Skipped _param_constant144: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 128, 50, 50]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 128, 50, 50])\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 128, 50, 50]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant145: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant145)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128]))",
      "text":"Skipped _param_constant145: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant146: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant146)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128]))",
      "text":"Skipped _param_constant146: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant82: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant82)[get_attr]:None\n## Return values\nTensor(f32[128])",
      "text":"Skipped _tensor_constant82: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant83: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant83)[get_attr]:None\n## Return values\nTensor(f32[128])",
      "text":"Skipped _tensor_constant83: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50])\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_39. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 128, 50, 50])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument getitem_123 is not promoted. Already torch.float32.\nArgument getitem_120 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Type promotion not needed for add_39. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant147: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant147)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128, 1, 3, 3]))",
      "text":"Skipped _param_constant147: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 128, 50, 50]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 128, 50, 50])\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 128, 50, 50]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant148: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant148)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128]))",
      "text":"Skipped _param_constant148: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant149: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant149)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128]))",
      "text":"Skipped _param_constant149: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant84: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant84)[get_attr]:None\n## Return values\nTensor(f32[128])",
      "text":"Skipped _tensor_constant84: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant85: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant85)[get_attr]:None\n## Return values\nTensor(f32[128])",
      "text":"Skipped _tensor_constant85: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50])\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_40. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 128, 50, 50])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_39 is not promoted. Already torch.float32.\nArgument getitem_126 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Type promotion not needed for add_40. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant150: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant150)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128]))",
      "text":"Skipped _param_constant150: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant151: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant151)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128]))",
      "text":"Skipped _param_constant151: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant86: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant86)[get_attr]:None\n## Return values\nTensor(f32[128])",
      "text":"Skipped _tensor_constant86: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant87: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant87)[get_attr]:None\n## Return values\nTensor(f32[128])",
      "text":"Skipped _tensor_constant87: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50])\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Applied type promotion for add_41. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 128, 50, 50])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument getitem_129 is not promoted. Already torch.float32.\nArgument 0(Scalar of equivalent dtype: torch.int64) is promoted to torch.float32.\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Applied type promotion for add_41. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for sub_6. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.sub.Tensor)[call_function]:Tensor(f32[1, 128, 50, 50])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'sub', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_40 is not promoted. Already torch.float32.\nArgument add_41 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Type promotion not needed for sub_6. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant152: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant152)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128, 1, 1]))",
      "text":"Skipped _param_constant152: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for mul_12. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.mul.Tensor)[call_function]:Tensor(f32[1, 128, 50, 50])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'mul', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument sub_6 is not promoted. Already torch.float32.\nArgument _param_constant152 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Type promotion not needed for mul_12. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_42. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 128, 50, 50])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_38 is not promoted. Already torch.float32.\nArgument mul_12 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Type promotion not needed for add_42. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant153: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant153)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128, 1, 7, 7]))",
      "text":"Skipped _param_constant153: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 128, 50, 50]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 128, 50, 50])\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 128, 50, 50]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant154: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant154)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128]))",
      "text":"Skipped _param_constant154: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant155: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant155)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128]))",
      "text":"Skipped _param_constant155: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant88: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant88)[get_attr]:None\n## Return values\nTensor(f32[128])",
      "text":"Skipped _tensor_constant88: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant89: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant89)[get_attr]:None\n## Return values\nTensor(f32[128])",
      "text":"Skipped _tensor_constant89: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50])\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant156: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant156)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512, 128, 1, 1]))",
      "text":"Skipped _param_constant156: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant157: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant157)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512]))",
      "text":"Skipped _param_constant157: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 512, 50, 50]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 512, 50, 50])\n## Return values\nTensor(f32[1, 512, 50, 50])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 512, 50, 50]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for gelu_10. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.gelu.default)[call_function]:Tensor(f32[1, 512, 50, 50])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'gelu', [0], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument convolution_41 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 512, 50, 50])",
      "text":"Type promotion not needed for gelu_10. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 512, 50, 50]): Cannot find type promotion rule for op: aten.clone.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 512, 50, 50])\n## Return values\nTensor(f32[1, 512, 50, 50])",
      "text":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 512, 50, 50]): Cannot find type promotion rule for op: aten.clone.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant158: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant158)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128, 512, 1, 1]))",
      "text":"Skipped _param_constant158: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant159: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant159)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128]))",
      "text":"Skipped _param_constant159: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 128, 50, 50]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 128, 50, 50])\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 128, 50, 50]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 128, 50, 50]): Cannot find type promotion rule for op: aten.clone.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 128, 50, 50])\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 128, 50, 50]): Cannot find type promotion rule for op: aten.clone.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant160: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant160)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128, 1, 1]))",
      "text":"Skipped _param_constant160: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for mul_13. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.mul.Tensor)[call_function]:Tensor(f32[1, 128, 50, 50])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'mul', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument clone_13 is not promoted. Already torch.float32.\nArgument _param_constant160 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Type promotion not needed for mul_13. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_43. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 128, 50, 50])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_42 is not promoted. Already torch.float32.\nArgument mul_13 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Type promotion not needed for add_43. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant161: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant161)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128]))",
      "text":"Skipped _param_constant161: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant162: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant162)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128]))",
      "text":"Skipped _param_constant162: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant90: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant90)[get_attr]:None\n## Return values\nTensor(f32[128])",
      "text":"Skipped _tensor_constant90: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant91: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant91)[get_attr]:None\n## Return values\nTensor(f32[128])",
      "text":"Skipped _tensor_constant91: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50])\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant163: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant163)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128, 1, 1, 1]))",
      "text":"Skipped _param_constant163: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 128, 50, 50]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 128, 50, 50])\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 128, 50, 50]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant164: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant164)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128]))",
      "text":"Skipped _param_constant164: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant165: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant165)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128]))",
      "text":"Skipped _param_constant165: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant92: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant92)[get_attr]:None\n## Return values\nTensor(f32[128])",
      "text":"Skipped _tensor_constant92: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant93: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant93)[get_attr]:None\n## Return values\nTensor(f32[128])",
      "text":"Skipped _tensor_constant93: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50])\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_44. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 128, 50, 50])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument getitem_138 is not promoted. Already torch.float32.\nArgument getitem_135 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Type promotion not needed for add_44. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant166: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant166)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128, 1, 3, 3]))",
      "text":"Skipped _param_constant166: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 128, 50, 50]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 128, 50, 50])\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 128, 50, 50]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant167: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant167)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128]))",
      "text":"Skipped _param_constant167: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant168: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant168)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128]))",
      "text":"Skipped _param_constant168: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant94: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant94)[get_attr]:None\n## Return values\nTensor(f32[128])",
      "text":"Skipped _tensor_constant94: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant95: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant95)[get_attr]:None\n## Return values\nTensor(f32[128])",
      "text":"Skipped _tensor_constant95: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50])\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_45. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 128, 50, 50])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_44 is not promoted. Already torch.float32.\nArgument getitem_141 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Type promotion not needed for add_45. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant169: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant169)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128]))",
      "text":"Skipped _param_constant169: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant170: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant170)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128]))",
      "text":"Skipped _param_constant170: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant96: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant96)[get_attr]:None\n## Return values\nTensor(f32[128])",
      "text":"Skipped _tensor_constant96: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant97: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant97)[get_attr]:None\n## Return values\nTensor(f32[128])",
      "text":"Skipped _tensor_constant97: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50])\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Applied type promotion for add_46. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 128, 50, 50])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument getitem_144 is not promoted. Already torch.float32.\nArgument 0(Scalar of equivalent dtype: torch.int64) is promoted to torch.float32.\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Applied type promotion for add_46. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for sub_7. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.sub.Tensor)[call_function]:Tensor(f32[1, 128, 50, 50])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'sub', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_45 is not promoted. Already torch.float32.\nArgument add_46 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Type promotion not needed for sub_7. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant171: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant171)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128, 1, 1]))",
      "text":"Skipped _param_constant171: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for mul_14. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.mul.Tensor)[call_function]:Tensor(f32[1, 128, 50, 50])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'mul', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument sub_7 is not promoted. Already torch.float32.\nArgument _param_constant171 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Type promotion not needed for mul_14. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_47. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 128, 50, 50])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_43 is not promoted. Already torch.float32.\nArgument mul_14 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Type promotion not needed for add_47. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant172: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant172)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128, 1, 7, 7]))",
      "text":"Skipped _param_constant172: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 128, 50, 50]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 128, 50, 50])\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 128, 50, 50]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant173: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant173)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128]))",
      "text":"Skipped _param_constant173: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant174: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant174)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128]))",
      "text":"Skipped _param_constant174: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant98: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant98)[get_attr]:None\n## Return values\nTensor(f32[128])",
      "text":"Skipped _tensor_constant98: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant99: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant99)[get_attr]:None\n## Return values\nTensor(f32[128])",
      "text":"Skipped _tensor_constant99: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 128, 50, 50]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50])\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 128, 50, 50]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant175: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant175)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512, 128, 1, 1]))",
      "text":"Skipped _param_constant175: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant176: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant176)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512]))",
      "text":"Skipped _param_constant176: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 512, 50, 50]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 512, 50, 50])\n## Return values\nTensor(f32[1, 512, 50, 50])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 512, 50, 50]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for gelu_11. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.gelu.default)[call_function]:Tensor(f32[1, 512, 50, 50])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'gelu', [0], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument convolution_46 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 512, 50, 50])",
      "text":"Type promotion not needed for gelu_11. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 512, 50, 50]): Cannot find type promotion rule for op: aten.clone.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 512, 50, 50])\n## Return values\nTensor(f32[1, 512, 50, 50])",
      "text":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 512, 50, 50]): Cannot find type promotion rule for op: aten.clone.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant177: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant177)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128, 512, 1, 1]))",
      "text":"Skipped _param_constant177: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant178: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant178)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128]))",
      "text":"Skipped _param_constant178: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 128, 50, 50]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 128, 50, 50])\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 128, 50, 50]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 128, 50, 50]): Cannot find type promotion rule for op: aten.clone.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 128, 50, 50])\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 128, 50, 50]): Cannot find type promotion rule for op: aten.clone.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant179: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant179)[get_attr]:None\n## Return values\nParameter(Tensor(f32[128, 1, 1]))",
      "text":"Skipped _param_constant179: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for mul_15. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.mul.Tensor)[call_function]:Tensor(f32[1, 128, 50, 50])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'mul', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument clone_15 is not promoted. Already torch.float32.\nArgument _param_constant179 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Type promotion not needed for mul_15. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_48. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 128, 50, 50])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_47 is not promoted. Already torch.float32.\nArgument mul_15 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 128, 50, 50])",
      "text":"Type promotion not needed for add_48. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant180: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant180)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1, 7, 7]))",
      "text":"Skipped _param_constant180: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant181: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant181)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant181: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant182: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant182)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant182: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant100: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant100)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant100: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant101: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant101)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant101: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant183: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant183)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1, 3, 3]))",
      "text":"Skipped _param_constant183: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant184: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant184)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant184: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant185: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant185)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant185: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant102: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant102)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant102: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant103: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant103)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant103: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_49. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument getitem_150 is not promoted. Already torch.float32.\nArgument getitem_153 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for add_49. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant186: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant186)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant186: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant187: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant187)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant187: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant104: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant104)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant104: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant105: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant105)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant105: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Applied type promotion for add_50. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument getitem_156 is not promoted. Already torch.float32.\nArgument 0(Scalar of equivalent dtype: torch.int64) is promoted to torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Applied type promotion for add_50. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant188: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant188)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 256, 1, 1]))",
      "text":"Skipped _param_constant188: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant189: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant189)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant189: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant190: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant190)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant190: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant106: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant106)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant106: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant107: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant107)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant107: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_51. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_50 is not promoted. Already torch.float32.\nArgument getitem_159 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for add_51. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for gelu_12. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.gelu.default)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'gelu', [0], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_51 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for gelu_12. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant191: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant191)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant191: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant192: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant192)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant192: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant108: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant108)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant108: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant109: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant109)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant109: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant193: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant193)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1, 1, 1]))",
      "text":"Skipped _param_constant193: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant194: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant194)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant194: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant195: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant195)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant195: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant110: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant110)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant110: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant111: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant111)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant111: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_52. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument getitem_165 is not promoted. Already torch.float32.\nArgument getitem_162 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for add_52. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant196: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant196)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1, 3, 3]))",
      "text":"Skipped _param_constant196: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant197: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant197)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant197: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant198: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant198)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant198: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant112: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant112)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant112: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant113: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant113)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant113: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_53. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_52 is not promoted. Already torch.float32.\nArgument getitem_168 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for add_53. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant199: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant199)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant199: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant200: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant200)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant200: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant114: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant114)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant114: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant115: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant115)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant115: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Applied type promotion for add_54. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument getitem_171 is not promoted. Already torch.float32.\nArgument 0(Scalar of equivalent dtype: torch.int64) is promoted to torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Applied type promotion for add_54. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for sub_8. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.sub.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'sub', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_53 is not promoted. Already torch.float32.\nArgument add_54 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for sub_8. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant201: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant201)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1, 1]))",
      "text":"Skipped _param_constant201: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for mul_16. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.mul.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'mul', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument sub_8 is not promoted. Already torch.float32.\nArgument _param_constant201 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for mul_16. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_55. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument gelu_12 is not promoted. Already torch.float32.\nArgument mul_16 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for add_55. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant202: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant202)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1, 7, 7]))",
      "text":"Skipped _param_constant202: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant203: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant203)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant203: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant204: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant204)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant204: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant116: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant116)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant116: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant117: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant117)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant117: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant205: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant205)[get_attr]:None\n## Return values\nParameter(Tensor(f32[1024, 256, 1, 1]))",
      "text":"Skipped _param_constant205: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant206: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant206)[get_attr]:None\n## Return values\nParameter(Tensor(f32[1024]))",
      "text":"Skipped _param_constant206: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 1024, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 1024, 25, 25])\n## Return values\nTensor(f32[1, 1024, 25, 25])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 1024, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for gelu_13. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.gelu.default)[call_function]:Tensor(f32[1, 1024, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'gelu', [0], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument convolution_54 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 1024, 25, 25])",
      "text":"Type promotion not needed for gelu_13. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 1024, 25, 25]): Cannot find type promotion rule for op: aten.clone.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 1024, 25, 25])\n## Return values\nTensor(f32[1, 1024, 25, 25])",
      "text":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 1024, 25, 25]): Cannot find type promotion rule for op: aten.clone.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant207: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant207)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1024, 1, 1]))",
      "text":"Skipped _param_constant207: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant208: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant208)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant208: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.clone.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.clone.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant209: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant209)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1, 1]))",
      "text":"Skipped _param_constant209: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for mul_17. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.mul.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'mul', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument clone_17 is not promoted. Already torch.float32.\nArgument _param_constant209 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for mul_17. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_56. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_55 is not promoted. Already torch.float32.\nArgument mul_17 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for add_56. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant210: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant210)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant210: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant211: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant211)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant211: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant118: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant118)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant118: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant119: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant119)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant119: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant212: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant212)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1, 1, 1]))",
      "text":"Skipped _param_constant212: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant213: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant213)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant213: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant214: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant214)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant214: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant120: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant120)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant120: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant121: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant121)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant121: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_57. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument getitem_180 is not promoted. Already torch.float32.\nArgument getitem_177 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for add_57. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant215: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant215)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1, 3, 3]))",
      "text":"Skipped _param_constant215: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant216: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant216)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant216: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant217: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant217)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant217: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant122: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant122)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant122: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant123: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant123)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant123: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_58. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_57 is not promoted. Already torch.float32.\nArgument getitem_183 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for add_58. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant218: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant218)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant218: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant219: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant219)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant219: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant124: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant124)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant124: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant125: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant125)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant125: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Applied type promotion for add_59. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument getitem_186 is not promoted. Already torch.float32.\nArgument 0(Scalar of equivalent dtype: torch.int64) is promoted to torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Applied type promotion for add_59. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for sub_9. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.sub.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'sub', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_58 is not promoted. Already torch.float32.\nArgument add_59 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for sub_9. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant220: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant220)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1, 1]))",
      "text":"Skipped _param_constant220: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for mul_18. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.mul.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'mul', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument sub_9 is not promoted. Already torch.float32.\nArgument _param_constant220 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for mul_18. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_60. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_56 is not promoted. Already torch.float32.\nArgument mul_18 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for add_60. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant221: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant221)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1, 7, 7]))",
      "text":"Skipped _param_constant221: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant222: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant222)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant222: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant223: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant223)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant223: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant126: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant126)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant126: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant127: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant127)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant127: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant224: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant224)[get_attr]:None\n## Return values\nParameter(Tensor(f32[1024, 256, 1, 1]))",
      "text":"Skipped _param_constant224: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant225: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant225)[get_attr]:None\n## Return values\nParameter(Tensor(f32[1024]))",
      "text":"Skipped _param_constant225: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 1024, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 1024, 25, 25])\n## Return values\nTensor(f32[1, 1024, 25, 25])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 1024, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for gelu_14. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.gelu.default)[call_function]:Tensor(f32[1, 1024, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'gelu', [0], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument convolution_59 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 1024, 25, 25])",
      "text":"Type promotion not needed for gelu_14. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 1024, 25, 25]): Cannot find type promotion rule for op: aten.clone.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 1024, 25, 25])\n## Return values\nTensor(f32[1, 1024, 25, 25])",
      "text":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 1024, 25, 25]): Cannot find type promotion rule for op: aten.clone.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant226: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant226)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1024, 1, 1]))",
      "text":"Skipped _param_constant226: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant227: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant227)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant227: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.clone.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.clone.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant228: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant228)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1, 1]))",
      "text":"Skipped _param_constant228: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for mul_19. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.mul.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'mul', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument clone_19 is not promoted. Already torch.float32.\nArgument _param_constant228 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for mul_19. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_61. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_60 is not promoted. Already torch.float32.\nArgument mul_19 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for add_61. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant229: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant229)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant229: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant230: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant230)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant230: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant128: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant128)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant128: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant129: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant129)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant129: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant231: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant231)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1, 1, 1]))",
      "text":"Skipped _param_constant231: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant232: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant232)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant232: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant233: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant233)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant233: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant130: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant130)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant130: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant131: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant131)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant131: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_62. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument getitem_195 is not promoted. Already torch.float32.\nArgument getitem_192 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for add_62. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant234: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant234)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1, 3, 3]))",
      "text":"Skipped _param_constant234: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant235: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant235)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant235: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant236: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant236)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant236: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant132: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant132)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant132: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant133: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant133)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant133: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_63. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_62 is not promoted. Already torch.float32.\nArgument getitem_198 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for add_63. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant237: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant237)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant237: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant238: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant238)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant238: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant134: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant134)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant134: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant135: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant135)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant135: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Applied type promotion for add_64. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument getitem_201 is not promoted. Already torch.float32.\nArgument 0(Scalar of equivalent dtype: torch.int64) is promoted to torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Applied type promotion for add_64. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for sub_10. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.sub.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'sub', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_63 is not promoted. Already torch.float32.\nArgument add_64 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for sub_10. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant239: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant239)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1, 1]))",
      "text":"Skipped _param_constant239: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for mul_20. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.mul.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'mul', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument sub_10 is not promoted. Already torch.float32.\nArgument _param_constant239 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for mul_20. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_65. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_61 is not promoted. Already torch.float32.\nArgument mul_20 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for add_65. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant240: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant240)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1, 7, 7]))",
      "text":"Skipped _param_constant240: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant241: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant241)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant241: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant242: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant242)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant242: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant136: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant136)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant136: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant137: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant137)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant137: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant243: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant243)[get_attr]:None\n## Return values\nParameter(Tensor(f32[1024, 256, 1, 1]))",
      "text":"Skipped _param_constant243: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant244: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant244)[get_attr]:None\n## Return values\nParameter(Tensor(f32[1024]))",
      "text":"Skipped _param_constant244: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 1024, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 1024, 25, 25])\n## Return values\nTensor(f32[1, 1024, 25, 25])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 1024, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for gelu_15. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.gelu.default)[call_function]:Tensor(f32[1, 1024, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'gelu', [0], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument convolution_64 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 1024, 25, 25])",
      "text":"Type promotion not needed for gelu_15. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 1024, 25, 25]): Cannot find type promotion rule for op: aten.clone.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 1024, 25, 25])\n## Return values\nTensor(f32[1, 1024, 25, 25])",
      "text":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 1024, 25, 25]): Cannot find type promotion rule for op: aten.clone.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant245: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant245)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1024, 1, 1]))",
      "text":"Skipped _param_constant245: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant246: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant246)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant246: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.clone.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.clone.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant247: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant247)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1, 1]))",
      "text":"Skipped _param_constant247: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for mul_21. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.mul.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'mul', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument clone_21 is not promoted. Already torch.float32.\nArgument _param_constant247 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for mul_21. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_66. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_65 is not promoted. Already torch.float32.\nArgument mul_21 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for add_66. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant248: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant248)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant248: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant249: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant249)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant249: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant138: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant138)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant138: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant139: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant139)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant139: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant250: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant250)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1, 1, 1]))",
      "text":"Skipped _param_constant250: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant251: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant251)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant251: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant252: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant252)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant252: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant140: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant140)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant140: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant141: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant141)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant141: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_67. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument getitem_210 is not promoted. Already torch.float32.\nArgument getitem_207 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for add_67. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant253: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant253)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1, 3, 3]))",
      "text":"Skipped _param_constant253: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant254: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant254)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant254: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant255: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant255)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant255: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant142: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant142)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant142: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant143: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant143)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant143: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_68. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_67 is not promoted. Already torch.float32.\nArgument getitem_213 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for add_68. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant256: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant256)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant256: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant257: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant257)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant257: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant144: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant144)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant144: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant145: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant145)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant145: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Applied type promotion for add_69. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument getitem_216 is not promoted. Already torch.float32.\nArgument 0(Scalar of equivalent dtype: torch.int64) is promoted to torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Applied type promotion for add_69. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for sub_11. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.sub.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'sub', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_68 is not promoted. Already torch.float32.\nArgument add_69 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for sub_11. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant258: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant258)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1, 1]))",
      "text":"Skipped _param_constant258: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for mul_22. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.mul.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'mul', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument sub_11 is not promoted. Already torch.float32.\nArgument _param_constant258 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for mul_22. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_70. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_66 is not promoted. Already torch.float32.\nArgument mul_22 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for add_70. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant259: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant259)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1, 7, 7]))",
      "text":"Skipped _param_constant259: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant260: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant260)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant260: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant261: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant261)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant261: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant146: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant146)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant146: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant147: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant147)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant147: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant262: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant262)[get_attr]:None\n## Return values\nParameter(Tensor(f32[1024, 256, 1, 1]))",
      "text":"Skipped _param_constant262: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant263: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant263)[get_attr]:None\n## Return values\nParameter(Tensor(f32[1024]))",
      "text":"Skipped _param_constant263: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 1024, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 1024, 25, 25])\n## Return values\nTensor(f32[1, 1024, 25, 25])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 1024, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for gelu_16. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.gelu.default)[call_function]:Tensor(f32[1, 1024, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'gelu', [0], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument convolution_69 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 1024, 25, 25])",
      "text":"Type promotion not needed for gelu_16. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 1024, 25, 25]): Cannot find type promotion rule for op: aten.clone.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 1024, 25, 25])\n## Return values\nTensor(f32[1, 1024, 25, 25])",
      "text":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 1024, 25, 25]): Cannot find type promotion rule for op: aten.clone.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant264: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant264)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1024, 1, 1]))",
      "text":"Skipped _param_constant264: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant265: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant265)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant265: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.clone.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.clone.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant266: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant266)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1, 1]))",
      "text":"Skipped _param_constant266: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for mul_23. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.mul.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'mul', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument clone_23 is not promoted. Already torch.float32.\nArgument _param_constant266 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for mul_23. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_71. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_70 is not promoted. Already torch.float32.\nArgument mul_23 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for add_71. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant267: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant267)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant267: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant268: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant268)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant268: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant148: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant148)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant148: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant149: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant149)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant149: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant269: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant269)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1, 1, 1]))",
      "text":"Skipped _param_constant269: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant270: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant270)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant270: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant271: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant271)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant271: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant150: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant150)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant150: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant151: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant151)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant151: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_72. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument getitem_225 is not promoted. Already torch.float32.\nArgument getitem_222 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for add_72. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant272: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant272)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1, 3, 3]))",
      "text":"Skipped _param_constant272: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant273: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant273)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant273: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant274: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant274)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant274: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant152: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant152)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant152: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant153: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant153)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant153: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_73. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_72 is not promoted. Already torch.float32.\nArgument getitem_228 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for add_73. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant275: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant275)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant275: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant276: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant276)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant276: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant154: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant154)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant154: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant155: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant155)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant155: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Applied type promotion for add_74. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument getitem_231 is not promoted. Already torch.float32.\nArgument 0(Scalar of equivalent dtype: torch.int64) is promoted to torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Applied type promotion for add_74. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for sub_12. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.sub.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'sub', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_73 is not promoted. Already torch.float32.\nArgument add_74 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for sub_12. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant277: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant277)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1, 1]))",
      "text":"Skipped _param_constant277: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for mul_24. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.mul.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'mul', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument sub_12 is not promoted. Already torch.float32.\nArgument _param_constant277 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for mul_24. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_75. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_71 is not promoted. Already torch.float32.\nArgument mul_24 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for add_75. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant278: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant278)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1, 7, 7]))",
      "text":"Skipped _param_constant278: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant279: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant279)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant279: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant280: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant280)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant280: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant156: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant156)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant156: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant157: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant157)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant157: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant281: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant281)[get_attr]:None\n## Return values\nParameter(Tensor(f32[1024, 256, 1, 1]))",
      "text":"Skipped _param_constant281: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant282: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant282)[get_attr]:None\n## Return values\nParameter(Tensor(f32[1024]))",
      "text":"Skipped _param_constant282: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 1024, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 1024, 25, 25])\n## Return values\nTensor(f32[1, 1024, 25, 25])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 1024, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for gelu_17. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.gelu.default)[call_function]:Tensor(f32[1, 1024, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'gelu', [0], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument convolution_74 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 1024, 25, 25])",
      "text":"Type promotion not needed for gelu_17. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 1024, 25, 25]): Cannot find type promotion rule for op: aten.clone.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 1024, 25, 25])\n## Return values\nTensor(f32[1, 1024, 25, 25])",
      "text":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 1024, 25, 25]): Cannot find type promotion rule for op: aten.clone.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant283: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant283)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1024, 1, 1]))",
      "text":"Skipped _param_constant283: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant284: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant284)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant284: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.clone.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.clone.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant285: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant285)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1, 1]))",
      "text":"Skipped _param_constant285: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for mul_25. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.mul.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'mul', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument clone_25 is not promoted. Already torch.float32.\nArgument _param_constant285 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for mul_25. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_76. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_75 is not promoted. Already torch.float32.\nArgument mul_25 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for add_76. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant286: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant286)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant286: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant287: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant287)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant287: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant158: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant158)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant158: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant159: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant159)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant159: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant288: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant288)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1, 1, 1]))",
      "text":"Skipped _param_constant288: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant289: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant289)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant289: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant290: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant290)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant290: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant160: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant160)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant160: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant161: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant161)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant161: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_77. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument getitem_240 is not promoted. Already torch.float32.\nArgument getitem_237 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for add_77. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant291: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant291)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1, 3, 3]))",
      "text":"Skipped _param_constant291: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant292: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant292)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant292: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant293: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant293)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant293: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant162: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant162)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant162: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant163: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant163)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant163: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_78. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_77 is not promoted. Already torch.float32.\nArgument getitem_243 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for add_78. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant294: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant294)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant294: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant295: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant295)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant295: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant164: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant164)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant164: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant165: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant165)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant165: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Applied type promotion for add_79. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument getitem_246 is not promoted. Already torch.float32.\nArgument 0(Scalar of equivalent dtype: torch.int64) is promoted to torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Applied type promotion for add_79. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for sub_13. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.sub.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'sub', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_78 is not promoted. Already torch.float32.\nArgument add_79 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for sub_13. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant296: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant296)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1, 1]))",
      "text":"Skipped _param_constant296: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for mul_26. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.mul.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'mul', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument sub_13 is not promoted. Already torch.float32.\nArgument _param_constant296 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for mul_26. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_80. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_76 is not promoted. Already torch.float32.\nArgument mul_26 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for add_80. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant297: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant297)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1, 7, 7]))",
      "text":"Skipped _param_constant297: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant298: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant298)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant298: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant299: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant299)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant299: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant166: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant166)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant166: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant167: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant167)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant167: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant300: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant300)[get_attr]:None\n## Return values\nParameter(Tensor(f32[1024, 256, 1, 1]))",
      "text":"Skipped _param_constant300: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant301: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant301)[get_attr]:None\n## Return values\nParameter(Tensor(f32[1024]))",
      "text":"Skipped _param_constant301: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 1024, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 1024, 25, 25])\n## Return values\nTensor(f32[1, 1024, 25, 25])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 1024, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for gelu_18. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.gelu.default)[call_function]:Tensor(f32[1, 1024, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'gelu', [0], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument convolution_79 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 1024, 25, 25])",
      "text":"Type promotion not needed for gelu_18. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 1024, 25, 25]): Cannot find type promotion rule for op: aten.clone.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 1024, 25, 25])\n## Return values\nTensor(f32[1, 1024, 25, 25])",
      "text":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 1024, 25, 25]): Cannot find type promotion rule for op: aten.clone.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant302: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant302)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1024, 1, 1]))",
      "text":"Skipped _param_constant302: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant303: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant303)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant303: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.clone.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.clone.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant304: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant304)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1, 1]))",
      "text":"Skipped _param_constant304: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for mul_27. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.mul.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'mul', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument clone_27 is not promoted. Already torch.float32.\nArgument _param_constant304 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for mul_27. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_81. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_80 is not promoted. Already torch.float32.\nArgument mul_27 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for add_81. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant305: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant305)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant305: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant306: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant306)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant306: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant168: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant168)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant168: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant169: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant169)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant169: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant307: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant307)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1, 1, 1]))",
      "text":"Skipped _param_constant307: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant308: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant308)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant308: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant309: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant309)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant309: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant170: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant170)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant170: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant171: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant171)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant171: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_82. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument getitem_255 is not promoted. Already torch.float32.\nArgument getitem_252 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for add_82. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant310: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant310)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1, 3, 3]))",
      "text":"Skipped _param_constant310: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant311: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant311)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant311: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant312: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant312)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant312: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant172: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant172)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant172: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant173: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant173)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant173: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_83. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_82 is not promoted. Already torch.float32.\nArgument getitem_258 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for add_83. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant313: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant313)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant313: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant314: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant314)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant314: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant174: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant174)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant174: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant175: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant175)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant175: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Applied type promotion for add_84. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument getitem_261 is not promoted. Already torch.float32.\nArgument 0(Scalar of equivalent dtype: torch.int64) is promoted to torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Applied type promotion for add_84. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for sub_14. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.sub.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'sub', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_83 is not promoted. Already torch.float32.\nArgument add_84 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for sub_14. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant315: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant315)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1, 1]))",
      "text":"Skipped _param_constant315: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for mul_28. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.mul.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'mul', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument sub_14 is not promoted. Already torch.float32.\nArgument _param_constant315 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for mul_28. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_85. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_81 is not promoted. Already torch.float32.\nArgument mul_28 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for add_85. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant316: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant316)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1, 7, 7]))",
      "text":"Skipped _param_constant316: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant317: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant317)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant317: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant318: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant318)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant318: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant176: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant176)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant176: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant177: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant177)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant177: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant319: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant319)[get_attr]:None\n## Return values\nParameter(Tensor(f32[1024, 256, 1, 1]))",
      "text":"Skipped _param_constant319: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant320: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant320)[get_attr]:None\n## Return values\nParameter(Tensor(f32[1024]))",
      "text":"Skipped _param_constant320: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 1024, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 1024, 25, 25])\n## Return values\nTensor(f32[1, 1024, 25, 25])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 1024, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for gelu_19. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.gelu.default)[call_function]:Tensor(f32[1, 1024, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'gelu', [0], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument convolution_84 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 1024, 25, 25])",
      "text":"Type promotion not needed for gelu_19. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 1024, 25, 25]): Cannot find type promotion rule for op: aten.clone.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 1024, 25, 25])\n## Return values\nTensor(f32[1, 1024, 25, 25])",
      "text":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 1024, 25, 25]): Cannot find type promotion rule for op: aten.clone.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant321: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant321)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1024, 1, 1]))",
      "text":"Skipped _param_constant321: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant322: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant322)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant322: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.clone.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.clone.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant323: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant323)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1, 1]))",
      "text":"Skipped _param_constant323: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for mul_29. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.mul.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'mul', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument clone_29 is not promoted. Already torch.float32.\nArgument _param_constant323 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for mul_29. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_86. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_85 is not promoted. Already torch.float32.\nArgument mul_29 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for add_86. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant324: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant324)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant324: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant325: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant325)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant325: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant178: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant178)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant178: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant179: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant179)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant179: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant326: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant326)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1, 1, 1]))",
      "text":"Skipped _param_constant326: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant327: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant327)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant327: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant328: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant328)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant328: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant180: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant180)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant180: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant181: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant181)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant181: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_87. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument getitem_270 is not promoted. Already torch.float32.\nArgument getitem_267 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for add_87. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant329: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant329)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1, 3, 3]))",
      "text":"Skipped _param_constant329: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant330: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant330)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant330: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant331: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant331)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant331: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant182: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant182)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant182: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant183: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant183)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant183: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_88. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_87 is not promoted. Already torch.float32.\nArgument getitem_273 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for add_88. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant332: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant332)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant332: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant333: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant333)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant333: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant184: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant184)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant184: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant185: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant185)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant185: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Applied type promotion for add_89. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument getitem_276 is not promoted. Already torch.float32.\nArgument 0(Scalar of equivalent dtype: torch.int64) is promoted to torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Applied type promotion for add_89. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for sub_15. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.sub.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'sub', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_88 is not promoted. Already torch.float32.\nArgument add_89 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for sub_15. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant334: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant334)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1, 1]))",
      "text":"Skipped _param_constant334: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for mul_30. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.mul.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'mul', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument sub_15 is not promoted. Already torch.float32.\nArgument _param_constant334 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for mul_30. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_90. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_86 is not promoted. Already torch.float32.\nArgument mul_30 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for add_90. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant335: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant335)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1, 7, 7]))",
      "text":"Skipped _param_constant335: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant336: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant336)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant336: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant337: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant337)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant337: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant186: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant186)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant186: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant187: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant187)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant187: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant338: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant338)[get_attr]:None\n## Return values\nParameter(Tensor(f32[1024, 256, 1, 1]))",
      "text":"Skipped _param_constant338: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant339: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant339)[get_attr]:None\n## Return values\nParameter(Tensor(f32[1024]))",
      "text":"Skipped _param_constant339: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 1024, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 1024, 25, 25])\n## Return values\nTensor(f32[1, 1024, 25, 25])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 1024, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for gelu_20. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.gelu.default)[call_function]:Tensor(f32[1, 1024, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'gelu', [0], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument convolution_89 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 1024, 25, 25])",
      "text":"Type promotion not needed for gelu_20. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 1024, 25, 25]): Cannot find type promotion rule for op: aten.clone.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 1024, 25, 25])\n## Return values\nTensor(f32[1, 1024, 25, 25])",
      "text":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 1024, 25, 25]): Cannot find type promotion rule for op: aten.clone.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant340: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant340)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1024, 1, 1]))",
      "text":"Skipped _param_constant340: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant341: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant341)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant341: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.clone.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.clone.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant342: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant342)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1, 1]))",
      "text":"Skipped _param_constant342: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for mul_31. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.mul.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'mul', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument clone_31 is not promoted. Already torch.float32.\nArgument _param_constant342 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for mul_31. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_91. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_90 is not promoted. Already torch.float32.\nArgument mul_31 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for add_91. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant343: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant343)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant343: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant344: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant344)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant344: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant188: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant188)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant188: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant189: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant189)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant189: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant345: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant345)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1, 1, 1]))",
      "text":"Skipped _param_constant345: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant346: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant346)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant346: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant347: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant347)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant347: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant190: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant190)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant190: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant191: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant191)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant191: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_92. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument getitem_285 is not promoted. Already torch.float32.\nArgument getitem_282 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for add_92. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant348: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant348)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1, 3, 3]))",
      "text":"Skipped _param_constant348: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant349: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant349)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant349: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant350: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant350)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant350: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant192: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant192)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant192: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant193: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant193)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant193: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_93. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_92 is not promoted. Already torch.float32.\nArgument getitem_288 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for add_93. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant351: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant351)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant351: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant352: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant352)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant352: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant194: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant194)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant194: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant195: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant195)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant195: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Applied type promotion for add_94. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument getitem_291 is not promoted. Already torch.float32.\nArgument 0(Scalar of equivalent dtype: torch.int64) is promoted to torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Applied type promotion for add_94. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for sub_16. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.sub.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'sub', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_93 is not promoted. Already torch.float32.\nArgument add_94 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for sub_16. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant353: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant353)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1, 1]))",
      "text":"Skipped _param_constant353: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for mul_32. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.mul.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'mul', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument sub_16 is not promoted. Already torch.float32.\nArgument _param_constant353 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for mul_32. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_95. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_91 is not promoted. Already torch.float32.\nArgument mul_32 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for add_95. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant354: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant354)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1, 7, 7]))",
      "text":"Skipped _param_constant354: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant355: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant355)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant355: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant356: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant356)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant356: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant196: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant196)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant196: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant197: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant197)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant197: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant357: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant357)[get_attr]:None\n## Return values\nParameter(Tensor(f32[1024, 256, 1, 1]))",
      "text":"Skipped _param_constant357: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant358: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant358)[get_attr]:None\n## Return values\nParameter(Tensor(f32[1024]))",
      "text":"Skipped _param_constant358: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 1024, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 1024, 25, 25])\n## Return values\nTensor(f32[1, 1024, 25, 25])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 1024, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for gelu_21. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.gelu.default)[call_function]:Tensor(f32[1, 1024, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'gelu', [0], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument convolution_94 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 1024, 25, 25])",
      "text":"Type promotion not needed for gelu_21. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 1024, 25, 25]): Cannot find type promotion rule for op: aten.clone.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 1024, 25, 25])\n## Return values\nTensor(f32[1, 1024, 25, 25])",
      "text":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 1024, 25, 25]): Cannot find type promotion rule for op: aten.clone.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant359: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant359)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1024, 1, 1]))",
      "text":"Skipped _param_constant359: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant360: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant360)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant360: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.clone.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.clone.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant361: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant361)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1, 1]))",
      "text":"Skipped _param_constant361: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for mul_33. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.mul.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'mul', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument clone_33 is not promoted. Already torch.float32.\nArgument _param_constant361 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for mul_33. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_96. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_95 is not promoted. Already torch.float32.\nArgument mul_33 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for add_96. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant362: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant362)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant362: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant363: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant363)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant363: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant198: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant198)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant198: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant199: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant199)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant199: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant364: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant364)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1, 1, 1]))",
      "text":"Skipped _param_constant364: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant365: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant365)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant365: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant366: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant366)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant366: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant200: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant200)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant200: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant201: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant201)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant201: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_97. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument getitem_300 is not promoted. Already torch.float32.\nArgument getitem_297 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for add_97. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant367: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant367)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1, 3, 3]))",
      "text":"Skipped _param_constant367: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant368: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant368)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant368: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant369: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant369)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant369: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant202: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant202)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant202: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant203: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant203)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant203: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_98. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_97 is not promoted. Already torch.float32.\nArgument getitem_303 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for add_98. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant370: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant370)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant370: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant371: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant371)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant371: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant204: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant204)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant204: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant205: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant205)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant205: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Applied type promotion for add_99. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument getitem_306 is not promoted. Already torch.float32.\nArgument 0(Scalar of equivalent dtype: torch.int64) is promoted to torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Applied type promotion for add_99. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for sub_17. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.sub.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'sub', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_98 is not promoted. Already torch.float32.\nArgument add_99 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for sub_17. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant372: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant372)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1, 1]))",
      "text":"Skipped _param_constant372: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for mul_34. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.mul.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'mul', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument sub_17 is not promoted. Already torch.float32.\nArgument _param_constant372 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for mul_34. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_100. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_96 is not promoted. Already torch.float32.\nArgument mul_34 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for add_100. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant373: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant373)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1, 7, 7]))",
      "text":"Skipped _param_constant373: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant374: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant374)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant374: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant375: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant375)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant375: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant206: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant206)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant206: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant207: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant207)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant207: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant376: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant376)[get_attr]:None\n## Return values\nParameter(Tensor(f32[1024, 256, 1, 1]))",
      "text":"Skipped _param_constant376: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant377: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant377)[get_attr]:None\n## Return values\nParameter(Tensor(f32[1024]))",
      "text":"Skipped _param_constant377: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 1024, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 1024, 25, 25])\n## Return values\nTensor(f32[1, 1024, 25, 25])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 1024, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for gelu_22. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.gelu.default)[call_function]:Tensor(f32[1, 1024, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'gelu', [0], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument convolution_99 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 1024, 25, 25])",
      "text":"Type promotion not needed for gelu_22. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 1024, 25, 25]): Cannot find type promotion rule for op: aten.clone.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 1024, 25, 25])\n## Return values\nTensor(f32[1, 1024, 25, 25])",
      "text":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 1024, 25, 25]): Cannot find type promotion rule for op: aten.clone.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant378: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant378)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1024, 1, 1]))",
      "text":"Skipped _param_constant378: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant379: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant379)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant379: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.clone.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.clone.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant380: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant380)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1, 1]))",
      "text":"Skipped _param_constant380: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for mul_35. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.mul.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'mul', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument clone_35 is not promoted. Already torch.float32.\nArgument _param_constant380 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for mul_35. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_101. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_100 is not promoted. Already torch.float32.\nArgument mul_35 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for add_101. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant381: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant381)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant381: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant382: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant382)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant382: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant208: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant208)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant208: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant209: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant209)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant209: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant383: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant383)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1, 1, 1]))",
      "text":"Skipped _param_constant383: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant384: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant384)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant384: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant385: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant385)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant385: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant210: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant210)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant210: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant211: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant211)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant211: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_102. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument getitem_315 is not promoted. Already torch.float32.\nArgument getitem_312 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for add_102. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant386: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant386)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1, 3, 3]))",
      "text":"Skipped _param_constant386: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant387: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant387)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant387: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant388: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant388)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant388: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant212: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant212)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant212: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant213: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant213)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant213: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_103. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_102 is not promoted. Already torch.float32.\nArgument getitem_318 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for add_103. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant389: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant389)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant389: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant390: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant390)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant390: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant214: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant214)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant214: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant215: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant215)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant215: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Applied type promotion for add_104. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument getitem_321 is not promoted. Already torch.float32.\nArgument 0(Scalar of equivalent dtype: torch.int64) is promoted to torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Applied type promotion for add_104. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for sub_18. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.sub.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'sub', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_103 is not promoted. Already torch.float32.\nArgument add_104 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for sub_18. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant391: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant391)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1, 1]))",
      "text":"Skipped _param_constant391: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for mul_36. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.mul.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'mul', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument sub_18 is not promoted. Already torch.float32.\nArgument _param_constant391 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for mul_36. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_105. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_101 is not promoted. Already torch.float32.\nArgument mul_36 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for add_105. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant392: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant392)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1, 7, 7]))",
      "text":"Skipped _param_constant392: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant393: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant393)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant393: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant394: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant394)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant394: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant216: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant216)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant216: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant217: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant217)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant217: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant395: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant395)[get_attr]:None\n## Return values\nParameter(Tensor(f32[1024, 256, 1, 1]))",
      "text":"Skipped _param_constant395: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant396: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant396)[get_attr]:None\n## Return values\nParameter(Tensor(f32[1024]))",
      "text":"Skipped _param_constant396: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 1024, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 1024, 25, 25])\n## Return values\nTensor(f32[1, 1024, 25, 25])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 1024, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for gelu_23. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.gelu.default)[call_function]:Tensor(f32[1, 1024, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'gelu', [0], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument convolution_104 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 1024, 25, 25])",
      "text":"Type promotion not needed for gelu_23. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 1024, 25, 25]): Cannot find type promotion rule for op: aten.clone.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 1024, 25, 25])\n## Return values\nTensor(f32[1, 1024, 25, 25])",
      "text":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 1024, 25, 25]): Cannot find type promotion rule for op: aten.clone.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant397: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant397)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1024, 1, 1]))",
      "text":"Skipped _param_constant397: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant398: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant398)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant398: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.clone.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.clone.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant399: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant399)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1, 1]))",
      "text":"Skipped _param_constant399: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for mul_37. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.mul.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'mul', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument clone_37 is not promoted. Already torch.float32.\nArgument _param_constant399 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for mul_37. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_106. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_105 is not promoted. Already torch.float32.\nArgument mul_37 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for add_106. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant400: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant400)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant400: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant401: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant401)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant401: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant218: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant218)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant218: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant219: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant219)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant219: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant402: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant402)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1, 1, 1]))",
      "text":"Skipped _param_constant402: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant403: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant403)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant403: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant404: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant404)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant404: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant220: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant220)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant220: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant221: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant221)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant221: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_107. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument getitem_330 is not promoted. Already torch.float32.\nArgument getitem_327 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for add_107. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant405: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant405)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1, 3, 3]))",
      "text":"Skipped _param_constant405: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant406: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant406)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant406: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant407: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant407)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant407: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant222: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant222)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant222: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant223: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant223)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant223: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_108. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_107 is not promoted. Already torch.float32.\nArgument getitem_333 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for add_108. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant408: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant408)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant408: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant409: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant409)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant409: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant224: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant224)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant224: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant225: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant225)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant225: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Applied type promotion for add_109. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument getitem_336 is not promoted. Already torch.float32.\nArgument 0(Scalar of equivalent dtype: torch.int64) is promoted to torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Applied type promotion for add_109. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for sub_19. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.sub.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'sub', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_108 is not promoted. Already torch.float32.\nArgument add_109 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for sub_19. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant410: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant410)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1, 1]))",
      "text":"Skipped _param_constant410: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for mul_38. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.mul.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'mul', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument sub_19 is not promoted. Already torch.float32.\nArgument _param_constant410 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for mul_38. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_110. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_106 is not promoted. Already torch.float32.\nArgument mul_38 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for add_110. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant411: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant411)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1, 7, 7]))",
      "text":"Skipped _param_constant411: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant412: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant412)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant412: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant413: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant413)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant413: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant226: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant226)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant226: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant227: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant227)[get_attr]:None\n## Return values\nTensor(f32[256])",
      "text":"Skipped _tensor_constant227: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 256, 25, 25]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 256, 25, 25]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant414: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant414)[get_attr]:None\n## Return values\nParameter(Tensor(f32[1024, 256, 1, 1]))",
      "text":"Skipped _param_constant414: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant415: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant415)[get_attr]:None\n## Return values\nParameter(Tensor(f32[1024]))",
      "text":"Skipped _param_constant415: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 1024, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 1024, 25, 25])\n## Return values\nTensor(f32[1, 1024, 25, 25])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 1024, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for gelu_24. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.gelu.default)[call_function]:Tensor(f32[1, 1024, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'gelu', [0], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument convolution_109 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 1024, 25, 25])",
      "text":"Type promotion not needed for gelu_24. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 1024, 25, 25]): Cannot find type promotion rule for op: aten.clone.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 1024, 25, 25])\n## Return values\nTensor(f32[1, 1024, 25, 25])",
      "text":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 1024, 25, 25]): Cannot find type promotion rule for op: aten.clone.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant416: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant416)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1024, 1, 1]))",
      "text":"Skipped _param_constant416: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant417: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant417)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256]))",
      "text":"Skipped _param_constant417: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.clone.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 256, 25, 25])\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 256, 25, 25]): Cannot find type promotion rule for op: aten.clone.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant418: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant418)[get_attr]:None\n## Return values\nParameter(Tensor(f32[256, 1, 1]))",
      "text":"Skipped _param_constant418: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for mul_39. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.mul.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'mul', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument clone_39 is not promoted. Already torch.float32.\nArgument _param_constant418 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for mul_39. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_111. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 256, 25, 25])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_110 is not promoted. Already torch.float32.\nArgument mul_39 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 256, 25, 25])",
      "text":"Type promotion not needed for add_111. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant419: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant419)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512, 1, 7, 7]))",
      "text":"Skipped _param_constant419: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 512, 13, 13]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 512, 13, 13])\n## Return values\nTensor(f32[1, 512, 13, 13])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 512, 13, 13]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant420: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant420)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512]))",
      "text":"Skipped _param_constant420: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant421: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant421)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512]))",
      "text":"Skipped _param_constant421: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant228: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant228)[get_attr]:None\n## Return values\nTensor(f32[512])",
      "text":"Skipped _tensor_constant228: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant229: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant229)[get_attr]:None\n## Return values\nTensor(f32[512])",
      "text":"Skipped _tensor_constant229: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 512, 13, 13]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 512, 13, 13]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 512, 13, 13]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 512, 13, 13]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 512, 13, 13]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 512, 13, 13])\n## Return values\nTensor(f32[1, 512, 13, 13])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 512, 13, 13]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant422: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant422)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512, 1, 3, 3]))",
      "text":"Skipped _param_constant422: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 512, 13, 13]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 512, 13, 13])\n## Return values\nTensor(f32[1, 512, 13, 13])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 512, 13, 13]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant423: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant423)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512]))",
      "text":"Skipped _param_constant423: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant424: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant424)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512]))",
      "text":"Skipped _param_constant424: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant230: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant230)[get_attr]:None\n## Return values\nTensor(f32[512])",
      "text":"Skipped _tensor_constant230: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant231: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant231)[get_attr]:None\n## Return values\nTensor(f32[512])",
      "text":"Skipped _tensor_constant231: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 512, 13, 13]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 512, 13, 13]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 512, 13, 13]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 512, 13, 13]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 512, 13, 13]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 512, 13, 13])\n## Return values\nTensor(f32[1, 512, 13, 13])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 512, 13, 13]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_112. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 512, 13, 13])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument getitem_342 is not promoted. Already torch.float32.\nArgument getitem_345 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 512, 13, 13])",
      "text":"Type promotion not needed for add_112. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant425: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant425)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512]))",
      "text":"Skipped _param_constant425: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant426: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant426)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512]))",
      "text":"Skipped _param_constant426: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant232: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant232)[get_attr]:None\n## Return values\nTensor(f32[512])",
      "text":"Skipped _tensor_constant232: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant233: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant233)[get_attr]:None\n## Return values\nTensor(f32[512])",
      "text":"Skipped _tensor_constant233: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 512, 13, 13]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 512, 13, 13]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 512, 13, 13]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 512, 13, 13]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 512, 13, 13]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 512, 13, 13])\n## Return values\nTensor(f32[1, 512, 13, 13])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 512, 13, 13]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Applied type promotion for add_113. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 512, 13, 13])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument getitem_348 is not promoted. Already torch.float32.\nArgument 0(Scalar of equivalent dtype: torch.int64) is promoted to torch.float32.\n## Return values\nTensor(f32[1, 512, 13, 13])",
      "text":"Applied type promotion for add_113. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant427: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant427)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512, 512, 1, 1]))",
      "text":"Skipped _param_constant427: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 512, 13, 13]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 512, 13, 13])\n## Return values\nTensor(f32[1, 512, 13, 13])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 512, 13, 13]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant428: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant428)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512]))",
      "text":"Skipped _param_constant428: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant429: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant429)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512]))",
      "text":"Skipped _param_constant429: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant234: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant234)[get_attr]:None\n## Return values\nTensor(f32[512])",
      "text":"Skipped _tensor_constant234: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant235: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant235)[get_attr]:None\n## Return values\nTensor(f32[512])",
      "text":"Skipped _tensor_constant235: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 512, 13, 13]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 512, 13, 13]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 512, 13, 13]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 512, 13, 13]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 512, 13, 13]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 512, 13, 13])\n## Return values\nTensor(f32[1, 512, 13, 13])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 512, 13, 13]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_114. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 512, 13, 13])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_113 is not promoted. Already torch.float32.\nArgument getitem_351 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 512, 13, 13])",
      "text":"Type promotion not needed for add_114. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for gelu_25. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.gelu.default)[call_function]:Tensor(f32[1, 512, 13, 13])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'gelu', [0], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_114 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 512, 13, 13])",
      "text":"Type promotion not needed for gelu_25. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant430: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant430)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512, 1, 7, 7]))",
      "text":"Skipped _param_constant430: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant431: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant431)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512]))",
      "text":"Skipped _param_constant431: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 512, 13, 13]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 512, 13, 13])\n## Return values\nTensor(f32[1, 512, 13, 13])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 512, 13, 13]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_115. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 512, 13, 13])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument convolution_114 is not promoted. Already torch.float32.\nArgument gelu_25 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 512, 13, 13])",
      "text":"Type promotion not needed for add_115. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant432: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant432)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512]))",
      "text":"Skipped _param_constant432: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant433: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant433)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512]))",
      "text":"Skipped _param_constant433: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant236: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant236)[get_attr]:None\n## Return values\nTensor(f32[512])",
      "text":"Skipped _tensor_constant236: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant237: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant237)[get_attr]:None\n## Return values\nTensor(f32[512])",
      "text":"Skipped _tensor_constant237: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 512, 13, 13]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 512, 13, 13]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 512, 13, 13]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 512, 13, 13]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 512, 13, 13]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 512, 13, 13])\n## Return values\nTensor(f32[1, 512, 13, 13])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 512, 13, 13]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.view.default)[call_function]:Tensor(f32[1, 512, 169]): Cannot find type promotion rule for op: aten.view.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.view.default)[call_function]:Tensor(f32[1, 512, 169])\n## Return values\nTensor(f32[1, 512, 169])",
      "text":"Skipped for fx.Node(aten.view.default)[call_function]:Tensor(f32[1, 512, 169]): Cannot find type promotion rule for op: aten.view.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.transpose.int)[call_function]:Tensor(f32[1, 169, 512]): Cannot find type promotion rule for op: aten.transpose.int\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.transpose.int)[call_function]:Tensor(f32[1, 169, 512])\n## Return values\nTensor(f32[1, 169, 512])",
      "text":"Skipped for fx.Node(aten.transpose.int)[call_function]:Tensor(f32[1, 169, 512]): Cannot find type promotion rule for op: aten.transpose.int"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant434: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant434)[get_attr]:None\n## Return values\nParameter(Tensor(f32[1536, 512]))",
      "text":"Skipped _param_constant434: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.t.default)[call_function]:Tensor(f32[512, 1536]): Cannot find type promotion rule for op: aten.t.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.t.default)[call_function]:Tensor(f32[512, 1536])\n## Return values\nTensor(f32[512, 1536])",
      "text":"Skipped for fx.Node(aten.t.default)[call_function]:Tensor(f32[512, 1536]): Cannot find type promotion rule for op: aten.t.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.view.default)[call_function]:Tensor(f32[169, 512]): Cannot find type promotion rule for op: aten.view.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.view.default)[call_function]:Tensor(f32[169, 512])\n## Return values\nTensor(f32[169, 512])",
      "text":"Skipped for fx.Node(aten.view.default)[call_function]:Tensor(f32[169, 512]): Cannot find type promotion rule for op: aten.view.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.mm.default)[call_function]:Tensor(f32[169, 1536]): Cannot find type promotion rule for op: aten.mm.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.mm.default)[call_function]:Tensor(f32[169, 1536])\n## Return values\nTensor(f32[169, 1536])",
      "text":"Skipped for fx.Node(aten.mm.default)[call_function]:Tensor(f32[169, 1536]): Cannot find type promotion rule for op: aten.mm.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._unsafe_view.default)[call_function]:Tensor(f32[1, 169, 1536]): Cannot find type promotion rule for op: aten._unsafe_view.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._unsafe_view.default)[call_function]:Tensor(f32[1, 169, 1536])\n## Return values\nTensor(f32[1, 169, 1536])",
      "text":"Skipped for fx.Node(aten._unsafe_view.default)[call_function]:Tensor(f32[1, 169, 1536]): Cannot find type promotion rule for op: aten._unsafe_view.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.view.default)[call_function]:Tensor(f32[1, 169, 3, 16, 32]): Cannot find type promotion rule for op: aten.view.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.view.default)[call_function]:Tensor(f32[1, 169, 3, 16, 32])\n## Return values\nTensor(f32[1, 169, 3, 16, 32])",
      "text":"Skipped for fx.Node(aten.view.default)[call_function]:Tensor(f32[1, 169, 3, 16, 32]): Cannot find type promotion rule for op: aten.view.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.permute.default)[call_function]:Tensor(f32[3, 1, 16, 169, 32]): Cannot find type promotion rule for op: aten.permute.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.permute.default)[call_function]:Tensor(f32[3, 1, 16, 169, 32])\n## Return values\nTensor(f32[3, 1, 16, 169, 32])",
      "text":"Skipped for fx.Node(aten.permute.default)[call_function]:Tensor(f32[3, 1, 16, 169, 32]): Cannot find type promotion rule for op: aten.permute.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.unbind.int)[call_function]:List[length=3](\nTensor(f32[1, 16, 169, 32]),\nTensor(f32[1, 16, 169, 32]),\nTensor(f32[1, 16, 169, 32]),\n): Cannot find type promotion rule for op: aten.unbind.int\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.unbind.int)[call_function]:List[length=3](\nTensor(f32[1, 16, 169, 32]),\nTensor(f32[1, 16, 169, 32]),\nTensor(f32[1, 16, 169, 32]),\n)\n## Return values\nList[length=3](\nTensor(f32[1, 16, 169, 32]),\nTensor(f32[1, 16, 169, 32]),\nTensor(f32[1, 16, 169, 32]),\n)",
      "text":"Skipped for fx.Node(aten.unbind.int)[call_function]:List[length=3](\nTensor(f32[1, 16, 169, 32]),\nTensor(f32[1, 16, 169, 32]),\nTensor(f32[1, 16, 169, 32]),\n): Cannot find type promotion rule for op: aten.unbind.int"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 16, 169, 32]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 16, 169, 32])\n## Return values\nTensor(f32[1, 16, 169, 32])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 16, 169, 32]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 16, 169, 32]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 16, 169, 32])\n## Return values\nTensor(f32[1, 16, 169, 32])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 16, 169, 32]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 16, 169, 32]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 16, 169, 32])\n## Return values\nTensor(f32[1, 16, 169, 32])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 16, 169, 32]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._scaled_dot_product_flash_attention_for_cpu.default)[call_function]:Tuple[length=2](\nTensor(f32[1, 16, 169, 32]),\nTensor(f32[1, 16, 169]),\n): Cannot find type promotion rule for op: aten._scaled_dot_product_flash_attention_for_cpu.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._scaled_dot_product_flash_attention_for_cpu.default)[call_function]:Tuple[length=2](\nTensor(f32[1, 16, 169, 32]),\nTensor(f32[1, 16, 169]),\n)\n## Return values\nTuple[length=2](\nTensor(f32[1, 16, 169, 32]),\nTensor(f32[1, 16, 169]),\n)",
      "text":"Skipped for fx.Node(aten._scaled_dot_product_flash_attention_for_cpu.default)[call_function]:Tuple[length=2](\nTensor(f32[1, 16, 169, 32]),\nTensor(f32[1, 16, 169]),\n): Cannot find type promotion rule for op: aten._scaled_dot_product_flash_attention_for_cpu.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 16, 169, 32]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 16, 169, 32])\n## Return values\nTensor(f32[1, 16, 169, 32])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 16, 169, 32]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 16, 169]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 16, 169])\n## Return values\nTensor(f32[1, 16, 169])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 16, 169]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.transpose.int)[call_function]:Tensor(f32[1, 169, 16, 32]): Cannot find type promotion rule for op: aten.transpose.int\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.transpose.int)[call_function]:Tensor(f32[1, 169, 16, 32])\n## Return values\nTensor(f32[1, 169, 16, 32])",
      "text":"Skipped for fx.Node(aten.transpose.int)[call_function]:Tensor(f32[1, 169, 16, 32]): Cannot find type promotion rule for op: aten.transpose.int"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.view.default)[call_function]:Tensor(f32[1, 169, 512]): Cannot find type promotion rule for op: aten.view.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.view.default)[call_function]:Tensor(f32[1, 169, 512])\n## Return values\nTensor(f32[1, 169, 512])",
      "text":"Skipped for fx.Node(aten.view.default)[call_function]:Tensor(f32[1, 169, 512]): Cannot find type promotion rule for op: aten.view.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.view.default)[call_function]:Tensor(f32[169, 512]): Cannot find type promotion rule for op: aten.view.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.view.default)[call_function]:Tensor(f32[169, 512])\n## Return values\nTensor(f32[169, 512])",
      "text":"Skipped for fx.Node(aten.view.default)[call_function]:Tensor(f32[169, 512]): Cannot find type promotion rule for op: aten.view.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant435: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant435)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512, 512]))",
      "text":"Skipped _param_constant435: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.t.default)[call_function]:Tensor(f32[512, 512]): Cannot find type promotion rule for op: aten.t.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.t.default)[call_function]:Tensor(f32[512, 512])\n## Return values\nTensor(f32[512, 512])",
      "text":"Skipped for fx.Node(aten.t.default)[call_function]:Tensor(f32[512, 512]): Cannot find type promotion rule for op: aten.t.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant436: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant436)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512]))",
      "text":"Skipped _param_constant436: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.addmm.default)[call_function]:Tensor(f32[169, 512]): Cannot find type promotion rule for op: aten.addmm.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.addmm.default)[call_function]:Tensor(f32[169, 512])\n## Return values\nTensor(f32[169, 512])",
      "text":"Skipped for fx.Node(aten.addmm.default)[call_function]:Tensor(f32[169, 512]): Cannot find type promotion rule for op: aten.addmm.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.view.default)[call_function]:Tensor(f32[1, 169, 512]): Cannot find type promotion rule for op: aten.view.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.view.default)[call_function]:Tensor(f32[1, 169, 512])\n## Return values\nTensor(f32[1, 169, 512])",
      "text":"Skipped for fx.Node(aten.view.default)[call_function]:Tensor(f32[1, 169, 512]): Cannot find type promotion rule for op: aten.view.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 169, 512]): Cannot find type promotion rule for op: aten.clone.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 169, 512])\n## Return values\nTensor(f32[1, 169, 512])",
      "text":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 169, 512]): Cannot find type promotion rule for op: aten.clone.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.transpose.int)[call_function]:Tensor(f32[1, 512, 169]): Cannot find type promotion rule for op: aten.transpose.int\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.transpose.int)[call_function]:Tensor(f32[1, 512, 169])\n## Return values\nTensor(f32[1, 512, 169])",
      "text":"Skipped for fx.Node(aten.transpose.int)[call_function]:Tensor(f32[1, 512, 169]): Cannot find type promotion rule for op: aten.transpose.int"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.view.default)[call_function]:Tensor(f32[1, 512, 13, 13]): Cannot find type promotion rule for op: aten.view.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.view.default)[call_function]:Tensor(f32[1, 512, 13, 13])\n## Return values\nTensor(f32[1, 512, 13, 13])",
      "text":"Skipped for fx.Node(aten.view.default)[call_function]:Tensor(f32[1, 512, 13, 13]): Cannot find type promotion rule for op: aten.view.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant437: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant437)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512, 1, 1]))",
      "text":"Skipped _param_constant437: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for mul_40. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.mul.Tensor)[call_function]:Tensor(f32[1, 512, 13, 13])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'mul', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument view_6 is not promoted. Already torch.float32.\nArgument _param_constant437 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 512, 13, 13])",
      "text":"Type promotion not needed for mul_40. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_116. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 512, 13, 13])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_115 is not promoted. Already torch.float32.\nArgument mul_40 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 512, 13, 13])",
      "text":"Type promotion not needed for add_116. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant438: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant438)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512, 1, 7, 7]))",
      "text":"Skipped _param_constant438: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 512, 13, 13]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 512, 13, 13])\n## Return values\nTensor(f32[1, 512, 13, 13])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 512, 13, 13]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant439: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant439)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512]))",
      "text":"Skipped _param_constant439: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant440: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant440)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512]))",
      "text":"Skipped _param_constant440: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant238: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant238)[get_attr]:None\n## Return values\nTensor(f32[512])",
      "text":"Skipped _tensor_constant238: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant239: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant239)[get_attr]:None\n## Return values\nTensor(f32[512])",
      "text":"Skipped _tensor_constant239: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 512, 13, 13]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 512, 13, 13]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 512, 13, 13]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 512, 13, 13]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 512, 13, 13]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 512, 13, 13])\n## Return values\nTensor(f32[1, 512, 13, 13])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 512, 13, 13]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant441: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant441)[get_attr]:None\n## Return values\nParameter(Tensor(f32[2048, 512, 1, 1]))",
      "text":"Skipped _param_constant441: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant442: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant442)[get_attr]:None\n## Return values\nParameter(Tensor(f32[2048]))",
      "text":"Skipped _param_constant442: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 2048, 13, 13]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 2048, 13, 13])\n## Return values\nTensor(f32[1, 2048, 13, 13])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 2048, 13, 13]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for gelu_26. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.gelu.default)[call_function]:Tensor(f32[1, 2048, 13, 13])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'gelu', [0], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument convolution_116 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 2048, 13, 13])",
      "text":"Type promotion not needed for gelu_26. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 2048, 13, 13]): Cannot find type promotion rule for op: aten.clone.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 2048, 13, 13])\n## Return values\nTensor(f32[1, 2048, 13, 13])",
      "text":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 2048, 13, 13]): Cannot find type promotion rule for op: aten.clone.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant443: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant443)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512, 2048, 1, 1]))",
      "text":"Skipped _param_constant443: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant444: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant444)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512]))",
      "text":"Skipped _param_constant444: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 512, 13, 13]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 512, 13, 13])\n## Return values\nTensor(f32[1, 512, 13, 13])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 512, 13, 13]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 512, 13, 13]): Cannot find type promotion rule for op: aten.clone.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 512, 13, 13])\n## Return values\nTensor(f32[1, 512, 13, 13])",
      "text":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 512, 13, 13]): Cannot find type promotion rule for op: aten.clone.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant445: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant445)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512, 1, 1]))",
      "text":"Skipped _param_constant445: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for mul_41. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.mul.Tensor)[call_function]:Tensor(f32[1, 512, 13, 13])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'mul', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument clone_42 is not promoted. Already torch.float32.\nArgument _param_constant445 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 512, 13, 13])",
      "text":"Type promotion not needed for mul_41. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_117. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 512, 13, 13])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_116 is not promoted. Already torch.float32.\nArgument mul_41 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 512, 13, 13])",
      "text":"Type promotion not needed for add_117. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant446: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant446)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512]))",
      "text":"Skipped _param_constant446: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant447: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant447)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512]))",
      "text":"Skipped _param_constant447: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant240: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant240)[get_attr]:None\n## Return values\nTensor(f32[512])",
      "text":"Skipped _tensor_constant240: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant241: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant241)[get_attr]:None\n## Return values\nTensor(f32[512])",
      "text":"Skipped _tensor_constant241: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 512, 13, 13]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 512, 13, 13]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 512, 13, 13]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 512, 13, 13]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 512, 13, 13]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 512, 13, 13])\n## Return values\nTensor(f32[1, 512, 13, 13])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 512, 13, 13]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.view.default)[call_function]:Tensor(f32[1, 512, 169]): Cannot find type promotion rule for op: aten.view.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.view.default)[call_function]:Tensor(f32[1, 512, 169])\n## Return values\nTensor(f32[1, 512, 169])",
      "text":"Skipped for fx.Node(aten.view.default)[call_function]:Tensor(f32[1, 512, 169]): Cannot find type promotion rule for op: aten.view.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.transpose.int)[call_function]:Tensor(f32[1, 169, 512]): Cannot find type promotion rule for op: aten.transpose.int\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.transpose.int)[call_function]:Tensor(f32[1, 169, 512])\n## Return values\nTensor(f32[1, 169, 512])",
      "text":"Skipped for fx.Node(aten.transpose.int)[call_function]:Tensor(f32[1, 169, 512]): Cannot find type promotion rule for op: aten.transpose.int"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant448: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant448)[get_attr]:None\n## Return values\nParameter(Tensor(f32[1536, 512]))",
      "text":"Skipped _param_constant448: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.t.default)[call_function]:Tensor(f32[512, 1536]): Cannot find type promotion rule for op: aten.t.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.t.default)[call_function]:Tensor(f32[512, 1536])\n## Return values\nTensor(f32[512, 1536])",
      "text":"Skipped for fx.Node(aten.t.default)[call_function]:Tensor(f32[512, 1536]): Cannot find type promotion rule for op: aten.t.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.view.default)[call_function]:Tensor(f32[169, 512]): Cannot find type promotion rule for op: aten.view.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.view.default)[call_function]:Tensor(f32[169, 512])\n## Return values\nTensor(f32[169, 512])",
      "text":"Skipped for fx.Node(aten.view.default)[call_function]:Tensor(f32[169, 512]): Cannot find type promotion rule for op: aten.view.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.mm.default)[call_function]:Tensor(f32[169, 1536]): Cannot find type promotion rule for op: aten.mm.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.mm.default)[call_function]:Tensor(f32[169, 1536])\n## Return values\nTensor(f32[169, 1536])",
      "text":"Skipped for fx.Node(aten.mm.default)[call_function]:Tensor(f32[169, 1536]): Cannot find type promotion rule for op: aten.mm.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._unsafe_view.default)[call_function]:Tensor(f32[1, 169, 1536]): Cannot find type promotion rule for op: aten._unsafe_view.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._unsafe_view.default)[call_function]:Tensor(f32[1, 169, 1536])\n## Return values\nTensor(f32[1, 169, 1536])",
      "text":"Skipped for fx.Node(aten._unsafe_view.default)[call_function]:Tensor(f32[1, 169, 1536]): Cannot find type promotion rule for op: aten._unsafe_view.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.view.default)[call_function]:Tensor(f32[1, 169, 3, 16, 32]): Cannot find type promotion rule for op: aten.view.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.view.default)[call_function]:Tensor(f32[1, 169, 3, 16, 32])\n## Return values\nTensor(f32[1, 169, 3, 16, 32])",
      "text":"Skipped for fx.Node(aten.view.default)[call_function]:Tensor(f32[1, 169, 3, 16, 32]): Cannot find type promotion rule for op: aten.view.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.permute.default)[call_function]:Tensor(f32[3, 1, 16, 169, 32]): Cannot find type promotion rule for op: aten.permute.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.permute.default)[call_function]:Tensor(f32[3, 1, 16, 169, 32])\n## Return values\nTensor(f32[3, 1, 16, 169, 32])",
      "text":"Skipped for fx.Node(aten.permute.default)[call_function]:Tensor(f32[3, 1, 16, 169, 32]): Cannot find type promotion rule for op: aten.permute.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.unbind.int)[call_function]:List[length=3](\nTensor(f32[1, 16, 169, 32]),\nTensor(f32[1, 16, 169, 32]),\nTensor(f32[1, 16, 169, 32]),\n): Cannot find type promotion rule for op: aten.unbind.int\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.unbind.int)[call_function]:List[length=3](\nTensor(f32[1, 16, 169, 32]),\nTensor(f32[1, 16, 169, 32]),\nTensor(f32[1, 16, 169, 32]),\n)\n## Return values\nList[length=3](\nTensor(f32[1, 16, 169, 32]),\nTensor(f32[1, 16, 169, 32]),\nTensor(f32[1, 16, 169, 32]),\n)",
      "text":"Skipped for fx.Node(aten.unbind.int)[call_function]:List[length=3](\nTensor(f32[1, 16, 169, 32]),\nTensor(f32[1, 16, 169, 32]),\nTensor(f32[1, 16, 169, 32]),\n): Cannot find type promotion rule for op: aten.unbind.int"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 16, 169, 32]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 16, 169, 32])\n## Return values\nTensor(f32[1, 16, 169, 32])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 16, 169, 32]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 16, 169, 32]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 16, 169, 32])\n## Return values\nTensor(f32[1, 16, 169, 32])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 16, 169, 32]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 16, 169, 32]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 16, 169, 32])\n## Return values\nTensor(f32[1, 16, 169, 32])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 16, 169, 32]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._scaled_dot_product_flash_attention_for_cpu.default)[call_function]:Tuple[length=2](\nTensor(f32[1, 16, 169, 32]),\nTensor(f32[1, 16, 169]),\n): Cannot find type promotion rule for op: aten._scaled_dot_product_flash_attention_for_cpu.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._scaled_dot_product_flash_attention_for_cpu.default)[call_function]:Tuple[length=2](\nTensor(f32[1, 16, 169, 32]),\nTensor(f32[1, 16, 169]),\n)\n## Return values\nTuple[length=2](\nTensor(f32[1, 16, 169, 32]),\nTensor(f32[1, 16, 169]),\n)",
      "text":"Skipped for fx.Node(aten._scaled_dot_product_flash_attention_for_cpu.default)[call_function]:Tuple[length=2](\nTensor(f32[1, 16, 169, 32]),\nTensor(f32[1, 16, 169]),\n): Cannot find type promotion rule for op: aten._scaled_dot_product_flash_attention_for_cpu.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 16, 169, 32]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 16, 169, 32])\n## Return values\nTensor(f32[1, 16, 169, 32])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 16, 169, 32]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 16, 169]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 16, 169])\n## Return values\nTensor(f32[1, 16, 169])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 16, 169]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.transpose.int)[call_function]:Tensor(f32[1, 169, 16, 32]): Cannot find type promotion rule for op: aten.transpose.int\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.transpose.int)[call_function]:Tensor(f32[1, 169, 16, 32])\n## Return values\nTensor(f32[1, 169, 16, 32])",
      "text":"Skipped for fx.Node(aten.transpose.int)[call_function]:Tensor(f32[1, 169, 16, 32]): Cannot find type promotion rule for op: aten.transpose.int"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.view.default)[call_function]:Tensor(f32[1, 169, 512]): Cannot find type promotion rule for op: aten.view.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.view.default)[call_function]:Tensor(f32[1, 169, 512])\n## Return values\nTensor(f32[1, 169, 512])",
      "text":"Skipped for fx.Node(aten.view.default)[call_function]:Tensor(f32[1, 169, 512]): Cannot find type promotion rule for op: aten.view.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.view.default)[call_function]:Tensor(f32[169, 512]): Cannot find type promotion rule for op: aten.view.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.view.default)[call_function]:Tensor(f32[169, 512])\n## Return values\nTensor(f32[169, 512])",
      "text":"Skipped for fx.Node(aten.view.default)[call_function]:Tensor(f32[169, 512]): Cannot find type promotion rule for op: aten.view.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant449: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant449)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512, 512]))",
      "text":"Skipped _param_constant449: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.t.default)[call_function]:Tensor(f32[512, 512]): Cannot find type promotion rule for op: aten.t.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.t.default)[call_function]:Tensor(f32[512, 512])\n## Return values\nTensor(f32[512, 512])",
      "text":"Skipped for fx.Node(aten.t.default)[call_function]:Tensor(f32[512, 512]): Cannot find type promotion rule for op: aten.t.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant450: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant450)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512]))",
      "text":"Skipped _param_constant450: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.addmm.default)[call_function]:Tensor(f32[169, 512]): Cannot find type promotion rule for op: aten.addmm.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.addmm.default)[call_function]:Tensor(f32[169, 512])\n## Return values\nTensor(f32[169, 512])",
      "text":"Skipped for fx.Node(aten.addmm.default)[call_function]:Tensor(f32[169, 512]): Cannot find type promotion rule for op: aten.addmm.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.view.default)[call_function]:Tensor(f32[1, 169, 512]): Cannot find type promotion rule for op: aten.view.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.view.default)[call_function]:Tensor(f32[1, 169, 512])\n## Return values\nTensor(f32[1, 169, 512])",
      "text":"Skipped for fx.Node(aten.view.default)[call_function]:Tensor(f32[1, 169, 512]): Cannot find type promotion rule for op: aten.view.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 169, 512]): Cannot find type promotion rule for op: aten.clone.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 169, 512])\n## Return values\nTensor(f32[1, 169, 512])",
      "text":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 169, 512]): Cannot find type promotion rule for op: aten.clone.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.transpose.int)[call_function]:Tensor(f32[1, 512, 169]): Cannot find type promotion rule for op: aten.transpose.int\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.transpose.int)[call_function]:Tensor(f32[1, 512, 169])\n## Return values\nTensor(f32[1, 512, 169])",
      "text":"Skipped for fx.Node(aten.transpose.int)[call_function]:Tensor(f32[1, 512, 169]): Cannot find type promotion rule for op: aten.transpose.int"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.view.default)[call_function]:Tensor(f32[1, 512, 13, 13]): Cannot find type promotion rule for op: aten.view.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.view.default)[call_function]:Tensor(f32[1, 512, 13, 13])\n## Return values\nTensor(f32[1, 512, 13, 13])",
      "text":"Skipped for fx.Node(aten.view.default)[call_function]:Tensor(f32[1, 512, 13, 13]): Cannot find type promotion rule for op: aten.view.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant451: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant451)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512, 1, 1]))",
      "text":"Skipped _param_constant451: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for mul_42. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.mul.Tensor)[call_function]:Tensor(f32[1, 512, 13, 13])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'mul', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument view_13 is not promoted. Already torch.float32.\nArgument _param_constant451 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 512, 13, 13])",
      "text":"Type promotion not needed for mul_42. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_118. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 512, 13, 13])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_117 is not promoted. Already torch.float32.\nArgument mul_42 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 512, 13, 13])",
      "text":"Type promotion not needed for add_118. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant452: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant452)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512, 1, 7, 7]))",
      "text":"Skipped _param_constant452: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 512, 13, 13]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 512, 13, 13])\n## Return values\nTensor(f32[1, 512, 13, 13])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 512, 13, 13]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant453: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant453)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512]))",
      "text":"Skipped _param_constant453: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant454: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant454)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512]))",
      "text":"Skipped _param_constant454: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant242: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant242)[get_attr]:None\n## Return values\nTensor(f32[512])",
      "text":"Skipped _tensor_constant242: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant243: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant243)[get_attr]:None\n## Return values\nTensor(f32[512])",
      "text":"Skipped _tensor_constant243: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 512, 13, 13]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 512, 13, 13]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 512, 13, 13]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 512, 13, 13]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 512, 13, 13]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 512, 13, 13])\n## Return values\nTensor(f32[1, 512, 13, 13])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 512, 13, 13]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant455: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant455)[get_attr]:None\n## Return values\nParameter(Tensor(f32[2048, 512, 1, 1]))",
      "text":"Skipped _param_constant455: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant456: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant456)[get_attr]:None\n## Return values\nParameter(Tensor(f32[2048]))",
      "text":"Skipped _param_constant456: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 2048, 13, 13]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 2048, 13, 13])\n## Return values\nTensor(f32[1, 2048, 13, 13])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 2048, 13, 13]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for gelu_27. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.gelu.default)[call_function]:Tensor(f32[1, 2048, 13, 13])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'gelu', [0], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument convolution_119 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 2048, 13, 13])",
      "text":"Type promotion not needed for gelu_27. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 2048, 13, 13]): Cannot find type promotion rule for op: aten.clone.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 2048, 13, 13])\n## Return values\nTensor(f32[1, 2048, 13, 13])",
      "text":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 2048, 13, 13]): Cannot find type promotion rule for op: aten.clone.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant457: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant457)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512, 2048, 1, 1]))",
      "text":"Skipped _param_constant457: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant458: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant458)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512]))",
      "text":"Skipped _param_constant458: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 512, 13, 13]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 512, 13, 13])\n## Return values\nTensor(f32[1, 512, 13, 13])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 512, 13, 13]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 512, 13, 13]): Cannot find type promotion rule for op: aten.clone.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 512, 13, 13])\n## Return values\nTensor(f32[1, 512, 13, 13])",
      "text":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 512, 13, 13]): Cannot find type promotion rule for op: aten.clone.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant459: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant459)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512, 1, 1]))",
      "text":"Skipped _param_constant459: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for mul_43. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.mul.Tensor)[call_function]:Tensor(f32[1, 512, 13, 13])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'mul', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument clone_45 is not promoted. Already torch.float32.\nArgument _param_constant459 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 512, 13, 13])",
      "text":"Type promotion not needed for mul_43. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_119. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 512, 13, 13])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_118 is not promoted. Already torch.float32.\nArgument mul_43 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 512, 13, 13])",
      "text":"Type promotion not needed for add_119. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant460: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant460)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512]))",
      "text":"Skipped _param_constant460: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant461: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant461)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512]))",
      "text":"Skipped _param_constant461: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant244: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant244)[get_attr]:None\n## Return values\nTensor(f32[512])",
      "text":"Skipped _tensor_constant244: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant245: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant245)[get_attr]:None\n## Return values\nTensor(f32[512])",
      "text":"Skipped _tensor_constant245: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 512, 13, 13]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 512, 13, 13]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 512, 13, 13]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 512, 13, 13]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 512, 13, 13]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 512, 13, 13])\n## Return values\nTensor(f32[1, 512, 13, 13])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 512, 13, 13]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.view.default)[call_function]:Tensor(f32[1, 512, 169]): Cannot find type promotion rule for op: aten.view.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.view.default)[call_function]:Tensor(f32[1, 512, 169])\n## Return values\nTensor(f32[1, 512, 169])",
      "text":"Skipped for fx.Node(aten.view.default)[call_function]:Tensor(f32[1, 512, 169]): Cannot find type promotion rule for op: aten.view.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.transpose.int)[call_function]:Tensor(f32[1, 169, 512]): Cannot find type promotion rule for op: aten.transpose.int\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.transpose.int)[call_function]:Tensor(f32[1, 169, 512])\n## Return values\nTensor(f32[1, 169, 512])",
      "text":"Skipped for fx.Node(aten.transpose.int)[call_function]:Tensor(f32[1, 169, 512]): Cannot find type promotion rule for op: aten.transpose.int"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant462: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant462)[get_attr]:None\n## Return values\nParameter(Tensor(f32[1536, 512]))",
      "text":"Skipped _param_constant462: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.t.default)[call_function]:Tensor(f32[512, 1536]): Cannot find type promotion rule for op: aten.t.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.t.default)[call_function]:Tensor(f32[512, 1536])\n## Return values\nTensor(f32[512, 1536])",
      "text":"Skipped for fx.Node(aten.t.default)[call_function]:Tensor(f32[512, 1536]): Cannot find type promotion rule for op: aten.t.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.view.default)[call_function]:Tensor(f32[169, 512]): Cannot find type promotion rule for op: aten.view.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.view.default)[call_function]:Tensor(f32[169, 512])\n## Return values\nTensor(f32[169, 512])",
      "text":"Skipped for fx.Node(aten.view.default)[call_function]:Tensor(f32[169, 512]): Cannot find type promotion rule for op: aten.view.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.mm.default)[call_function]:Tensor(f32[169, 1536]): Cannot find type promotion rule for op: aten.mm.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.mm.default)[call_function]:Tensor(f32[169, 1536])\n## Return values\nTensor(f32[169, 1536])",
      "text":"Skipped for fx.Node(aten.mm.default)[call_function]:Tensor(f32[169, 1536]): Cannot find type promotion rule for op: aten.mm.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._unsafe_view.default)[call_function]:Tensor(f32[1, 169, 1536]): Cannot find type promotion rule for op: aten._unsafe_view.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._unsafe_view.default)[call_function]:Tensor(f32[1, 169, 1536])\n## Return values\nTensor(f32[1, 169, 1536])",
      "text":"Skipped for fx.Node(aten._unsafe_view.default)[call_function]:Tensor(f32[1, 169, 1536]): Cannot find type promotion rule for op: aten._unsafe_view.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.view.default)[call_function]:Tensor(f32[1, 169, 3, 16, 32]): Cannot find type promotion rule for op: aten.view.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.view.default)[call_function]:Tensor(f32[1, 169, 3, 16, 32])\n## Return values\nTensor(f32[1, 169, 3, 16, 32])",
      "text":"Skipped for fx.Node(aten.view.default)[call_function]:Tensor(f32[1, 169, 3, 16, 32]): Cannot find type promotion rule for op: aten.view.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.permute.default)[call_function]:Tensor(f32[3, 1, 16, 169, 32]): Cannot find type promotion rule for op: aten.permute.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.permute.default)[call_function]:Tensor(f32[3, 1, 16, 169, 32])\n## Return values\nTensor(f32[3, 1, 16, 169, 32])",
      "text":"Skipped for fx.Node(aten.permute.default)[call_function]:Tensor(f32[3, 1, 16, 169, 32]): Cannot find type promotion rule for op: aten.permute.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.unbind.int)[call_function]:List[length=3](\nTensor(f32[1, 16, 169, 32]),\nTensor(f32[1, 16, 169, 32]),\nTensor(f32[1, 16, 169, 32]),\n): Cannot find type promotion rule for op: aten.unbind.int\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.unbind.int)[call_function]:List[length=3](\nTensor(f32[1, 16, 169, 32]),\nTensor(f32[1, 16, 169, 32]),\nTensor(f32[1, 16, 169, 32]),\n)\n## Return values\nList[length=3](\nTensor(f32[1, 16, 169, 32]),\nTensor(f32[1, 16, 169, 32]),\nTensor(f32[1, 16, 169, 32]),\n)",
      "text":"Skipped for fx.Node(aten.unbind.int)[call_function]:List[length=3](\nTensor(f32[1, 16, 169, 32]),\nTensor(f32[1, 16, 169, 32]),\nTensor(f32[1, 16, 169, 32]),\n): Cannot find type promotion rule for op: aten.unbind.int"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 16, 169, 32]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 16, 169, 32])\n## Return values\nTensor(f32[1, 16, 169, 32])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 16, 169, 32]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 16, 169, 32]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 16, 169, 32])\n## Return values\nTensor(f32[1, 16, 169, 32])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 16, 169, 32]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 16, 169, 32]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 16, 169, 32])\n## Return values\nTensor(f32[1, 16, 169, 32])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 16, 169, 32]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._scaled_dot_product_flash_attention_for_cpu.default)[call_function]:Tuple[length=2](\nTensor(f32[1, 16, 169, 32]),\nTensor(f32[1, 16, 169]),\n): Cannot find type promotion rule for op: aten._scaled_dot_product_flash_attention_for_cpu.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._scaled_dot_product_flash_attention_for_cpu.default)[call_function]:Tuple[length=2](\nTensor(f32[1, 16, 169, 32]),\nTensor(f32[1, 16, 169]),\n)\n## Return values\nTuple[length=2](\nTensor(f32[1, 16, 169, 32]),\nTensor(f32[1, 16, 169]),\n)",
      "text":"Skipped for fx.Node(aten._scaled_dot_product_flash_attention_for_cpu.default)[call_function]:Tuple[length=2](\nTensor(f32[1, 16, 169, 32]),\nTensor(f32[1, 16, 169]),\n): Cannot find type promotion rule for op: aten._scaled_dot_product_flash_attention_for_cpu.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 16, 169, 32]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 16, 169, 32])\n## Return values\nTensor(f32[1, 16, 169, 32])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 16, 169, 32]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 16, 169]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 16, 169])\n## Return values\nTensor(f32[1, 16, 169])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 16, 169]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.transpose.int)[call_function]:Tensor(f32[1, 169, 16, 32]): Cannot find type promotion rule for op: aten.transpose.int\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.transpose.int)[call_function]:Tensor(f32[1, 169, 16, 32])\n## Return values\nTensor(f32[1, 169, 16, 32])",
      "text":"Skipped for fx.Node(aten.transpose.int)[call_function]:Tensor(f32[1, 169, 16, 32]): Cannot find type promotion rule for op: aten.transpose.int"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.view.default)[call_function]:Tensor(f32[1, 169, 512]): Cannot find type promotion rule for op: aten.view.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.view.default)[call_function]:Tensor(f32[1, 169, 512])\n## Return values\nTensor(f32[1, 169, 512])",
      "text":"Skipped for fx.Node(aten.view.default)[call_function]:Tensor(f32[1, 169, 512]): Cannot find type promotion rule for op: aten.view.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.view.default)[call_function]:Tensor(f32[169, 512]): Cannot find type promotion rule for op: aten.view.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.view.default)[call_function]:Tensor(f32[169, 512])\n## Return values\nTensor(f32[169, 512])",
      "text":"Skipped for fx.Node(aten.view.default)[call_function]:Tensor(f32[169, 512]): Cannot find type promotion rule for op: aten.view.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant463: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant463)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512, 512]))",
      "text":"Skipped _param_constant463: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.t.default)[call_function]:Tensor(f32[512, 512]): Cannot find type promotion rule for op: aten.t.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.t.default)[call_function]:Tensor(f32[512, 512])\n## Return values\nTensor(f32[512, 512])",
      "text":"Skipped for fx.Node(aten.t.default)[call_function]:Tensor(f32[512, 512]): Cannot find type promotion rule for op: aten.t.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant464: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant464)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512]))",
      "text":"Skipped _param_constant464: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.addmm.default)[call_function]:Tensor(f32[169, 512]): Cannot find type promotion rule for op: aten.addmm.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.addmm.default)[call_function]:Tensor(f32[169, 512])\n## Return values\nTensor(f32[169, 512])",
      "text":"Skipped for fx.Node(aten.addmm.default)[call_function]:Tensor(f32[169, 512]): Cannot find type promotion rule for op: aten.addmm.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.view.default)[call_function]:Tensor(f32[1, 169, 512]): Cannot find type promotion rule for op: aten.view.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.view.default)[call_function]:Tensor(f32[1, 169, 512])\n## Return values\nTensor(f32[1, 169, 512])",
      "text":"Skipped for fx.Node(aten.view.default)[call_function]:Tensor(f32[1, 169, 512]): Cannot find type promotion rule for op: aten.view.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 169, 512]): Cannot find type promotion rule for op: aten.clone.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 169, 512])\n## Return values\nTensor(f32[1, 169, 512])",
      "text":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 169, 512]): Cannot find type promotion rule for op: aten.clone.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.transpose.int)[call_function]:Tensor(f32[1, 512, 169]): Cannot find type promotion rule for op: aten.transpose.int\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.transpose.int)[call_function]:Tensor(f32[1, 512, 169])\n## Return values\nTensor(f32[1, 512, 169])",
      "text":"Skipped for fx.Node(aten.transpose.int)[call_function]:Tensor(f32[1, 512, 169]): Cannot find type promotion rule for op: aten.transpose.int"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.view.default)[call_function]:Tensor(f32[1, 512, 13, 13]): Cannot find type promotion rule for op: aten.view.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.view.default)[call_function]:Tensor(f32[1, 512, 13, 13])\n## Return values\nTensor(f32[1, 512, 13, 13])",
      "text":"Skipped for fx.Node(aten.view.default)[call_function]:Tensor(f32[1, 512, 13, 13]): Cannot find type promotion rule for op: aten.view.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant465: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant465)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512, 1, 1]))",
      "text":"Skipped _param_constant465: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for mul_44. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.mul.Tensor)[call_function]:Tensor(f32[1, 512, 13, 13])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'mul', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument view_20 is not promoted. Already torch.float32.\nArgument _param_constant465 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 512, 13, 13])",
      "text":"Type promotion not needed for mul_44. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_120. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 512, 13, 13])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_119 is not promoted. Already torch.float32.\nArgument mul_44 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 512, 13, 13])",
      "text":"Type promotion not needed for add_120. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant466: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant466)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512, 1, 7, 7]))",
      "text":"Skipped _param_constant466: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 512, 13, 13]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 512, 13, 13])\n## Return values\nTensor(f32[1, 512, 13, 13])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 512, 13, 13]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant467: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant467)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512]))",
      "text":"Skipped _param_constant467: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant468: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant468)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512]))",
      "text":"Skipped _param_constant468: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant246: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant246)[get_attr]:None\n## Return values\nTensor(f32[512])",
      "text":"Skipped _tensor_constant246: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant247: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant247)[get_attr]:None\n## Return values\nTensor(f32[512])",
      "text":"Skipped _tensor_constant247: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 512, 13, 13]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 512, 13, 13]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 512, 13, 13]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 512, 13, 13]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 512, 13, 13]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 512, 13, 13])\n## Return values\nTensor(f32[1, 512, 13, 13])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 512, 13, 13]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant469: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant469)[get_attr]:None\n## Return values\nParameter(Tensor(f32[2048, 512, 1, 1]))",
      "text":"Skipped _param_constant469: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant470: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant470)[get_attr]:None\n## Return values\nParameter(Tensor(f32[2048]))",
      "text":"Skipped _param_constant470: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 2048, 13, 13]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 2048, 13, 13])\n## Return values\nTensor(f32[1, 2048, 13, 13])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 2048, 13, 13]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for gelu_28. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.gelu.default)[call_function]:Tensor(f32[1, 2048, 13, 13])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'gelu', [0], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument convolution_122 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 2048, 13, 13])",
      "text":"Type promotion not needed for gelu_28. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 2048, 13, 13]): Cannot find type promotion rule for op: aten.clone.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 2048, 13, 13])\n## Return values\nTensor(f32[1, 2048, 13, 13])",
      "text":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 2048, 13, 13]): Cannot find type promotion rule for op: aten.clone.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant471: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant471)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512, 2048, 1, 1]))",
      "text":"Skipped _param_constant471: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant472: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant472)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512]))",
      "text":"Skipped _param_constant472: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 512, 13, 13]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 512, 13, 13])\n## Return values\nTensor(f32[1, 512, 13, 13])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 512, 13, 13]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 512, 13, 13]): Cannot find type promotion rule for op: aten.clone.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 512, 13, 13])\n## Return values\nTensor(f32[1, 512, 13, 13])",
      "text":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 512, 13, 13]): Cannot find type promotion rule for op: aten.clone.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant473: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant473)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512, 1, 1]))",
      "text":"Skipped _param_constant473: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for mul_45. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.mul.Tensor)[call_function]:Tensor(f32[1, 512, 13, 13])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'mul', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument clone_48 is not promoted. Already torch.float32.\nArgument _param_constant473 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 512, 13, 13])",
      "text":"Type promotion not needed for mul_45. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_121. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 512, 13, 13])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_120 is not promoted. Already torch.float32.\nArgument mul_45 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 512, 13, 13])",
      "text":"Type promotion not needed for add_121. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant474: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant474)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512]))",
      "text":"Skipped _param_constant474: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant475: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant475)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512]))",
      "text":"Skipped _param_constant475: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant248: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant248)[get_attr]:None\n## Return values\nTensor(f32[512])",
      "text":"Skipped _tensor_constant248: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant249: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant249)[get_attr]:None\n## Return values\nTensor(f32[512])",
      "text":"Skipped _tensor_constant249: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 512, 13, 13]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 512, 13, 13]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 512, 13, 13]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 512, 13, 13]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 512, 13, 13]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 512, 13, 13])\n## Return values\nTensor(f32[1, 512, 13, 13])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 512, 13, 13]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.view.default)[call_function]:Tensor(f32[1, 512, 169]): Cannot find type promotion rule for op: aten.view.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.view.default)[call_function]:Tensor(f32[1, 512, 169])\n## Return values\nTensor(f32[1, 512, 169])",
      "text":"Skipped for fx.Node(aten.view.default)[call_function]:Tensor(f32[1, 512, 169]): Cannot find type promotion rule for op: aten.view.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.transpose.int)[call_function]:Tensor(f32[1, 169, 512]): Cannot find type promotion rule for op: aten.transpose.int\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.transpose.int)[call_function]:Tensor(f32[1, 169, 512])\n## Return values\nTensor(f32[1, 169, 512])",
      "text":"Skipped for fx.Node(aten.transpose.int)[call_function]:Tensor(f32[1, 169, 512]): Cannot find type promotion rule for op: aten.transpose.int"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant476: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant476)[get_attr]:None\n## Return values\nParameter(Tensor(f32[1536, 512]))",
      "text":"Skipped _param_constant476: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.t.default)[call_function]:Tensor(f32[512, 1536]): Cannot find type promotion rule for op: aten.t.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.t.default)[call_function]:Tensor(f32[512, 1536])\n## Return values\nTensor(f32[512, 1536])",
      "text":"Skipped for fx.Node(aten.t.default)[call_function]:Tensor(f32[512, 1536]): Cannot find type promotion rule for op: aten.t.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.view.default)[call_function]:Tensor(f32[169, 512]): Cannot find type promotion rule for op: aten.view.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.view.default)[call_function]:Tensor(f32[169, 512])\n## Return values\nTensor(f32[169, 512])",
      "text":"Skipped for fx.Node(aten.view.default)[call_function]:Tensor(f32[169, 512]): Cannot find type promotion rule for op: aten.view.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.mm.default)[call_function]:Tensor(f32[169, 1536]): Cannot find type promotion rule for op: aten.mm.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.mm.default)[call_function]:Tensor(f32[169, 1536])\n## Return values\nTensor(f32[169, 1536])",
      "text":"Skipped for fx.Node(aten.mm.default)[call_function]:Tensor(f32[169, 1536]): Cannot find type promotion rule for op: aten.mm.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._unsafe_view.default)[call_function]:Tensor(f32[1, 169, 1536]): Cannot find type promotion rule for op: aten._unsafe_view.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._unsafe_view.default)[call_function]:Tensor(f32[1, 169, 1536])\n## Return values\nTensor(f32[1, 169, 1536])",
      "text":"Skipped for fx.Node(aten._unsafe_view.default)[call_function]:Tensor(f32[1, 169, 1536]): Cannot find type promotion rule for op: aten._unsafe_view.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.view.default)[call_function]:Tensor(f32[1, 169, 3, 16, 32]): Cannot find type promotion rule for op: aten.view.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.view.default)[call_function]:Tensor(f32[1, 169, 3, 16, 32])\n## Return values\nTensor(f32[1, 169, 3, 16, 32])",
      "text":"Skipped for fx.Node(aten.view.default)[call_function]:Tensor(f32[1, 169, 3, 16, 32]): Cannot find type promotion rule for op: aten.view.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.permute.default)[call_function]:Tensor(f32[3, 1, 16, 169, 32]): Cannot find type promotion rule for op: aten.permute.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.permute.default)[call_function]:Tensor(f32[3, 1, 16, 169, 32])\n## Return values\nTensor(f32[3, 1, 16, 169, 32])",
      "text":"Skipped for fx.Node(aten.permute.default)[call_function]:Tensor(f32[3, 1, 16, 169, 32]): Cannot find type promotion rule for op: aten.permute.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.unbind.int)[call_function]:List[length=3](\nTensor(f32[1, 16, 169, 32]),\nTensor(f32[1, 16, 169, 32]),\nTensor(f32[1, 16, 169, 32]),\n): Cannot find type promotion rule for op: aten.unbind.int\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.unbind.int)[call_function]:List[length=3](\nTensor(f32[1, 16, 169, 32]),\nTensor(f32[1, 16, 169, 32]),\nTensor(f32[1, 16, 169, 32]),\n)\n## Return values\nList[length=3](\nTensor(f32[1, 16, 169, 32]),\nTensor(f32[1, 16, 169, 32]),\nTensor(f32[1, 16, 169, 32]),\n)",
      "text":"Skipped for fx.Node(aten.unbind.int)[call_function]:List[length=3](\nTensor(f32[1, 16, 169, 32]),\nTensor(f32[1, 16, 169, 32]),\nTensor(f32[1, 16, 169, 32]),\n): Cannot find type promotion rule for op: aten.unbind.int"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 16, 169, 32]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 16, 169, 32])\n## Return values\nTensor(f32[1, 16, 169, 32])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 16, 169, 32]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 16, 169, 32]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 16, 169, 32])\n## Return values\nTensor(f32[1, 16, 169, 32])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 16, 169, 32]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 16, 169, 32]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 16, 169, 32])\n## Return values\nTensor(f32[1, 16, 169, 32])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 16, 169, 32]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._scaled_dot_product_flash_attention_for_cpu.default)[call_function]:Tuple[length=2](\nTensor(f32[1, 16, 169, 32]),\nTensor(f32[1, 16, 169]),\n): Cannot find type promotion rule for op: aten._scaled_dot_product_flash_attention_for_cpu.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._scaled_dot_product_flash_attention_for_cpu.default)[call_function]:Tuple[length=2](\nTensor(f32[1, 16, 169, 32]),\nTensor(f32[1, 16, 169]),\n)\n## Return values\nTuple[length=2](\nTensor(f32[1, 16, 169, 32]),\nTensor(f32[1, 16, 169]),\n)",
      "text":"Skipped for fx.Node(aten._scaled_dot_product_flash_attention_for_cpu.default)[call_function]:Tuple[length=2](\nTensor(f32[1, 16, 169, 32]),\nTensor(f32[1, 16, 169]),\n): Cannot find type promotion rule for op: aten._scaled_dot_product_flash_attention_for_cpu.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 16, 169, 32]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 16, 169, 32])\n## Return values\nTensor(f32[1, 16, 169, 32])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 16, 169, 32]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 16, 169]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 16, 169])\n## Return values\nTensor(f32[1, 16, 169])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 16, 169]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.transpose.int)[call_function]:Tensor(f32[1, 169, 16, 32]): Cannot find type promotion rule for op: aten.transpose.int\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.transpose.int)[call_function]:Tensor(f32[1, 169, 16, 32])\n## Return values\nTensor(f32[1, 169, 16, 32])",
      "text":"Skipped for fx.Node(aten.transpose.int)[call_function]:Tensor(f32[1, 169, 16, 32]): Cannot find type promotion rule for op: aten.transpose.int"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.view.default)[call_function]:Tensor(f32[1, 169, 512]): Cannot find type promotion rule for op: aten.view.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.view.default)[call_function]:Tensor(f32[1, 169, 512])\n## Return values\nTensor(f32[1, 169, 512])",
      "text":"Skipped for fx.Node(aten.view.default)[call_function]:Tensor(f32[1, 169, 512]): Cannot find type promotion rule for op: aten.view.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.view.default)[call_function]:Tensor(f32[169, 512]): Cannot find type promotion rule for op: aten.view.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.view.default)[call_function]:Tensor(f32[169, 512])\n## Return values\nTensor(f32[169, 512])",
      "text":"Skipped for fx.Node(aten.view.default)[call_function]:Tensor(f32[169, 512]): Cannot find type promotion rule for op: aten.view.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant477: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant477)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512, 512]))",
      "text":"Skipped _param_constant477: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.t.default)[call_function]:Tensor(f32[512, 512]): Cannot find type promotion rule for op: aten.t.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.t.default)[call_function]:Tensor(f32[512, 512])\n## Return values\nTensor(f32[512, 512])",
      "text":"Skipped for fx.Node(aten.t.default)[call_function]:Tensor(f32[512, 512]): Cannot find type promotion rule for op: aten.t.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant478: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant478)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512]))",
      "text":"Skipped _param_constant478: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.addmm.default)[call_function]:Tensor(f32[169, 512]): Cannot find type promotion rule for op: aten.addmm.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.addmm.default)[call_function]:Tensor(f32[169, 512])\n## Return values\nTensor(f32[169, 512])",
      "text":"Skipped for fx.Node(aten.addmm.default)[call_function]:Tensor(f32[169, 512]): Cannot find type promotion rule for op: aten.addmm.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.view.default)[call_function]:Tensor(f32[1, 169, 512]): Cannot find type promotion rule for op: aten.view.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.view.default)[call_function]:Tensor(f32[1, 169, 512])\n## Return values\nTensor(f32[1, 169, 512])",
      "text":"Skipped for fx.Node(aten.view.default)[call_function]:Tensor(f32[1, 169, 512]): Cannot find type promotion rule for op: aten.view.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 169, 512]): Cannot find type promotion rule for op: aten.clone.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 169, 512])\n## Return values\nTensor(f32[1, 169, 512])",
      "text":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 169, 512]): Cannot find type promotion rule for op: aten.clone.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.transpose.int)[call_function]:Tensor(f32[1, 512, 169]): Cannot find type promotion rule for op: aten.transpose.int\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.transpose.int)[call_function]:Tensor(f32[1, 512, 169])\n## Return values\nTensor(f32[1, 512, 169])",
      "text":"Skipped for fx.Node(aten.transpose.int)[call_function]:Tensor(f32[1, 512, 169]): Cannot find type promotion rule for op: aten.transpose.int"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.view.default)[call_function]:Tensor(f32[1, 512, 13, 13]): Cannot find type promotion rule for op: aten.view.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.view.default)[call_function]:Tensor(f32[1, 512, 13, 13])\n## Return values\nTensor(f32[1, 512, 13, 13])",
      "text":"Skipped for fx.Node(aten.view.default)[call_function]:Tensor(f32[1, 512, 13, 13]): Cannot find type promotion rule for op: aten.view.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant479: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant479)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512, 1, 1]))",
      "text":"Skipped _param_constant479: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for mul_46. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.mul.Tensor)[call_function]:Tensor(f32[1, 512, 13, 13])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'mul', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument view_27 is not promoted. Already torch.float32.\nArgument _param_constant479 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 512, 13, 13])",
      "text":"Type promotion not needed for mul_46. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_122. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 512, 13, 13])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_121 is not promoted. Already torch.float32.\nArgument mul_46 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 512, 13, 13])",
      "text":"Type promotion not needed for add_122. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant480: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant480)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512, 1, 7, 7]))",
      "text":"Skipped _param_constant480: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 512, 13, 13]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 512, 13, 13])\n## Return values\nTensor(f32[1, 512, 13, 13])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 512, 13, 13]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant481: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant481)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512]))",
      "text":"Skipped _param_constant481: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant482: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant482)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512]))",
      "text":"Skipped _param_constant482: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant250: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant250)[get_attr]:None\n## Return values\nTensor(f32[512])",
      "text":"Skipped _tensor_constant250: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant251: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant251)[get_attr]:None\n## Return values\nTensor(f32[512])",
      "text":"Skipped _tensor_constant251: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 512, 13, 13]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 512, 13, 13]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 512, 13, 13]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 512, 13, 13]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 512, 13, 13]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 512, 13, 13])\n## Return values\nTensor(f32[1, 512, 13, 13])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 512, 13, 13]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant483: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant483)[get_attr]:None\n## Return values\nParameter(Tensor(f32[2048, 512, 1, 1]))",
      "text":"Skipped _param_constant483: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant484: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant484)[get_attr]:None\n## Return values\nParameter(Tensor(f32[2048]))",
      "text":"Skipped _param_constant484: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 2048, 13, 13]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 2048, 13, 13])\n## Return values\nTensor(f32[1, 2048, 13, 13])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 2048, 13, 13]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for gelu_29. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.gelu.default)[call_function]:Tensor(f32[1, 2048, 13, 13])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'gelu', [0], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument convolution_125 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 2048, 13, 13])",
      "text":"Type promotion not needed for gelu_29. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 2048, 13, 13]): Cannot find type promotion rule for op: aten.clone.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 2048, 13, 13])\n## Return values\nTensor(f32[1, 2048, 13, 13])",
      "text":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 2048, 13, 13]): Cannot find type promotion rule for op: aten.clone.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant485: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant485)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512, 2048, 1, 1]))",
      "text":"Skipped _param_constant485: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant486: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant486)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512]))",
      "text":"Skipped _param_constant486: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 512, 13, 13]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 512, 13, 13])\n## Return values\nTensor(f32[1, 512, 13, 13])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 512, 13, 13]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 512, 13, 13]): Cannot find type promotion rule for op: aten.clone.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 512, 13, 13])\n## Return values\nTensor(f32[1, 512, 13, 13])",
      "text":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 512, 13, 13]): Cannot find type promotion rule for op: aten.clone.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant487: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant487)[get_attr]:None\n## Return values\nParameter(Tensor(f32[512, 1, 1]))",
      "text":"Skipped _param_constant487: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for mul_47. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.mul.Tensor)[call_function]:Tensor(f32[1, 512, 13, 13])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'mul', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument clone_51 is not promoted. Already torch.float32.\nArgument _param_constant487 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 512, 13, 13])",
      "text":"Type promotion not needed for mul_47. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_123. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 512, 13, 13])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_122 is not promoted. Already torch.float32.\nArgument mul_47 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 512, 13, 13])",
      "text":"Type promotion not needed for add_123. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant488: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant488)[get_attr]:None\n## Return values\nParameter(Tensor(f32[1024, 1, 1, 1]))",
      "text":"Skipped _param_constant488: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 1024, 13, 13]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 1024, 13, 13])\n## Return values\nTensor(f32[1, 1024, 13, 13])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 1024, 13, 13]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant489: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant489)[get_attr]:None\n## Return values\nParameter(Tensor(f32[1024]))",
      "text":"Skipped _param_constant489: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant490: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant490)[get_attr]:None\n## Return values\nParameter(Tensor(f32[1024]))",
      "text":"Skipped _param_constant490: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant252: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant252)[get_attr]:None\n## Return values\nTensor(f32[1024])",
      "text":"Skipped _tensor_constant252: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant253: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant253)[get_attr]:None\n## Return values\nTensor(f32[1024])",
      "text":"Skipped _tensor_constant253: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 1024, 13, 13]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 1024, 13, 13]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 1024, 13, 13]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 1024, 13, 13]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 1024, 13, 13]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 1024, 13, 13])\n## Return values\nTensor(f32[1, 1024, 13, 13])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 1024, 13, 13]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Applied type promotion for add_124. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 1024, 13, 13])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument getitem_398 is not promoted. Already torch.float32.\nArgument 0(Scalar of equivalent dtype: torch.int64) is promoted to torch.float32.\n## Return values\nTensor(f32[1, 1024, 13, 13])",
      "text":"Applied type promotion for add_124. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant491: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant491)[get_attr]:None\n## Return values\nParameter(Tensor(f32[1024, 1, 3, 3]))",
      "text":"Skipped _param_constant491: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 1024, 13, 13]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 1024, 13, 13])\n## Return values\nTensor(f32[1, 1024, 13, 13])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 1024, 13, 13]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0])\n## Return values\nTensor(u8[0])",
      "text":"Skipped for fx.Node(aten.empty.memory_format)[call_function]:Tensor(u8[0]): Cannot find type promotion rule for op: aten.empty.memory_format"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant492: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant492)[get_attr]:None\n## Return values\nParameter(Tensor(f32[1024]))",
      "text":"Skipped _param_constant492: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant493: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant493)[get_attr]:None\n## Return values\nParameter(Tensor(f32[1024]))",
      "text":"Skipped _param_constant493: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant254: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant254)[get_attr]:None\n## Return values\nTensor(f32[1024])",
      "text":"Skipped _tensor_constant254: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _tensor_constant255: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_tensor_constant255)[get_attr]:None\n## Return values\nTensor(f32[1024])",
      "text":"Skipped _tensor_constant255: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 1024, 13, 13]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 1024, 13, 13]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n## Return values\nTuple[length=3](\nTensor(f32[1, 1024, 13, 13]),\nTensor(f32[0]),\nTensor(f32[0]),\n)",
      "text":"Skipped for fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 1024, 13, 13]),\nTensor(f32[0]),\nTensor(f32[0]),\n): Cannot find type promotion rule for op: aten._native_batch_norm_legit_no_training.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 1024, 13, 13]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 1024, 13, 13])\n## Return values\nTensor(f32[1, 1024, 13, 13])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 1024, 13, 13]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0])\n## Return values\nTensor(f32[0])",
      "text":"Skipped for fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[0]): node.target is not OpOverload. Got type: <class 'builtin_function_or_method'>"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for add_125. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 1024, 13, 13])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'add', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_124 is not promoted. Already torch.float32.\nArgument getitem_401 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 1024, 13, 13])",
      "text":"Type promotion not needed for add_125. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.mean.dim)[call_function]:Tensor(f32[1, 1024, 1, 1]): Cannot find type promotion rule for op: aten.mean.dim\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.mean.dim)[call_function]:Tensor(f32[1, 1024, 1, 1])\n## Return values\nTensor(f32[1, 1024, 1, 1])",
      "text":"Skipped for fx.Node(aten.mean.dim)[call_function]:Tensor(f32[1, 1024, 1, 1]): Cannot find type promotion rule for op: aten.mean.dim"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant494: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant494)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64, 1024, 1, 1]))",
      "text":"Skipped _param_constant494: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant495: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant495)[get_attr]:None\n## Return values\nParameter(Tensor(f32[64]))",
      "text":"Skipped _param_constant495: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 1, 1]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 1, 1])\n## Return values\nTensor(f32[1, 64, 1, 1])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 1, 1]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for relu. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.relu.default)[call_function]:Tensor(f32[1, 64, 1, 1])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'relu', [0], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument convolution_129 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 64, 1, 1])",
      "text":"Type promotion not needed for relu. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.copy.default)[call_function]:Tensor(f32[1, 64, 1, 1]): Cannot find type promotion rule for op: aten.copy.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.copy.default)[call_function]:Tensor(f32[1, 64, 1, 1])\n## Return values\nTensor(f32[1, 64, 1, 1])",
      "text":"Skipped for fx.Node(aten.copy.default)[call_function]:Tensor(f32[1, 64, 1, 1]): Cannot find type promotion rule for op: aten.copy.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant496: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant496)[get_attr]:None\n## Return values\nParameter(Tensor(f32[1024, 64, 1, 1]))",
      "text":"Skipped _param_constant496: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant497: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant497)[get_attr]:None\n## Return values\nParameter(Tensor(f32[1024]))",
      "text":"Skipped _param_constant497: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 1024, 1, 1]): Cannot find type promotion rule for op: aten.convolution.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 1024, 1, 1])\n## Return values\nTensor(f32[1, 1024, 1, 1])",
      "text":"Skipped for fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 1024, 1, 1]): Cannot find type promotion rule for op: aten.convolution.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for sigmoid. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.sigmoid.default)[call_function]:Tensor(f32[1, 1024, 1, 1])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'sigmoid', [0], [], ELEMENTWISE_TYPE_PROMOTION_KIND.INT_TO_FLOAT)\nArgument convolution_130 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 1024, 1, 1])",
      "text":"Type promotion not needed for sigmoid. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for mul_48. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.mul.Tensor)[call_function]:Tensor(f32[1, 1024, 13, 13])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'mul', [0, 1], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument add_125 is not promoted. Already torch.float32.\nArgument sigmoid is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 1024, 13, 13])",
      "text":"Type promotion not needed for mul_48. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Type promotion not needed for gelu_30. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.gelu.default)[call_function]:Tensor(f32[1, 1024, 13, 13])\nFound type promotion rule: ElementwiseTypePromotionRule('aten', 'gelu', [0], [], ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)\nArgument mul_48 is not promoted. Already torch.float32.\n## Return values\nTensor(f32[1, 1024, 13, 13])",
      "text":"Type promotion not needed for gelu_30. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.mean.dim)[call_function]:Tensor(f32[1, 1024, 1, 1]): Cannot find type promotion rule for op: aten.mean.dim\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.mean.dim)[call_function]:Tensor(f32[1, 1024, 1, 1])\n## Return values\nTensor(f32[1, 1024, 1, 1])",
      "text":"Skipped for fx.Node(aten.mean.dim)[call_function]:Tensor(f32[1, 1024, 1, 1]): Cannot find type promotion rule for op: aten.mean.dim"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.view.default)[call_function]:Tensor(f32[1, 1024]): Cannot find type promotion rule for op: aten.view.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.view.default)[call_function]:Tensor(f32[1, 1024])\n## Return values\nTensor(f32[1, 1024])",
      "text":"Skipped for fx.Node(aten.view.default)[call_function]:Tensor(f32[1, 1024]): Cannot find type promotion rule for op: aten.view.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 1024]): Cannot find type promotion rule for op: aten.clone.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 1024])\n## Return values\nTensor(f32[1, 1024])",
      "text":"Skipped for fx.Node(aten.clone.default)[call_function]:Tensor(f32[1, 1024]): Cannot find type promotion rule for op: aten.clone.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant498: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant498)[get_attr]:None\n## Return values\nParameter(Tensor(f32[5, 1024]))",
      "text":"Skipped _param_constant498: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.t.default)[call_function]:Tensor(f32[1024, 5]): Cannot find type promotion rule for op: aten.t.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.t.default)[call_function]:Tensor(f32[1024, 5])\n## Return values\nTensor(f32[1024, 5])",
      "text":"Skipped for fx.Node(aten.t.default)[call_function]:Tensor(f32[1024, 5]): Cannot find type promotion rule for op: aten.t.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant499: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant499)[get_attr]:None\n## Return values\nParameter(Tensor(f32[5]))",
      "text":"Skipped _param_constant499: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.addmm.default)[call_function]:Tensor(f32[1, 5]): Cannot find type promotion rule for op: aten.addmm.default\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.addmm.default)[call_function]:Tensor(f32[1, 5])\n## Return values\nTensor(f32[1, 5])",
      "text":"Skipped for fx.Node(aten.addmm.default)[call_function]:Tensor(f32[1, 5]): Cannot find type promotion rule for op: aten.addmm.default"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped output: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(output)[output]:None\n## Return values\nList[length=1](\nTensor(f32[1, 5]),\n)",
      "text":"Skipped output: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1601
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Running InsertTypePromotion pass. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature Transform.run\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion.InsertTypePromotion'>\nFor detailed logging of graph modifications by this pass, either set `DiagnosticOptions.verbosity_level` to `logging.DEBUG` or use the environment variable `TORCH_LOGS='onnx_diagnostics'`.\n## Return values\ntorch.fx.GraphModule(<lambda>)",
      "text":"Running InsertTypePromotion pass. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"Transform.run"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/_pass.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":240
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0010",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Running RestoreParameterAndBufferNames pass. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature Transform.run\n- self: <class 'torch.onnx._internal.fx.passes.readability.RestoreParameterAndBufferNames'>\nFor detailed logging of graph modifications by this pass, either set `DiagnosticOptions.verbosity_level` to `logging.DEBUG` or use the environment variable `TORCH_LOGS='onnx_diagnostics'`.\nRenamed 'self._param_constant0' to 'self.stem/0/conv_scale/conv/weight', normalized from original parameter name 'stem.0.conv_scale.conv.weight'.\nRenamed 'self._param_constant1' to 'self.stem/0/conv_scale/bn/weight', normalized from original parameter name 'stem.0.conv_scale.bn.weight'.\nRenamed 'self._param_constant2' to 'self.stem/0/conv_scale/bn/bias', normalized from original parameter name 'stem.0.conv_scale.bn.bias'.\nRenamed 'self._tensor_constant0' to 'self.stem/0/conv_scale/bn/running_mean', normalized from original parameter name 'stem.0.conv_scale.bn.running_mean'.\nRenamed 'self._tensor_constant1' to 'self.stem/0/conv_scale/bn/running_var', normalized from original parameter name 'stem.0.conv_scale.bn.running_var'.\nRenamed 'self._param_constant3' to 'self.stem/0/conv_kxk/0/conv/weight', normalized from original parameter name 'stem.0.conv_kxk.0.conv.weight'.\nRenamed 'self._param_constant4' to 'self.stem/0/conv_kxk/0/bn/weight', normalized from original parameter name 'stem.0.conv_kxk.0.bn.weight'.\nRenamed 'self._param_constant5' to 'self.stem/0/conv_kxk/0/bn/bias', normalized from original parameter name 'stem.0.conv_kxk.0.bn.bias'.\nRenamed 'self._tensor_constant2' to 'self.stem/0/conv_kxk/0/bn/running_mean', normalized from original parameter name 'stem.0.conv_kxk.0.bn.running_mean'.\nRenamed 'self._tensor_constant3' to 'self.stem/0/conv_kxk/0/bn/running_var', normalized from original parameter name 'stem.0.conv_kxk.0.bn.running_var'.\nRenamed 'self._param_constant6' to 'self.stem/1/conv_scale/conv/weight', normalized from original parameter name 'stem.1.conv_scale.conv.weight'.\nRenamed 'self._param_constant7' to 'self.stem/1/conv_scale/bn/weight', normalized from original parameter name 'stem.1.conv_scale.bn.weight'.\nRenamed 'self._param_constant8' to 'self.stem/1/conv_scale/bn/bias', normalized from original parameter name 'stem.1.conv_scale.bn.bias'.\nRenamed 'self._tensor_constant4' to 'self.stem/1/conv_scale/bn/running_mean', normalized from original parameter name 'stem.1.conv_scale.bn.running_mean'.\nRenamed 'self._tensor_constant5' to 'self.stem/1/conv_scale/bn/running_var', normalized from original parameter name 'stem.1.conv_scale.bn.running_var'.\nRenamed 'self._param_constant9' to 'self.stem/1/conv_kxk/0/conv/weight', normalized from original parameter name 'stem.1.conv_kxk.0.conv.weight'.\nRenamed 'self._param_constant10' to 'self.stem/1/conv_kxk/0/bn/weight', normalized from original parameter name 'stem.1.conv_kxk.0.bn.weight'.\nRenamed 'self._param_constant11' to 'self.stem/1/conv_kxk/0/bn/bias', normalized from original parameter name 'stem.1.conv_kxk.0.bn.bias'.\nRenamed 'self._tensor_constant6' to 'self.stem/1/conv_kxk/0/bn/running_mean', normalized from original parameter name 'stem.1.conv_kxk.0.bn.running_mean'.\nRenamed 'self._tensor_constant7' to 'self.stem/1/conv_kxk/0/bn/running_var', normalized from original parameter name 'stem.1.conv_kxk.0.bn.running_var'.\nRenamed 'self._param_constant12' to 'self.stem/2/identity/weight', normalized from original parameter name 'stem.2.identity.weight'.\nRenamed 'self._param_constant13' to 'self.stem/2/identity/bias', normalized from original parameter name 'stem.2.identity.bias'.\nRenamed 'self._tensor_constant8' to 'self.stem/2/identity/running_mean', normalized from original parameter name 'stem.2.identity.running_mean'.\nRenamed 'self._tensor_constant9' to 'self.stem/2/identity/running_var', normalized from original parameter name 'stem.2.identity.running_var'.\nRenamed 'self._param_constant14' to 'self.stem/2/conv_kxk/0/conv/weight', normalized from original parameter name 'stem.2.conv_kxk.0.conv.weight'.\nRenamed 'self._param_constant15' to 'self.stem/2/conv_kxk/0/bn/weight', normalized from original parameter name 'stem.2.conv_kxk.0.bn.weight'.\nRenamed 'self._param_constant16' to 'self.stem/2/conv_kxk/0/bn/bias', normalized from original parameter name 'stem.2.conv_kxk.0.bn.bias'.\nRenamed 'self._tensor_constant10' to 'self.stem/2/conv_kxk/0/bn/running_mean', normalized from original parameter name 'stem.2.conv_kxk.0.bn.running_mean'.\nRenamed 'self._tensor_constant11' to 'self.stem/2/conv_kxk/0/bn/running_var', normalized from original parameter name 'stem.2.conv_kxk.0.bn.running_var'.\nRenamed 'self._param_constant17' to 'self.stages/0/blocks/0/token_mixer/mixer/identity/weight', normalized from original parameter name 'stages.0.blocks.0.token_mixer.mixer.identity.weight'.\nRenamed 'self._param_constant18' to 'self.stages/0/blocks/0/token_mixer/mixer/identity/bias', normalized from original parameter name 'stages.0.blocks.0.token_mixer.mixer.identity.bias'.\nRenamed 'self._tensor_constant12' to 'self.stages/0/blocks/0/token_mixer/mixer/identity/running_mean', normalized from original parameter name 'stages.0.blocks.0.token_mixer.mixer.identity.running_mean'.\nRenamed 'self._tensor_constant13' to 'self.stages/0/blocks/0/token_mixer/mixer/identity/running_var', normalized from original parameter name 'stages.0.blocks.0.token_mixer.mixer.identity.running_var'.\nRenamed 'self._param_constant19' to 'self.stages/0/blocks/0/token_mixer/mixer/conv_scale/conv/weight', normalized from original parameter name 'stages.0.blocks.0.token_mixer.mixer.conv_scale.conv.weight'.\nRenamed 'self._param_constant20' to 'self.stages/0/blocks/0/token_mixer/mixer/conv_scale/bn/weight', normalized from original parameter name 'stages.0.blocks.0.token_mixer.mixer.conv_scale.bn.weight'.\nRenamed 'self._param_constant21' to 'self.stages/0/blocks/0/token_mixer/mixer/conv_scale/bn/bias', normalized from original parameter name 'stages.0.blocks.0.token_mixer.mixer.conv_scale.bn.bias'.\nRenamed 'self._tensor_constant14' to 'self.stages/0/blocks/0/token_mixer/mixer/conv_scale/bn/running_mean', normalized from original parameter name 'stages.0.blocks.0.token_mixer.mixer.conv_scale.bn.running_mean'.\nRenamed 'self._tensor_constant15' to 'self.stages/0/blocks/0/token_mixer/mixer/conv_scale/bn/running_var', normalized from original parameter name 'stages.0.blocks.0.token_mixer.mixer.conv_scale.bn.running_var'.\nRenamed 'self._param_constant22' to 'self.stages/0/blocks/0/token_mixer/mixer/conv_kxk/0/conv/weight', normalized from original parameter name 'stages.0.blocks.0.token_mixer.mixer.conv_kxk.0.conv.weight'.\nRenamed 'self._param_constant23' to 'self.stages/0/blocks/0/token_mixer/mixer/conv_kxk/0/bn/weight', normalized from original parameter name 'stages.0.blocks.0.token_mixer.mixer.conv_kxk.0.bn.weight'.\nRenamed 'self._param_constant24' to 'self.stages/0/blocks/0/token_mixer/mixer/conv_kxk/0/bn/bias', normalized from original parameter name 'stages.0.blocks.0.token_mixer.mixer.conv_kxk.0.bn.bias'.\nRenamed 'self._tensor_constant16' to 'self.stages/0/blocks/0/token_mixer/mixer/conv_kxk/0/bn/running_mean', normalized from original parameter name 'stages.0.blocks.0.token_mixer.mixer.conv_kxk.0.bn.running_mean'.\nRenamed 'self._tensor_constant17' to 'self.stages/0/blocks/0/token_mixer/mixer/conv_kxk/0/bn/running_var', normalized from original parameter name 'stages.0.blocks.0.token_mixer.mixer.conv_kxk.0.bn.running_var'.\nRenamed 'self._param_constant25' to 'self.stages/0/blocks/0/token_mixer/norm/identity/weight', normalized from original parameter name 'stages.0.blocks.0.token_mixer.norm.identity.weight'.\nRenamed 'self._param_constant26' to 'self.stages/0/blocks/0/token_mixer/norm/identity/bias', normalized from original parameter name 'stages.0.blocks.0.token_mixer.norm.identity.bias'.\nRenamed 'self._tensor_constant18' to 'self.stages/0/blocks/0/token_mixer/norm/identity/running_mean', normalized from original parameter name 'stages.0.blocks.0.token_mixer.norm.identity.running_mean'.\nRenamed 'self._tensor_constant19' to 'self.stages/0/blocks/0/token_mixer/norm/identity/running_var', normalized from original parameter name 'stages.0.blocks.0.token_mixer.norm.identity.running_var'.\nRenamed 'self._param_constant27' to 'self.stages/0/blocks/0/token_mixer/layer_scale/gamma', normalized from original parameter name 'stages.0.blocks.0.token_mixer.layer_scale.gamma'.\nRenamed 'self._param_constant28' to 'self.stages/0/blocks/0/mlp/conv/conv/weight', normalized from original parameter name 'stages.0.blocks.0.mlp.conv.conv.weight'.\nRenamed 'self._param_constant29' to 'self.stages/0/blocks/0/mlp/conv/bn/weight', normalized from original parameter name 'stages.0.blocks.0.mlp.conv.bn.weight'.\nRenamed 'self._param_constant30' to 'self.stages/0/blocks/0/mlp/conv/bn/bias', normalized from original parameter name 'stages.0.blocks.0.mlp.conv.bn.bias'.\nRenamed 'self._tensor_constant20' to 'self.stages/0/blocks/0/mlp/conv/bn/running_mean', normalized from original parameter name 'stages.0.blocks.0.mlp.conv.bn.running_mean'.\nRenamed 'self._tensor_constant21' to 'self.stages/0/blocks/0/mlp/conv/bn/running_var', normalized from original parameter name 'stages.0.blocks.0.mlp.conv.bn.running_var'.\nRenamed 'self._param_constant31' to 'self.stages/0/blocks/0/mlp/fc1/weight', normalized from original parameter name 'stages.0.blocks.0.mlp.fc1.weight'.\nRenamed 'self._param_constant32' to 'self.stages/0/blocks/0/mlp/fc1/bias', normalized from original parameter name 'stages.0.blocks.0.mlp.fc1.bias'.\nRenamed 'self._param_constant33' to 'self.stages/0/blocks/0/mlp/fc2/weight', normalized from original parameter name 'stages.0.blocks.0.mlp.fc2.weight'.\nRenamed 'self._param_constant34' to 'self.stages/0/blocks/0/mlp/fc2/bias', normalized from original parameter name 'stages.0.blocks.0.mlp.fc2.bias'.\nRenamed 'self._param_constant35' to 'self.stages/0/blocks/0/layer_scale/gamma', normalized from original parameter name 'stages.0.blocks.0.layer_scale.gamma'.\nRenamed 'self._param_constant36' to 'self.stages/0/blocks/1/token_mixer/mixer/identity/weight', normalized from original parameter name 'stages.0.blocks.1.token_mixer.mixer.identity.weight'.\nRenamed 'self._param_constant37' to 'self.stages/0/blocks/1/token_mixer/mixer/identity/bias', normalized from original parameter name 'stages.0.blocks.1.token_mixer.mixer.identity.bias'.\nRenamed 'self._tensor_constant22' to 'self.stages/0/blocks/1/token_mixer/mixer/identity/running_mean', normalized from original parameter name 'stages.0.blocks.1.token_mixer.mixer.identity.running_mean'.\nRenamed 'self._tensor_constant23' to 'self.stages/0/blocks/1/token_mixer/mixer/identity/running_var', normalized from original parameter name 'stages.0.blocks.1.token_mixer.mixer.identity.running_var'.\nRenamed 'self._param_constant38' to 'self.stages/0/blocks/1/token_mixer/mixer/conv_scale/conv/weight', normalized from original parameter name 'stages.0.blocks.1.token_mixer.mixer.conv_scale.conv.weight'.\nRenamed 'self._param_constant39' to 'self.stages/0/blocks/1/token_mixer/mixer/conv_scale/bn/weight', normalized from original parameter name 'stages.0.blocks.1.token_mixer.mixer.conv_scale.bn.weight'.\nRenamed 'self._param_constant40' to 'self.stages/0/blocks/1/token_mixer/mixer/conv_scale/bn/bias', normalized from original parameter name 'stages.0.blocks.1.token_mixer.mixer.conv_scale.bn.bias'.\nRenamed 'self._tensor_constant24' to 'self.stages/0/blocks/1/token_mixer/mixer/conv_scale/bn/running_mean', normalized from original parameter name 'stages.0.blocks.1.token_mixer.mixer.conv_scale.bn.running_mean'.\nRenamed 'self._tensor_constant25' to 'self.stages/0/blocks/1/token_mixer/mixer/conv_scale/bn/running_var', normalized from original parameter name 'stages.0.blocks.1.token_mixer.mixer.conv_scale.bn.running_var'.\nRenamed 'self._param_constant41' to 'self.stages/0/blocks/1/token_mixer/mixer/conv_kxk/0/conv/weight', normalized from original parameter name 'stages.0.blocks.1.token_mixer.mixer.conv_kxk.0.conv.weight'.\nRenamed 'self._param_constant42' to 'self.stages/0/blocks/1/token_mixer/mixer/conv_kxk/0/bn/weight', normalized from original parameter name 'stages.0.blocks.1.token_mixer.mixer.conv_kxk.0.bn.weight'.\nRenamed 'self._param_constant43' to 'self.stages/0/blocks/1/token_mixer/mixer/conv_kxk/0/bn/bias', normalized from original parameter name 'stages.0.blocks.1.token_mixer.mixer.conv_kxk.0.bn.bias'.\nRenamed 'self._tensor_constant26' to 'self.stages/0/blocks/1/token_mixer/mixer/conv_kxk/0/bn/running_mean', normalized from original parameter name 'stages.0.blocks.1.token_mixer.mixer.conv_kxk.0.bn.running_mean'.\nRenamed 'self._tensor_constant27' to 'self.stages/0/blocks/1/token_mixer/mixer/conv_kxk/0/bn/running_var', normalized from original parameter name 'stages.0.blocks.1.token_mixer.mixer.conv_kxk.0.bn.running_var'.\nRenamed 'self._param_constant44' to 'self.stages/0/blocks/1/token_mixer/norm/identity/weight', normalized from original parameter name 'stages.0.blocks.1.token_mixer.norm.identity.weight'.\nRenamed 'self._param_constant45' to 'self.stages/0/blocks/1/token_mixer/norm/identity/bias', normalized from original parameter name 'stages.0.blocks.1.token_mixer.norm.identity.bias'.\nRenamed 'self._tensor_constant28' to 'self.stages/0/blocks/1/token_mixer/norm/identity/running_mean', normalized from original parameter name 'stages.0.blocks.1.token_mixer.norm.identity.running_mean'.\nRenamed 'self._tensor_constant29' to 'self.stages/0/blocks/1/token_mixer/norm/identity/running_var', normalized from original parameter name 'stages.0.blocks.1.token_mixer.norm.identity.running_var'.\nRenamed 'self._param_constant46' to 'self.stages/0/blocks/1/token_mixer/layer_scale/gamma', normalized from original parameter name 'stages.0.blocks.1.token_mixer.layer_scale.gamma'.\nRenamed 'self._param_constant47' to 'self.stages/0/blocks/1/mlp/conv/conv/weight', normalized from original parameter name 'stages.0.blocks.1.mlp.conv.conv.weight'.\nRenamed 'self._param_constant48' to 'self.stages/0/blocks/1/mlp/conv/bn/weight', normalized from original parameter name 'stages.0.blocks.1.mlp.conv.bn.weight'.\nRenamed 'self._param_constant49' to 'self.stages/0/blocks/1/mlp/conv/bn/bias', normalized from original parameter name 'stages.0.blocks.1.mlp.conv.bn.bias'.\nRenamed 'self._tensor_constant30' to 'self.stages/0/blocks/1/mlp/conv/bn/running_mean', normalized from original parameter name 'stages.0.blocks.1.mlp.conv.bn.running_mean'.\nRenamed 'self._tensor_constant31' to 'self.stages/0/blocks/1/mlp/conv/bn/running_var', normalized from original parameter name 'stages.0.blocks.1.mlp.conv.bn.running_var'.\nRenamed 'self._param_constant50' to 'self.stages/0/blocks/1/mlp/fc1/weight', normalized from original parameter name 'stages.0.blocks.1.mlp.fc1.weight'.\nRenamed 'self._param_constant51' to 'self.stages/0/blocks/1/mlp/fc1/bias', normalized from original parameter name 'stages.0.blocks.1.mlp.fc1.bias'.\nRenamed 'self._param_constant52' to 'self.stages/0/blocks/1/mlp/fc2/weight', normalized from original parameter name 'stages.0.blocks.1.mlp.fc2.weight'.\nRenamed 'self._param_constant53' to 'self.stages/0/blocks/1/mlp/fc2/bias', normalized from original parameter name 'stages.0.blocks.1.mlp.fc2.bias'.\nRenamed 'self._param_constant54' to 'self.stages/0/blocks/1/layer_scale/gamma', normalized from original parameter name 'stages.0.blocks.1.layer_scale.gamma'.\nRenamed 'self._param_constant55' to 'self.stages/0/blocks/2/token_mixer/mixer/identity/weight', normalized from original parameter name 'stages.0.blocks.2.token_mixer.mixer.identity.weight'.\nRenamed 'self._param_constant56' to 'self.stages/0/blocks/2/token_mixer/mixer/identity/bias', normalized from original parameter name 'stages.0.blocks.2.token_mixer.mixer.identity.bias'.\nRenamed 'self._tensor_constant32' to 'self.stages/0/blocks/2/token_mixer/mixer/identity/running_mean', normalized from original parameter name 'stages.0.blocks.2.token_mixer.mixer.identity.running_mean'.\nRenamed 'self._tensor_constant33' to 'self.stages/0/blocks/2/token_mixer/mixer/identity/running_var', normalized from original parameter name 'stages.0.blocks.2.token_mixer.mixer.identity.running_var'.\nRenamed 'self._param_constant57' to 'self.stages/0/blocks/2/token_mixer/mixer/conv_scale/conv/weight', normalized from original parameter name 'stages.0.blocks.2.token_mixer.mixer.conv_scale.conv.weight'.\nRenamed 'self._param_constant58' to 'self.stages/0/blocks/2/token_mixer/mixer/conv_scale/bn/weight', normalized from original parameter name 'stages.0.blocks.2.token_mixer.mixer.conv_scale.bn.weight'.\nRenamed 'self._param_constant59' to 'self.stages/0/blocks/2/token_mixer/mixer/conv_scale/bn/bias', normalized from original parameter name 'stages.0.blocks.2.token_mixer.mixer.conv_scale.bn.bias'.\nRenamed 'self._tensor_constant34' to 'self.stages/0/blocks/2/token_mixer/mixer/conv_scale/bn/running_mean', normalized from original parameter name 'stages.0.blocks.2.token_mixer.mixer.conv_scale.bn.running_mean'.\nRenamed 'self._tensor_constant35' to 'self.stages/0/blocks/2/token_mixer/mixer/conv_scale/bn/running_var', normalized from original parameter name 'stages.0.blocks.2.token_mixer.mixer.conv_scale.bn.running_var'.\nRenamed 'self._param_constant60' to 'self.stages/0/blocks/2/token_mixer/mixer/conv_kxk/0/conv/weight', normalized from original parameter name 'stages.0.blocks.2.token_mixer.mixer.conv_kxk.0.conv.weight'.\nRenamed 'self._param_constant61' to 'self.stages/0/blocks/2/token_mixer/mixer/conv_kxk/0/bn/weight', normalized from original parameter name 'stages.0.blocks.2.token_mixer.mixer.conv_kxk.0.bn.weight'.\nRenamed 'self._param_constant62' to 'self.stages/0/blocks/2/token_mixer/mixer/conv_kxk/0/bn/bias', normalized from original parameter name 'stages.0.blocks.2.token_mixer.mixer.conv_kxk.0.bn.bias'.\nRenamed 'self._tensor_constant36' to 'self.stages/0/blocks/2/token_mixer/mixer/conv_kxk/0/bn/running_mean', normalized from original parameter name 'stages.0.blocks.2.token_mixer.mixer.conv_kxk.0.bn.running_mean'.\nRenamed 'self._tensor_constant37' to 'self.stages/0/blocks/2/token_mixer/mixer/conv_kxk/0/bn/running_var', normalized from original parameter name 'stages.0.blocks.2.token_mixer.mixer.conv_kxk.0.bn.running_var'.\nRenamed 'self._param_constant63' to 'self.stages/0/blocks/2/token_mixer/norm/identity/weight', normalized from original parameter name 'stages.0.blocks.2.token_mixer.norm.identity.weight'.\nRenamed 'self._param_constant64' to 'self.stages/0/blocks/2/token_mixer/norm/identity/bias', normalized from original parameter name 'stages.0.blocks.2.token_mixer.norm.identity.bias'.\nRenamed 'self._tensor_constant38' to 'self.stages/0/blocks/2/token_mixer/norm/identity/running_mean', normalized from original parameter name 'stages.0.blocks.2.token_mixer.norm.identity.running_mean'.\nRenamed 'self._tensor_constant39' to 'self.stages/0/blocks/2/token_mixer/norm/identity/running_var', normalized from original parameter name 'stages.0.blocks.2.token_mixer.norm.identity.running_var'.\nRenamed 'self._param_constant65' to 'self.stages/0/blocks/2/token_mixer/layer_scale/gamma', normalized from original parameter name 'stages.0.blocks.2.token_mixer.layer_scale.gamma'.\nRenamed 'self._param_constant66' to 'self.stages/0/blocks/2/mlp/conv/conv/weight', normalized from original parameter name 'stages.0.blocks.2.mlp.conv.conv.weight'.\nRenamed 'self._param_constant67' to 'self.stages/0/blocks/2/mlp/conv/bn/weight', normalized from original parameter name 'stages.0.blocks.2.mlp.conv.bn.weight'.\nRenamed 'self._param_constant68' to 'self.stages/0/blocks/2/mlp/conv/bn/bias', normalized from original parameter name 'stages.0.blocks.2.mlp.conv.bn.bias'.\nRenamed 'self._tensor_constant40' to 'self.stages/0/blocks/2/mlp/conv/bn/running_mean', normalized from original parameter name 'stages.0.blocks.2.mlp.conv.bn.running_mean'.\nRenamed 'self._tensor_constant41' to 'self.stages/0/blocks/2/mlp/conv/bn/running_var', normalized from original parameter name 'stages.0.blocks.2.mlp.conv.bn.running_var'.\nRenamed 'self._param_constant69' to 'self.stages/0/blocks/2/mlp/fc1/weight', normalized from original parameter name 'stages.0.blocks.2.mlp.fc1.weight'.\nRenamed 'self._param_constant70' to 'self.stages/0/blocks/2/mlp/fc1/bias', normalized from original parameter name 'stages.0.blocks.2.mlp.fc1.bias'.\nRenamed 'self._param_constant71' to 'self.stages/0/blocks/2/mlp/fc2/weight', normalized from original parameter name 'stages.0.blocks.2.mlp.fc2.weight'.\nRenamed 'self._param_constant72' to 'self.stages/0/blocks/2/mlp/fc2/bias', normalized from original parameter name 'stages.0.blocks.2.mlp.fc2.bias'.\nRenamed 'self._param_constant73' to 'self.stages/0/blocks/2/layer_scale/gamma', normalized from original parameter name 'stages.0.blocks.2.layer_scale.gamma'.\nRenamed 'self._param_constant74' to 'self.stages/0/blocks/3/token_mixer/mixer/identity/weight', normalized from original parameter name 'stages.0.blocks.3.token_mixer.mixer.identity.weight'.\nRenamed 'self._param_constant75' to 'self.stages/0/blocks/3/token_mixer/mixer/identity/bias', normalized from original parameter name 'stages.0.blocks.3.token_mixer.mixer.identity.bias'.\nRenamed 'self._tensor_constant42' to 'self.stages/0/blocks/3/token_mixer/mixer/identity/running_mean', normalized from original parameter name 'stages.0.blocks.3.token_mixer.mixer.identity.running_mean'.\nRenamed 'self._tensor_constant43' to 'self.stages/0/blocks/3/token_mixer/mixer/identity/running_var', normalized from original parameter name 'stages.0.blocks.3.token_mixer.mixer.identity.running_var'.\nRenamed 'self._param_constant76' to 'self.stages/0/blocks/3/token_mixer/mixer/conv_scale/conv/weight', normalized from original parameter name 'stages.0.blocks.3.token_mixer.mixer.conv_scale.conv.weight'.\nRenamed 'self._param_constant77' to 'self.stages/0/blocks/3/token_mixer/mixer/conv_scale/bn/weight', normalized from original parameter name 'stages.0.blocks.3.token_mixer.mixer.conv_scale.bn.weight'.\nRenamed 'self._param_constant78' to 'self.stages/0/blocks/3/token_mixer/mixer/conv_scale/bn/bias', normalized from original parameter name 'stages.0.blocks.3.token_mixer.mixer.conv_scale.bn.bias'.\nRenamed 'self._tensor_constant44' to 'self.stages/0/blocks/3/token_mixer/mixer/conv_scale/bn/running_mean', normalized from original parameter name 'stages.0.blocks.3.token_mixer.mixer.conv_scale.bn.running_mean'.\nRenamed 'self._tensor_constant45' to 'self.stages/0/blocks/3/token_mixer/mixer/conv_scale/bn/running_var', normalized from original parameter name 'stages.0.blocks.3.token_mixer.mixer.conv_scale.bn.running_var'.\nRenamed 'self._param_constant79' to 'self.stages/0/blocks/3/token_mixer/mixer/conv_kxk/0/conv/weight', normalized from original parameter name 'stages.0.blocks.3.token_mixer.mixer.conv_kxk.0.conv.weight'.\nRenamed 'self._param_constant80' to 'self.stages/0/blocks/3/token_mixer/mixer/conv_kxk/0/bn/weight', normalized from original parameter name 'stages.0.blocks.3.token_mixer.mixer.conv_kxk.0.bn.weight'.\nRenamed 'self._param_constant81' to 'self.stages/0/blocks/3/token_mixer/mixer/conv_kxk/0/bn/bias', normalized from original parameter name 'stages.0.blocks.3.token_mixer.mixer.conv_kxk.0.bn.bias'.\nRenamed 'self._tensor_constant46' to 'self.stages/0/blocks/3/token_mixer/mixer/conv_kxk/0/bn/running_mean', normalized from original parameter name 'stages.0.blocks.3.token_mixer.mixer.conv_kxk.0.bn.running_mean'.\nRenamed 'self._tensor_constant47' to 'self.stages/0/blocks/3/token_mixer/mixer/conv_kxk/0/bn/running_var', normalized from original parameter name 'stages.0.blocks.3.token_mixer.mixer.conv_kxk.0.bn.running_var'.\nRenamed 'self._param_constant82' to 'self.stages/0/blocks/3/token_mixer/norm/identity/weight', normalized from original parameter name 'stages.0.blocks.3.token_mixer.norm.identity.weight'.\nRenamed 'self._param_constant83' to 'self.stages/0/blocks/3/token_mixer/norm/identity/bias', normalized from original parameter name 'stages.0.blocks.3.token_mixer.norm.identity.bias'.\nRenamed 'self._tensor_constant48' to 'self.stages/0/blocks/3/token_mixer/norm/identity/running_mean', normalized from original parameter name 'stages.0.blocks.3.token_mixer.norm.identity.running_mean'.\nRenamed 'self._tensor_constant49' to 'self.stages/0/blocks/3/token_mixer/norm/identity/running_var', normalized from original parameter name 'stages.0.blocks.3.token_mixer.norm.identity.running_var'.\nRenamed 'self._param_constant84' to 'self.stages/0/blocks/3/token_mixer/layer_scale/gamma', normalized from original parameter name 'stages.0.blocks.3.token_mixer.layer_scale.gamma'.\nRenamed 'self._param_constant85' to 'self.stages/0/blocks/3/mlp/conv/conv/weight', normalized from original parameter name 'stages.0.blocks.3.mlp.conv.conv.weight'.\nRenamed 'self._param_constant86' to 'self.stages/0/blocks/3/mlp/conv/bn/weight', normalized from original parameter name 'stages.0.blocks.3.mlp.conv.bn.weight'.\nRenamed 'self._param_constant87' to 'self.stages/0/blocks/3/mlp/conv/bn/bias', normalized from original parameter name 'stages.0.blocks.3.mlp.conv.bn.bias'.\nRenamed 'self._tensor_constant50' to 'self.stages/0/blocks/3/mlp/conv/bn/running_mean', normalized from original parameter name 'stages.0.blocks.3.mlp.conv.bn.running_mean'.\nRenamed 'self._tensor_constant51' to 'self.stages/0/blocks/3/mlp/conv/bn/running_var', normalized from original parameter name 'stages.0.blocks.3.mlp.conv.bn.running_var'.\nRenamed 'self._param_constant88' to 'self.stages/0/blocks/3/mlp/fc1/weight', normalized from original parameter name 'stages.0.blocks.3.mlp.fc1.weight'.\nRenamed 'self._param_constant89' to 'self.stages/0/blocks/3/mlp/fc1/bias', normalized from original parameter name 'stages.0.blocks.3.mlp.fc1.bias'.\nRenamed 'self._param_constant90' to 'self.stages/0/blocks/3/mlp/fc2/weight', normalized from original parameter name 'stages.0.blocks.3.mlp.fc2.weight'.\nRenamed 'self._param_constant91' to 'self.stages/0/blocks/3/mlp/fc2/bias', normalized from original parameter name 'stages.0.blocks.3.mlp.fc2.bias'.\nRenamed 'self._param_constant92' to 'self.stages/0/blocks/3/layer_scale/gamma', normalized from original parameter name 'stages.0.blocks.3.layer_scale.gamma'.\nRenamed 'self._param_constant93' to 'self.stages/1/downsample/proj/0/large_conv/conv/weight', normalized from original parameter name 'stages.1.downsample.proj.0.large_conv.conv.weight'.\nRenamed 'self._param_constant94' to 'self.stages/1/downsample/proj/0/large_conv/bn/weight', normalized from original parameter name 'stages.1.downsample.proj.0.large_conv.bn.weight'.\nRenamed 'self._param_constant95' to 'self.stages/1/downsample/proj/0/large_conv/bn/bias', normalized from original parameter name 'stages.1.downsample.proj.0.large_conv.bn.bias'.\nRenamed 'self._tensor_constant52' to 'self.stages/1/downsample/proj/0/large_conv/bn/running_mean', normalized from original parameter name 'stages.1.downsample.proj.0.large_conv.bn.running_mean'.\nRenamed 'self._tensor_constant53' to 'self.stages/1/downsample/proj/0/large_conv/bn/running_var', normalized from original parameter name 'stages.1.downsample.proj.0.large_conv.bn.running_var'.\nRenamed 'self._param_constant96' to 'self.stages/1/downsample/proj/0/small_conv/conv/weight', normalized from original parameter name 'stages.1.downsample.proj.0.small_conv.conv.weight'.\nRenamed 'self._param_constant97' to 'self.stages/1/downsample/proj/0/small_conv/bn/weight', normalized from original parameter name 'stages.1.downsample.proj.0.small_conv.bn.weight'.\nRenamed 'self._param_constant98' to 'self.stages/1/downsample/proj/0/small_conv/bn/bias', normalized from original parameter name 'stages.1.downsample.proj.0.small_conv.bn.bias'.\nRenamed 'self._tensor_constant54' to 'self.stages/1/downsample/proj/0/small_conv/bn/running_mean', normalized from original parameter name 'stages.1.downsample.proj.0.small_conv.bn.running_mean'.\nRenamed 'self._tensor_constant55' to 'self.stages/1/downsample/proj/0/small_conv/bn/running_var', normalized from original parameter name 'stages.1.downsample.proj.0.small_conv.bn.running_var'.\nRenamed 'self._param_constant99' to 'self.stages/1/downsample/proj/1/identity/weight', normalized from original parameter name 'stages.1.downsample.proj.1.identity.weight'.\nRenamed 'self._param_constant100' to 'self.stages/1/downsample/proj/1/identity/bias', normalized from original parameter name 'stages.1.downsample.proj.1.identity.bias'.\nRenamed 'self._tensor_constant56' to 'self.stages/1/downsample/proj/1/identity/running_mean', normalized from original parameter name 'stages.1.downsample.proj.1.identity.running_mean'.\nRenamed 'self._tensor_constant57' to 'self.stages/1/downsample/proj/1/identity/running_var', normalized from original parameter name 'stages.1.downsample.proj.1.identity.running_var'.\nRenamed 'self._param_constant101' to 'self.stages/1/downsample/proj/1/conv_kxk/0/conv/weight', normalized from original parameter name 'stages.1.downsample.proj.1.conv_kxk.0.conv.weight'.\nRenamed 'self._param_constant102' to 'self.stages/1/downsample/proj/1/conv_kxk/0/bn/weight', normalized from original parameter name 'stages.1.downsample.proj.1.conv_kxk.0.bn.weight'.\nRenamed 'self._param_constant103' to 'self.stages/1/downsample/proj/1/conv_kxk/0/bn/bias', normalized from original parameter name 'stages.1.downsample.proj.1.conv_kxk.0.bn.bias'.\nRenamed 'self._tensor_constant58' to 'self.stages/1/downsample/proj/1/conv_kxk/0/bn/running_mean', normalized from original parameter name 'stages.1.downsample.proj.1.conv_kxk.0.bn.running_mean'.\nRenamed 'self._tensor_constant59' to 'self.stages/1/downsample/proj/1/conv_kxk/0/bn/running_var', normalized from original parameter name 'stages.1.downsample.proj.1.conv_kxk.0.bn.running_var'.\nRenamed 'self._param_constant104' to 'self.stages/1/blocks/0/token_mixer/mixer/identity/weight', normalized from original parameter name 'stages.1.blocks.0.token_mixer.mixer.identity.weight'.\nRenamed 'self._param_constant105' to 'self.stages/1/blocks/0/token_mixer/mixer/identity/bias', normalized from original parameter name 'stages.1.blocks.0.token_mixer.mixer.identity.bias'.\nRenamed 'self._tensor_constant60' to 'self.stages/1/blocks/0/token_mixer/mixer/identity/running_mean', normalized from original parameter name 'stages.1.blocks.0.token_mixer.mixer.identity.running_mean'.\nRenamed 'self._tensor_constant61' to 'self.stages/1/blocks/0/token_mixer/mixer/identity/running_var', normalized from original parameter name 'stages.1.blocks.0.token_mixer.mixer.identity.running_var'.\nRenamed 'self._param_constant106' to 'self.stages/1/blocks/0/token_mixer/mixer/conv_scale/conv/weight', normalized from original parameter name 'stages.1.blocks.0.token_mixer.mixer.conv_scale.conv.weight'.\nRenamed 'self._param_constant107' to 'self.stages/1/blocks/0/token_mixer/mixer/conv_scale/bn/weight', normalized from original parameter name 'stages.1.blocks.0.token_mixer.mixer.conv_scale.bn.weight'.\nRenamed 'self._param_constant108' to 'self.stages/1/blocks/0/token_mixer/mixer/conv_scale/bn/bias', normalized from original parameter name 'stages.1.blocks.0.token_mixer.mixer.conv_scale.bn.bias'.\nRenamed 'self._tensor_constant62' to 'self.stages/1/blocks/0/token_mixer/mixer/conv_scale/bn/running_mean', normalized from original parameter name 'stages.1.blocks.0.token_mixer.mixer.conv_scale.bn.running_mean'.\nRenamed 'self._tensor_constant63' to 'self.stages/1/blocks/0/token_mixer/mixer/conv_scale/bn/running_var', normalized from original parameter name 'stages.1.blocks.0.token_mixer.mixer.conv_scale.bn.running_var'.\nRenamed 'self._param_constant109' to 'self.stages/1/blocks/0/token_mixer/mixer/conv_kxk/0/conv/weight', normalized from original parameter name 'stages.1.blocks.0.token_mixer.mixer.conv_kxk.0.conv.weight'.\nRenamed 'self._param_constant110' to 'self.stages/1/blocks/0/token_mixer/mixer/conv_kxk/0/bn/weight', normalized from original parameter name 'stages.1.blocks.0.token_mixer.mixer.conv_kxk.0.bn.weight'.\nRenamed 'self._param_constant111' to 'self.stages/1/blocks/0/token_mixer/mixer/conv_kxk/0/bn/bias', normalized from original parameter name 'stages.1.blocks.0.token_mixer.mixer.conv_kxk.0.bn.bias'.\nRenamed 'self._tensor_constant64' to 'self.stages/1/blocks/0/token_mixer/mixer/conv_kxk/0/bn/running_mean', normalized from original parameter name 'stages.1.blocks.0.token_mixer.mixer.conv_kxk.0.bn.running_mean'.\nRenamed 'self._tensor_constant65' to 'self.stages/1/blocks/0/token_mixer/mixer/conv_kxk/0/bn/running_var', normalized from original parameter name 'stages.1.blocks.0.token_mixer.mixer.conv_kxk.0.bn.running_var'.\nRenamed 'self._param_constant112' to 'self.stages/1/blocks/0/token_mixer/norm/identity/weight', normalized from original parameter name 'stages.1.blocks.0.token_mixer.norm.identity.weight'.\nRenamed 'self._param_constant113' to 'self.stages/1/blocks/0/token_mixer/norm/identity/bias', normalized from original parameter name 'stages.1.blocks.0.token_mixer.norm.identity.bias'.\nRenamed 'self._tensor_constant66' to 'self.stages/1/blocks/0/token_mixer/norm/identity/running_mean', normalized from original parameter name 'stages.1.blocks.0.token_mixer.norm.identity.running_mean'.\nRenamed 'self._tensor_constant67' to 'self.stages/1/blocks/0/token_mixer/norm/identity/running_var', normalized from original parameter name 'stages.1.blocks.0.token_mixer.norm.identity.running_var'.\nRenamed 'self._param_constant114' to 'self.stages/1/blocks/0/token_mixer/layer_scale/gamma', normalized from original parameter name 'stages.1.blocks.0.token_mixer.layer_scale.gamma'.\nRenamed 'self._param_constant115' to 'self.stages/1/blocks/0/mlp/conv/conv/weight', normalized from original parameter name 'stages.1.blocks.0.mlp.conv.conv.weight'.\nRenamed 'self._param_constant116' to 'self.stages/1/blocks/0/mlp/conv/bn/weight', normalized from original parameter name 'stages.1.blocks.0.mlp.conv.bn.weight'.\nRenamed 'self._param_constant117' to 'self.stages/1/blocks/0/mlp/conv/bn/bias', normalized from original parameter name 'stages.1.blocks.0.mlp.conv.bn.bias'.\nRenamed 'self._tensor_constant68' to 'self.stages/1/blocks/0/mlp/conv/bn/running_mean', normalized from original parameter name 'stages.1.blocks.0.mlp.conv.bn.running_mean'.\nRenamed 'self._tensor_constant69' to 'self.stages/1/blocks/0/mlp/conv/bn/running_var', normalized from original parameter name 'stages.1.blocks.0.mlp.conv.bn.running_var'.\nRenamed 'self._param_constant118' to 'self.stages/1/blocks/0/mlp/fc1/weight', normalized from original parameter name 'stages.1.blocks.0.mlp.fc1.weight'.\nRenamed 'self._param_constant119' to 'self.stages/1/blocks/0/mlp/fc1/bias', normalized from original parameter name 'stages.1.blocks.0.mlp.fc1.bias'.\nRenamed 'self._param_constant120' to 'self.stages/1/blocks/0/mlp/fc2/weight', normalized from original parameter name 'stages.1.blocks.0.mlp.fc2.weight'.\nRenamed 'self._param_constant121' to 'self.stages/1/blocks/0/mlp/fc2/bias', normalized from original parameter name 'stages.1.blocks.0.mlp.fc2.bias'.\nRenamed 'self._param_constant122' to 'self.stages/1/blocks/0/layer_scale/gamma', normalized from original parameter name 'stages.1.blocks.0.layer_scale.gamma'.\nRenamed 'self._param_constant123' to 'self.stages/1/blocks/1/token_mixer/mixer/identity/weight', normalized from original parameter name 'stages.1.blocks.1.token_mixer.mixer.identity.weight'.\nRenamed 'self._param_constant124' to 'self.stages/1/blocks/1/token_mixer/mixer/identity/bias', normalized from original parameter name 'stages.1.blocks.1.token_mixer.mixer.identity.bias'.\nRenamed 'self._tensor_constant70' to 'self.stages/1/blocks/1/token_mixer/mixer/identity/running_mean', normalized from original parameter name 'stages.1.blocks.1.token_mixer.mixer.identity.running_mean'.\nRenamed 'self._tensor_constant71' to 'self.stages/1/blocks/1/token_mixer/mixer/identity/running_var', normalized from original parameter name 'stages.1.blocks.1.token_mixer.mixer.identity.running_var'.\nRenamed 'self._param_constant125' to 'self.stages/1/blocks/1/token_mixer/mixer/conv_scale/conv/weight', normalized from original parameter name 'stages.1.blocks.1.token_mixer.mixer.conv_scale.conv.weight'.\nRenamed 'self._param_constant126' to 'self.stages/1/blocks/1/token_mixer/mixer/conv_scale/bn/weight', normalized from original parameter name 'stages.1.blocks.1.token_mixer.mixer.conv_scale.bn.weight'.\nRenamed 'self._param_constant127' to 'self.stages/1/blocks/1/token_mixer/mixer/conv_scale/bn/bias', normalized from original parameter name 'stages.1.blocks.1.token_mixer.mixer.conv_scale.bn.bias'.\nRenamed 'self._tensor_constant72' to 'self.stages/1/blocks/1/token_mixer/mixer/conv_scale/bn/running_mean', normalized from original parameter name 'stages.1.blocks.1.token_mixer.mixer.conv_scale.bn.running_mean'.\nRenamed 'self._tensor_constant73' to 'self.stages/1/blocks/1/token_mixer/mixer/conv_scale/bn/running_var', normalized from original parameter name 'stages.1.blocks.1.token_mixer.mixer.conv_scale.bn.running_var'.\nRenamed 'self._param_constant128' to 'self.stages/1/blocks/1/token_mixer/mixer/conv_kxk/0/conv/weight', normalized from original parameter name 'stages.1.blocks.1.token_mixer.mixer.conv_kxk.0.conv.weight'.\nRenamed 'self._param_constant129' to 'self.stages/1/blocks/1/token_mixer/mixer/conv_kxk/0/bn/weight', normalized from original parameter name 'stages.1.blocks.1.token_mixer.mixer.conv_kxk.0.bn.weight'.\nRenamed 'self._param_constant130' to 'self.stages/1/blocks/1/token_mixer/mixer/conv_kxk/0/bn/bias', normalized from original parameter name 'stages.1.blocks.1.token_mixer.mixer.conv_kxk.0.bn.bias'.\nRenamed 'self._tensor_constant74' to 'self.stages/1/blocks/1/token_mixer/mixer/conv_kxk/0/bn/running_mean', normalized from original parameter name 'stages.1.blocks.1.token_mixer.mixer.conv_kxk.0.bn.running_mean'.\nRenamed 'self._tensor_constant75' to 'self.stages/1/blocks/1/token_mixer/mixer/conv_kxk/0/bn/running_var', normalized from original parameter name 'stages.1.blocks.1.token_mixer.mixer.conv_kxk.0.bn.running_var'.\nRenamed 'self._param_constant131' to 'self.stages/1/blocks/1/token_mixer/norm/identity/weight', normalized from original parameter name 'stages.1.blocks.1.token_mixer.norm.identity.weight'.\nRenamed 'self._param_constant132' to 'self.stages/1/blocks/1/token_mixer/norm/identity/bias', normalized from original parameter name 'stages.1.blocks.1.token_mixer.norm.identity.bias'.\nRenamed 'self._tensor_constant76' to 'self.stages/1/blocks/1/token_mixer/norm/identity/running_mean', normalized from original parameter name 'stages.1.blocks.1.token_mixer.norm.identity.running_mean'.\nRenamed 'self._tensor_constant77' to 'self.stages/1/blocks/1/token_mixer/norm/identity/running_var', normalized from original parameter name 'stages.1.blocks.1.token_mixer.norm.identity.running_var'.\nRenamed 'self._param_constant133' to 'self.stages/1/blocks/1/token_mixer/layer_scale/gamma', normalized from original parameter name 'stages.1.blocks.1.token_mixer.layer_scale.gamma'.\nRenamed 'self._param_constant134' to 'self.stages/1/blocks/1/mlp/conv/conv/weight', normalized from original parameter name 'stages.1.blocks.1.mlp.conv.conv.weight'.\nRenamed 'self._param_constant135' to 'self.stages/1/blocks/1/mlp/conv/bn/weight', normalized from original parameter name 'stages.1.blocks.1.mlp.conv.bn.weight'.\nRenamed 'self._param_constant136' to 'self.stages/1/blocks/1/mlp/conv/bn/bias', normalized from original parameter name 'stages.1.blocks.1.mlp.conv.bn.bias'.\nRenamed 'self._tensor_constant78' to 'self.stages/1/blocks/1/mlp/conv/bn/running_mean', normalized from original parameter name 'stages.1.blocks.1.mlp.conv.bn.running_mean'.\nRenamed 'self._tensor_constant79' to 'self.stages/1/blocks/1/mlp/conv/bn/running_var', normalized from original parameter name 'stages.1.blocks.1.mlp.conv.bn.running_var'.\nRenamed 'self._param_constant137' to 'self.stages/1/blocks/1/mlp/fc1/weight', normalized from original parameter name 'stages.1.blocks.1.mlp.fc1.weight'.\nRenamed 'self._param_constant138' to 'self.stages/1/blocks/1/mlp/fc1/bias', normalized from original parameter name 'stages.1.blocks.1.mlp.fc1.bias'.\nRenamed 'self._param_constant139' to 'self.stages/1/blocks/1/mlp/fc2/weight', normalized from original parameter name 'stages.1.blocks.1.mlp.fc2.weight'.\nRenamed 'self._param_constant140' to 'self.stages/1/blocks/1/mlp/fc2/bias', normalized from original parameter name 'stages.1.blocks.1.mlp.fc2.bias'.\nRenamed 'self._param_constant141' to 'self.stages/1/blocks/1/layer_scale/gamma', normalized from original parameter name 'stages.1.blocks.1.layer_scale.gamma'.\nRenamed 'self._param_constant142' to 'self.stages/1/blocks/2/token_mixer/mixer/identity/weight', normalized from original parameter name 'stages.1.blocks.2.token_mixer.mixer.identity.weight'.\nRenamed 'self._param_constant143' to 'self.stages/1/blocks/2/token_mixer/mixer/identity/bias', normalized from original parameter name 'stages.1.blocks.2.token_mixer.mixer.identity.bias'.\nRenamed 'self._tensor_constant80' to 'self.stages/1/blocks/2/token_mixer/mixer/identity/running_mean', normalized from original parameter name 'stages.1.blocks.2.token_mixer.mixer.identity.running_mean'.\nRenamed 'self._tensor_constant81' to 'self.stages/1/blocks/2/token_mixer/mixer/identity/running_var', normalized from original parameter name 'stages.1.blocks.2.token_mixer.mixer.identity.running_var'.\nRenamed 'self._param_constant144' to 'self.stages/1/blocks/2/token_mixer/mixer/conv_scale/conv/weight', normalized from original parameter name 'stages.1.blocks.2.token_mixer.mixer.conv_scale.conv.weight'.\nRenamed 'self._param_constant145' to 'self.stages/1/blocks/2/token_mixer/mixer/conv_scale/bn/weight', normalized from original parameter name 'stages.1.blocks.2.token_mixer.mixer.conv_scale.bn.weight'.\nRenamed 'self._param_constant146' to 'self.stages/1/blocks/2/token_mixer/mixer/conv_scale/bn/bias', normalized from original parameter name 'stages.1.blocks.2.token_mixer.mixer.conv_scale.bn.bias'.\nRenamed 'self._tensor_constant82' to 'self.stages/1/blocks/2/token_mixer/mixer/conv_scale/bn/running_mean', normalized from original parameter name 'stages.1.blocks.2.token_mixer.mixer.conv_scale.bn.running_mean'.\nRenamed 'self._tensor_constant83' to 'self.stages/1/blocks/2/token_mixer/mixer/conv_scale/bn/running_var', normalized from original parameter name 'stages.1.blocks.2.token_mixer.mixer.conv_scale.bn.running_var'.\nRenamed 'self._param_constant147' to 'self.stages/1/blocks/2/token_mixer/mixer/conv_kxk/0/conv/weight', normalized from original parameter name 'stages.1.blocks.2.token_mixer.mixer.conv_kxk.0.conv.weight'.\nRenamed 'self._param_constant148' to 'self.stages/1/blocks/2/token_mixer/mixer/conv_kxk/0/bn/weight', normalized from original parameter name 'stages.1.blocks.2.token_mixer.mixer.conv_kxk.0.bn.weight'.\nRenamed 'self._param_constant149' to 'self.stages/1/blocks/2/token_mixer/mixer/conv_kxk/0/bn/bias', normalized from original parameter name 'stages.1.blocks.2.token_mixer.mixer.conv_kxk.0.bn.bias'.\nRenamed 'self._tensor_constant84' to 'self.stages/1/blocks/2/token_mixer/mixer/conv_kxk/0/bn/running_mean', normalized from original parameter name 'stages.1.blocks.2.token_mixer.mixer.conv_kxk.0.bn.running_mean'.\nRenamed 'self._tensor_constant85' to 'self.stages/1/blocks/2/token_mixer/mixer/conv_kxk/0/bn/running_var', normalized from original parameter name 'stages.1.blocks.2.token_mixer.mixer.conv_kxk.0.bn.running_var'.\nRenamed 'self._param_constant150' to 'self.stages/1/blocks/2/token_mixer/norm/identity/weight', normalized from original parameter name 'stages.1.blocks.2.token_mixer.norm.identity.weight'.\nRenamed 'self._param_constant151' to 'self.stages/1/blocks/2/token_mixer/norm/identity/bias', normalized from original parameter name 'stages.1.blocks.2.token_mixer.norm.identity.bias'.\nRenamed 'self._tensor_constant86' to 'self.stages/1/blocks/2/token_mixer/norm/identity/running_mean', normalized from original parameter name 'stages.1.blocks.2.token_mixer.norm.identity.running_mean'.\nRenamed 'self._tensor_constant87' to 'self.stages/1/blocks/2/token_mixer/norm/identity/running_var', normalized from original parameter name 'stages.1.blocks.2.token_mixer.norm.identity.running_var'.\nRenamed 'self._param_constant152' to 'self.stages/1/blocks/2/token_mixer/layer_scale/gamma', normalized from original parameter name 'stages.1.blocks.2.token_mixer.layer_scale.gamma'.\nRenamed 'self._param_constant153' to 'self.stages/1/blocks/2/mlp/conv/conv/weight', normalized from original parameter name 'stages.1.blocks.2.mlp.conv.conv.weight'.\nRenamed 'self._param_constant154' to 'self.stages/1/blocks/2/mlp/conv/bn/weight', normalized from original parameter name 'stages.1.blocks.2.mlp.conv.bn.weight'.\nRenamed 'self._param_constant155' to 'self.stages/1/blocks/2/mlp/conv/bn/bias', normalized from original parameter name 'stages.1.blocks.2.mlp.conv.bn.bias'.\nRenamed 'self._tensor_constant88' to 'self.stages/1/blocks/2/mlp/conv/bn/running_mean', normalized from original parameter name 'stages.1.blocks.2.mlp.conv.bn.running_mean'.\nRenamed 'self._tensor_constant89' to 'self.stages/1/blocks/2/mlp/conv/bn/running_var', normalized from original parameter name 'stages.1.blocks.2.mlp.conv.bn.running_var'.\nRenamed 'self._param_constant156' to 'self.stages/1/blocks/2/mlp/fc1/weight', normalized from original parameter name 'stages.1.blocks.2.mlp.fc1.weight'.\nRenamed 'self._param_constant157' to 'self.stages/1/blocks/2/mlp/fc1/bias', normalized from original parameter name 'stages.1.blocks.2.mlp.fc1.bias'.\nRenamed 'self._param_constant158' to 'self.stages/1/blocks/2/mlp/fc2/weight', normalized from original parameter name 'stages.1.blocks.2.mlp.fc2.weight'.\nRenamed 'self._param_constant159' to 'self.stages/1/blocks/2/mlp/fc2/bias', normalized from original parameter name 'stages.1.blocks.2.mlp.fc2.bias'.\nRenamed 'self._param_constant160' to 'self.stages/1/blocks/2/layer_scale/gamma', normalized from original parameter name 'stages.1.blocks.2.layer_scale.gamma'.\nRenamed 'self._param_constant161' to 'self.stages/1/blocks/3/token_mixer/mixer/identity/weight', normalized from original parameter name 'stages.1.blocks.3.token_mixer.mixer.identity.weight'.\nRenamed 'self._param_constant162' to 'self.stages/1/blocks/3/token_mixer/mixer/identity/bias', normalized from original parameter name 'stages.1.blocks.3.token_mixer.mixer.identity.bias'.\nRenamed 'self._tensor_constant90' to 'self.stages/1/blocks/3/token_mixer/mixer/identity/running_mean', normalized from original parameter name 'stages.1.blocks.3.token_mixer.mixer.identity.running_mean'.\nRenamed 'self._tensor_constant91' to 'self.stages/1/blocks/3/token_mixer/mixer/identity/running_var', normalized from original parameter name 'stages.1.blocks.3.token_mixer.mixer.identity.running_var'.\nRenamed 'self._param_constant163' to 'self.stages/1/blocks/3/token_mixer/mixer/conv_scale/conv/weight', normalized from original parameter name 'stages.1.blocks.3.token_mixer.mixer.conv_scale.conv.weight'.\nRenamed 'self._param_constant164' to 'self.stages/1/blocks/3/token_mixer/mixer/conv_scale/bn/weight', normalized from original parameter name 'stages.1.blocks.3.token_mixer.mixer.conv_scale.bn.weight'.\nRenamed 'self._param_constant165' to 'self.stages/1/blocks/3/token_mixer/mixer/conv_scale/bn/bias', normalized from original parameter name 'stages.1.blocks.3.token_mixer.mixer.conv_scale.bn.bias'.\nRenamed 'self._tensor_constant92' to 'self.stages/1/blocks/3/token_mixer/mixer/conv_scale/bn/running_mean', normalized from original parameter name 'stages.1.blocks.3.token_mixer.mixer.conv_scale.bn.running_mean'.\nRenamed 'self._tensor_constant93' to 'self.stages/1/blocks/3/token_mixer/mixer/conv_scale/bn/running_var', normalized from original parameter name 'stages.1.blocks.3.token_mixer.mixer.conv_scale.bn.running_var'.\nRenamed 'self._param_constant166' to 'self.stages/1/blocks/3/token_mixer/mixer/conv_kxk/0/conv/weight', normalized from original parameter name 'stages.1.blocks.3.token_mixer.mixer.conv_kxk.0.conv.weight'.\nRenamed 'self._param_constant167' to 'self.stages/1/blocks/3/token_mixer/mixer/conv_kxk/0/bn/weight', normalized from original parameter name 'stages.1.blocks.3.token_mixer.mixer.conv_kxk.0.bn.weight'.\nRenamed 'self._param_constant168' to 'self.stages/1/blocks/3/token_mixer/mixer/conv_kxk/0/bn/bias', normalized from original parameter name 'stages.1.blocks.3.token_mixer.mixer.conv_kxk.0.bn.bias'.\nRenamed 'self._tensor_constant94' to 'self.stages/1/blocks/3/token_mixer/mixer/conv_kxk/0/bn/running_mean', normalized from original parameter name 'stages.1.blocks.3.token_mixer.mixer.conv_kxk.0.bn.running_mean'.\nRenamed 'self._tensor_constant95' to 'self.stages/1/blocks/3/token_mixer/mixer/conv_kxk/0/bn/running_var', normalized from original parameter name 'stages.1.blocks.3.token_mixer.mixer.conv_kxk.0.bn.running_var'.\nRenamed 'self._param_constant169' to 'self.stages/1/blocks/3/token_mixer/norm/identity/weight', normalized from original parameter name 'stages.1.blocks.3.token_mixer.norm.identity.weight'.\nRenamed 'self._param_constant170' to 'self.stages/1/blocks/3/token_mixer/norm/identity/bias', normalized from original parameter name 'stages.1.blocks.3.token_mixer.norm.identity.bias'.\nRenamed 'self._tensor_constant96' to 'self.stages/1/blocks/3/token_mixer/norm/identity/running_mean', normalized from original parameter name 'stages.1.blocks.3.token_mixer.norm.identity.running_mean'.\nRenamed 'self._tensor_constant97' to 'self.stages/1/blocks/3/token_mixer/norm/identity/running_var', normalized from original parameter name 'stages.1.blocks.3.token_mixer.norm.identity.running_var'.\nRenamed 'self._param_constant171' to 'self.stages/1/blocks/3/token_mixer/layer_scale/gamma', normalized from original parameter name 'stages.1.blocks.3.token_mixer.layer_scale.gamma'.\nRenamed 'self._param_constant172' to 'self.stages/1/blocks/3/mlp/conv/conv/weight', normalized from original parameter name 'stages.1.blocks.3.mlp.conv.conv.weight'.\nRenamed 'self._param_constant173' to 'self.stages/1/blocks/3/mlp/conv/bn/weight', normalized from original parameter name 'stages.1.blocks.3.mlp.conv.bn.weight'.\nRenamed 'self._param_constant174' to 'self.stages/1/blocks/3/mlp/conv/bn/bias', normalized from original parameter name 'stages.1.blocks.3.mlp.conv.bn.bias'.\nRenamed 'self._tensor_constant98' to 'self.stages/1/blocks/3/mlp/conv/bn/running_mean', normalized from original parameter name 'stages.1.blocks.3.mlp.conv.bn.running_mean'.\nRenamed 'self._tensor_constant99' to 'self.stages/1/blocks/3/mlp/conv/bn/running_var', normalized from original parameter name 'stages.1.blocks.3.mlp.conv.bn.running_var'.\nRenamed 'self._param_constant175' to 'self.stages/1/blocks/3/mlp/fc1/weight', normalized from original parameter name 'stages.1.blocks.3.mlp.fc1.weight'.\nRenamed 'self._param_constant176' to 'self.stages/1/blocks/3/mlp/fc1/bias', normalized from original parameter name 'stages.1.blocks.3.mlp.fc1.bias'.\nRenamed 'self._param_constant177' to 'self.stages/1/blocks/3/mlp/fc2/weight', normalized from original parameter name 'stages.1.blocks.3.mlp.fc2.weight'.\nRenamed 'self._param_constant178' to 'self.stages/1/blocks/3/mlp/fc2/bias', normalized from original parameter name 'stages.1.blocks.3.mlp.fc2.bias'.\nRenamed 'self._param_constant179' to 'self.stages/1/blocks/3/layer_scale/gamma', normalized from original parameter name 'stages.1.blocks.3.layer_scale.gamma'.\nRenamed 'self._param_constant180' to 'self.stages/2/downsample/proj/0/large_conv/conv/weight', normalized from original parameter name 'stages.2.downsample.proj.0.large_conv.conv.weight'.\nRenamed 'self._param_constant181' to 'self.stages/2/downsample/proj/0/large_conv/bn/weight', normalized from original parameter name 'stages.2.downsample.proj.0.large_conv.bn.weight'.\nRenamed 'self._param_constant182' to 'self.stages/2/downsample/proj/0/large_conv/bn/bias', normalized from original parameter name 'stages.2.downsample.proj.0.large_conv.bn.bias'.\nRenamed 'self._tensor_constant100' to 'self.stages/2/downsample/proj/0/large_conv/bn/running_mean', normalized from original parameter name 'stages.2.downsample.proj.0.large_conv.bn.running_mean'.\nRenamed 'self._tensor_constant101' to 'self.stages/2/downsample/proj/0/large_conv/bn/running_var', normalized from original parameter name 'stages.2.downsample.proj.0.large_conv.bn.running_var'.\nRenamed 'self._param_constant183' to 'self.stages/2/downsample/proj/0/small_conv/conv/weight', normalized from original parameter name 'stages.2.downsample.proj.0.small_conv.conv.weight'.\nRenamed 'self._param_constant184' to 'self.stages/2/downsample/proj/0/small_conv/bn/weight', normalized from original parameter name 'stages.2.downsample.proj.0.small_conv.bn.weight'.\nRenamed 'self._param_constant185' to 'self.stages/2/downsample/proj/0/small_conv/bn/bias', normalized from original parameter name 'stages.2.downsample.proj.0.small_conv.bn.bias'.\nRenamed 'self._tensor_constant102' to 'self.stages/2/downsample/proj/0/small_conv/bn/running_mean', normalized from original parameter name 'stages.2.downsample.proj.0.small_conv.bn.running_mean'.\nRenamed 'self._tensor_constant103' to 'self.stages/2/downsample/proj/0/small_conv/bn/running_var', normalized from original parameter name 'stages.2.downsample.proj.0.small_conv.bn.running_var'.\nRenamed 'self._param_constant186' to 'self.stages/2/downsample/proj/1/identity/weight', normalized from original parameter name 'stages.2.downsample.proj.1.identity.weight'.\nRenamed 'self._param_constant187' to 'self.stages/2/downsample/proj/1/identity/bias', normalized from original parameter name 'stages.2.downsample.proj.1.identity.bias'.\nRenamed 'self._tensor_constant104' to 'self.stages/2/downsample/proj/1/identity/running_mean', normalized from original parameter name 'stages.2.downsample.proj.1.identity.running_mean'.\nRenamed 'self._tensor_constant105' to 'self.stages/2/downsample/proj/1/identity/running_var', normalized from original parameter name 'stages.2.downsample.proj.1.identity.running_var'.\nRenamed 'self._param_constant188' to 'self.stages/2/downsample/proj/1/conv_kxk/0/conv/weight', normalized from original parameter name 'stages.2.downsample.proj.1.conv_kxk.0.conv.weight'.\nRenamed 'self._param_constant189' to 'self.stages/2/downsample/proj/1/conv_kxk/0/bn/weight', normalized from original parameter name 'stages.2.downsample.proj.1.conv_kxk.0.bn.weight'.\nRenamed 'self._param_constant190' to 'self.stages/2/downsample/proj/1/conv_kxk/0/bn/bias', normalized from original parameter name 'stages.2.downsample.proj.1.conv_kxk.0.bn.bias'.\nRenamed 'self._tensor_constant106' to 'self.stages/2/downsample/proj/1/conv_kxk/0/bn/running_mean', normalized from original parameter name 'stages.2.downsample.proj.1.conv_kxk.0.bn.running_mean'.\nRenamed 'self._tensor_constant107' to 'self.stages/2/downsample/proj/1/conv_kxk/0/bn/running_var', normalized from original parameter name 'stages.2.downsample.proj.1.conv_kxk.0.bn.running_var'.\nRenamed 'self._param_constant191' to 'self.stages/2/blocks/0/token_mixer/mixer/identity/weight', normalized from original parameter name 'stages.2.blocks.0.token_mixer.mixer.identity.weight'.\nRenamed 'self._param_constant192' to 'self.stages/2/blocks/0/token_mixer/mixer/identity/bias', normalized from original parameter name 'stages.2.blocks.0.token_mixer.mixer.identity.bias'.\nRenamed 'self._tensor_constant108' to 'self.stages/2/blocks/0/token_mixer/mixer/identity/running_mean', normalized from original parameter name 'stages.2.blocks.0.token_mixer.mixer.identity.running_mean'.\nRenamed 'self._tensor_constant109' to 'self.stages/2/blocks/0/token_mixer/mixer/identity/running_var', normalized from original parameter name 'stages.2.blocks.0.token_mixer.mixer.identity.running_var'.\nRenamed 'self._param_constant193' to 'self.stages/2/blocks/0/token_mixer/mixer/conv_scale/conv/weight', normalized from original parameter name 'stages.2.blocks.0.token_mixer.mixer.conv_scale.conv.weight'.\nRenamed 'self._param_constant194' to 'self.stages/2/blocks/0/token_mixer/mixer/conv_scale/bn/weight', normalized from original parameter name 'stages.2.blocks.0.token_mixer.mixer.conv_scale.bn.weight'.\nRenamed 'self._param_constant195' to 'self.stages/2/blocks/0/token_mixer/mixer/conv_scale/bn/bias', normalized from original parameter name 'stages.2.blocks.0.token_mixer.mixer.conv_scale.bn.bias'.\nRenamed 'self._tensor_constant110' to 'self.stages/2/blocks/0/token_mixer/mixer/conv_scale/bn/running_mean', normalized from original parameter name 'stages.2.blocks.0.token_mixer.mixer.conv_scale.bn.running_mean'.\nRenamed 'self._tensor_constant111' to 'self.stages/2/blocks/0/token_mixer/mixer/conv_scale/bn/running_var', normalized from original parameter name 'stages.2.blocks.0.token_mixer.mixer.conv_scale.bn.running_var'.\nRenamed 'self._param_constant196' to 'self.stages/2/blocks/0/token_mixer/mixer/conv_kxk/0/conv/weight', normalized from original parameter name 'stages.2.blocks.0.token_mixer.mixer.conv_kxk.0.conv.weight'.\nRenamed 'self._param_constant197' to 'self.stages/2/blocks/0/token_mixer/mixer/conv_kxk/0/bn/weight', normalized from original parameter name 'stages.2.blocks.0.token_mixer.mixer.conv_kxk.0.bn.weight'.\nRenamed 'self._param_constant198' to 'self.stages/2/blocks/0/token_mixer/mixer/conv_kxk/0/bn/bias', normalized from original parameter name 'stages.2.blocks.0.token_mixer.mixer.conv_kxk.0.bn.bias'.\nRenamed 'self._tensor_constant112' to 'self.stages/2/blocks/0/token_mixer/mixer/conv_kxk/0/bn/running_mean', normalized from original parameter name 'stages.2.blocks.0.token_mixer.mixer.conv_kxk.0.bn.running_mean'.\nRenamed 'self._tensor_constant113' to 'self.stages/2/blocks/0/token_mixer/mixer/conv_kxk/0/bn/running_var', normalized from original parameter name 'stages.2.blocks.0.token_mixer.mixer.conv_kxk.0.bn.running_var'.\nRenamed 'self._param_constant199' to 'self.stages/2/blocks/0/token_mixer/norm/identity/weight', normalized from original parameter name 'stages.2.blocks.0.token_mixer.norm.identity.weight'.\nRenamed 'self._param_constant200' to 'self.stages/2/blocks/0/token_mixer/norm/identity/bias', normalized from original parameter name 'stages.2.blocks.0.token_mixer.norm.identity.bias'.\nRenamed 'self._tensor_constant114' to 'self.stages/2/blocks/0/token_mixer/norm/identity/running_mean', normalized from original parameter name 'stages.2.blocks.0.token_mixer.norm.identity.running_mean'.\nRenamed 'self._tensor_constant115' to 'self.stages/2/blocks/0/token_mixer/norm/identity/running_var', normalized from original parameter name 'stages.2.blocks.0.token_mixer.norm.identity.running_var'.\nRenamed 'self._param_constant201' to 'self.stages/2/blocks/0/token_mixer/layer_scale/gamma', normalized from original parameter name 'stages.2.blocks.0.token_mixer.layer_scale.gamma'.\nRenamed 'self._param_constant202' to 'self.stages/2/blocks/0/mlp/conv/conv/weight', normalized from original parameter name 'stages.2.blocks.0.mlp.conv.conv.weight'.\nRenamed 'self._param_constant203' to 'self.stages/2/blocks/0/mlp/conv/bn/weight', normalized from original parameter name 'stages.2.blocks.0.mlp.conv.bn.weight'.\nRenamed 'self._param_constant204' to 'self.stages/2/blocks/0/mlp/conv/bn/bias', normalized from original parameter name 'stages.2.blocks.0.mlp.conv.bn.bias'.\nRenamed 'self._tensor_constant116' to 'self.stages/2/blocks/0/mlp/conv/bn/running_mean', normalized from original parameter name 'stages.2.blocks.0.mlp.conv.bn.running_mean'.\nRenamed 'self._tensor_constant117' to 'self.stages/2/blocks/0/mlp/conv/bn/running_var', normalized from original parameter name 'stages.2.blocks.0.mlp.conv.bn.running_var'.\nRenamed 'self._param_constant205' to 'self.stages/2/blocks/0/mlp/fc1/weight', normalized from original parameter name 'stages.2.blocks.0.mlp.fc1.weight'.\nRenamed 'self._param_constant206' to 'self.stages/2/blocks/0/mlp/fc1/bias', normalized from original parameter name 'stages.2.blocks.0.mlp.fc1.bias'.\nRenamed 'self._param_constant207' to 'self.stages/2/blocks/0/mlp/fc2/weight', normalized from original parameter name 'stages.2.blocks.0.mlp.fc2.weight'.\nRenamed 'self._param_constant208' to 'self.stages/2/blocks/0/mlp/fc2/bias', normalized from original parameter name 'stages.2.blocks.0.mlp.fc2.bias'.\nRenamed 'self._param_constant209' to 'self.stages/2/blocks/0/layer_scale/gamma', normalized from original parameter name 'stages.2.blocks.0.layer_scale.gamma'.\nRenamed 'self._param_constant210' to 'self.stages/2/blocks/1/token_mixer/mixer/identity/weight', normalized from original parameter name 'stages.2.blocks.1.token_mixer.mixer.identity.weight'.\nRenamed 'self._param_constant211' to 'self.stages/2/blocks/1/token_mixer/mixer/identity/bias', normalized from original parameter name 'stages.2.blocks.1.token_mixer.mixer.identity.bias'.\nRenamed 'self._tensor_constant118' to 'self.stages/2/blocks/1/token_mixer/mixer/identity/running_mean', normalized from original parameter name 'stages.2.blocks.1.token_mixer.mixer.identity.running_mean'.\nRenamed 'self._tensor_constant119' to 'self.stages/2/blocks/1/token_mixer/mixer/identity/running_var', normalized from original parameter name 'stages.2.blocks.1.token_mixer.mixer.identity.running_var'.\nRenamed 'self._param_constant212' to 'self.stages/2/blocks/1/token_mixer/mixer/conv_scale/conv/weight', normalized from original parameter name 'stages.2.blocks.1.token_mixer.mixer.conv_scale.conv.weight'.\nRenamed 'self._param_constant213' to 'self.stages/2/blocks/1/token_mixer/mixer/conv_scale/bn/weight', normalized from original parameter name 'stages.2.blocks.1.token_mixer.mixer.conv_scale.bn.weight'.\nRenamed 'self._param_constant214' to 'self.stages/2/blocks/1/token_mixer/mixer/conv_scale/bn/bias', normalized from original parameter name 'stages.2.blocks.1.token_mixer.mixer.conv_scale.bn.bias'.\nRenamed 'self._tensor_constant120' to 'self.stages/2/blocks/1/token_mixer/mixer/conv_scale/bn/running_mean', normalized from original parameter name 'stages.2.blocks.1.token_mixer.mixer.conv_scale.bn.running_mean'.\nRenamed 'self._tensor_constant121' to 'self.stages/2/blocks/1/token_mixer/mixer/conv_scale/bn/running_var', normalized from original parameter name 'stages.2.blocks.1.token_mixer.mixer.conv_scale.bn.running_var'.\nRenamed 'self._param_constant215' to 'self.stages/2/blocks/1/token_mixer/mixer/conv_kxk/0/conv/weight', normalized from original parameter name 'stages.2.blocks.1.token_mixer.mixer.conv_kxk.0.conv.weight'.\nRenamed 'self._param_constant216' to 'self.stages/2/blocks/1/token_mixer/mixer/conv_kxk/0/bn/weight', normalized from original parameter name 'stages.2.blocks.1.token_mixer.mixer.conv_kxk.0.bn.weight'.\nRenamed 'self._param_constant217' to 'self.stages/2/blocks/1/token_mixer/mixer/conv_kxk/0/bn/bias', normalized from original parameter name 'stages.2.blocks.1.token_mixer.mixer.conv_kxk.0.bn.bias'.\nRenamed 'self._tensor_constant122' to 'self.stages/2/blocks/1/token_mixer/mixer/conv_kxk/0/bn/running_mean', normalized from original parameter name 'stages.2.blocks.1.token_mixer.mixer.conv_kxk.0.bn.running_mean'.\nRenamed 'self._tensor_constant123' to 'self.stages/2/blocks/1/token_mixer/mixer/conv_kxk/0/bn/running_var', normalized from original parameter name 'stages.2.blocks.1.token_mixer.mixer.conv_kxk.0.bn.running_var'.\nRenamed 'self._param_constant218' to 'self.stages/2/blocks/1/token_mixer/norm/identity/weight', normalized from original parameter name 'stages.2.blocks.1.token_mixer.norm.identity.weight'.\nRenamed 'self._param_constant219' to 'self.stages/2/blocks/1/token_mixer/norm/identity/bias', normalized from original parameter name 'stages.2.blocks.1.token_mixer.norm.identity.bias'.\nRenamed 'self._tensor_constant124' to 'self.stages/2/blocks/1/token_mixer/norm/identity/running_mean', normalized from original parameter name 'stages.2.blocks.1.token_mixer.norm.identity.running_mean'.\nRenamed 'self._tensor_constant125' to 'self.stages/2/blocks/1/token_mixer/norm/identity/running_var', normalized from original parameter name 'stages.2.blocks.1.token_mixer.norm.identity.running_var'.\nRenamed 'self._param_constant220' to 'self.stages/2/blocks/1/token_mixer/layer_scale/gamma', normalized from original parameter name 'stages.2.blocks.1.token_mixer.layer_scale.gamma'.\nRenamed 'self._param_constant221' to 'self.stages/2/blocks/1/mlp/conv/conv/weight', normalized from original parameter name 'stages.2.blocks.1.mlp.conv.conv.weight'.\nRenamed 'self._param_constant222' to 'self.stages/2/blocks/1/mlp/conv/bn/weight', normalized from original parameter name 'stages.2.blocks.1.mlp.conv.bn.weight'.\nRenamed 'self._param_constant223' to 'self.stages/2/blocks/1/mlp/conv/bn/bias', normalized from original parameter name 'stages.2.blocks.1.mlp.conv.bn.bias'.\nRenamed 'self._tensor_constant126' to 'self.stages/2/blocks/1/mlp/conv/bn/running_mean', normalized from original parameter name 'stages.2.blocks.1.mlp.conv.bn.running_mean'.\nRenamed 'self._tensor_constant127' to 'self.stages/2/blocks/1/mlp/conv/bn/running_var', normalized from original parameter name 'stages.2.blocks.1.mlp.conv.bn.running_var'.\nRenamed 'self._param_constant224' to 'self.stages/2/blocks/1/mlp/fc1/weight', normalized from original parameter name 'stages.2.blocks.1.mlp.fc1.weight'.\nRenamed 'self._param_constant225' to 'self.stages/2/blocks/1/mlp/fc1/bias', normalized from original parameter name 'stages.2.blocks.1.mlp.fc1.bias'.\nRenamed 'self._param_constant226' to 'self.stages/2/blocks/1/mlp/fc2/weight', normalized from original parameter name 'stages.2.blocks.1.mlp.fc2.weight'.\nRenamed 'self._param_constant227' to 'self.stages/2/blocks/1/mlp/fc2/bias', normalized from original parameter name 'stages.2.blocks.1.mlp.fc2.bias'.\nRenamed 'self._param_constant228' to 'self.stages/2/blocks/1/layer_scale/gamma', normalized from original parameter name 'stages.2.blocks.1.layer_scale.gamma'.\nRenamed 'self._param_constant229' to 'self.stages/2/blocks/2/token_mixer/mixer/identity/weight', normalized from original parameter name 'stages.2.blocks.2.token_mixer.mixer.identity.weight'.\nRenamed 'self._param_constant230' to 'self.stages/2/blocks/2/token_mixer/mixer/identity/bias', normalized from original parameter name 'stages.2.blocks.2.token_mixer.mixer.identity.bias'.\nRenamed 'self._tensor_constant128' to 'self.stages/2/blocks/2/token_mixer/mixer/identity/running_mean', normalized from original parameter name 'stages.2.blocks.2.token_mixer.mixer.identity.running_mean'.\nRenamed 'self._tensor_constant129' to 'self.stages/2/blocks/2/token_mixer/mixer/identity/running_var', normalized from original parameter name 'stages.2.blocks.2.token_mixer.mixer.identity.running_var'.\nRenamed 'self._param_constant231' to 'self.stages/2/blocks/2/token_mixer/mixer/conv_scale/conv/weight', normalized from original parameter name 'stages.2.blocks.2.token_mixer.mixer.conv_scale.conv.weight'.\nRenamed 'self._param_constant232' to 'self.stages/2/blocks/2/token_mixer/mixer/conv_scale/bn/weight', normalized from original parameter name 'stages.2.blocks.2.token_mixer.mixer.conv_scale.bn.weight'.\nRenamed 'self._param_constant233' to 'self.stages/2/blocks/2/token_mixer/mixer/conv_scale/bn/bias', normalized from original parameter name 'stages.2.blocks.2.token_mixer.mixer.conv_scale.bn.bias'.\nRenamed 'self._tensor_constant130' to 'self.stages/2/blocks/2/token_mixer/mixer/conv_scale/bn/running_mean', normalized from original parameter name 'stages.2.blocks.2.token_mixer.mixer.conv_scale.bn.running_mean'.\nRenamed 'self._tensor_constant131' to 'self.stages/2/blocks/2/token_mixer/mixer/conv_scale/bn/running_var', normalized from original parameter name 'stages.2.blocks.2.token_mixer.mixer.conv_scale.bn.running_var'.\nRenamed 'self._param_constant234' to 'self.stages/2/blocks/2/token_mixer/mixer/conv_kxk/0/conv/weight', normalized from original parameter name 'stages.2.blocks.2.token_mixer.mixer.conv_kxk.0.conv.weight'.\nRenamed 'self._param_constant235' to 'self.stages/2/blocks/2/token_mixer/mixer/conv_kxk/0/bn/weight', normalized from original parameter name 'stages.2.blocks.2.token_mixer.mixer.conv_kxk.0.bn.weight'.\nRenamed 'self._param_constant236' to 'self.stages/2/blocks/2/token_mixer/mixer/conv_kxk/0/bn/bias', normalized from original parameter name 'stages.2.blocks.2.token_mixer.mixer.conv_kxk.0.bn.bias'.\nRenamed 'self._tensor_constant132' to 'self.stages/2/blocks/2/token_mixer/mixer/conv_kxk/0/bn/running_mean', normalized from original parameter name 'stages.2.blocks.2.token_mixer.mixer.conv_kxk.0.bn.running_mean'.\nRenamed 'self._tensor_constant133' to 'self.stages/2/blocks/2/token_mixer/mixer/conv_kxk/0/bn/running_var', normalized from original parameter name 'stages.2.blocks.2.token_mixer.mixer.conv_kxk.0.bn.running_var'.\nRenamed 'self._param_constant237' to 'self.stages/2/blocks/2/token_mixer/norm/identity/weight', normalized from original parameter name 'stages.2.blocks.2.token_mixer.norm.identity.weight'.\nRenamed 'self._param_constant238' to 'self.stages/2/blocks/2/token_mixer/norm/identity/bias', normalized from original parameter name 'stages.2.blocks.2.token_mixer.norm.identity.bias'.\nRenamed 'self._tensor_constant134' to 'self.stages/2/blocks/2/token_mixer/norm/identity/running_mean', normalized from original parameter name 'stages.2.blocks.2.token_mixer.norm.identity.running_mean'.\nRenamed 'self._tensor_constant135' to 'self.stages/2/blocks/2/token_mixer/norm/identity/running_var', normalized from original parameter name 'stages.2.blocks.2.token_mixer.norm.identity.running_var'.\nRenamed 'self._param_constant239' to 'self.stages/2/blocks/2/token_mixer/layer_scale/gamma', normalized from original parameter name 'stages.2.blocks.2.token_mixer.layer_scale.gamma'.\nRenamed 'self._param_constant240' to 'self.stages/2/blocks/2/mlp/conv/conv/weight', normalized from original parameter name 'stages.2.blocks.2.mlp.conv.conv.weight'.\nRenamed 'self._param_constant241' to 'self.stages/2/blocks/2/mlp/conv/bn/weight', normalized from original parameter name 'stages.2.blocks.2.mlp.conv.bn.weight'.\nRenamed 'self._param_constant242' to 'self.stages/2/blocks/2/mlp/conv/bn/bias', normalized from original parameter name 'stages.2.blocks.2.mlp.conv.bn.bias'.\nRenamed 'self._tensor_constant136' to 'self.stages/2/blocks/2/mlp/conv/bn/running_mean', normalized from original parameter name 'stages.2.blocks.2.mlp.conv.bn.running_mean'.\nRenamed 'self._tensor_constant137' to 'self.stages/2/blocks/2/mlp/conv/bn/running_var', normalized from original parameter name 'stages.2.blocks.2.mlp.conv.bn.running_var'.\nRenamed 'self._param_constant243' to 'self.stages/2/blocks/2/mlp/fc1/weight', normalized from original parameter name 'stages.2.blocks.2.mlp.fc1.weight'.\nRenamed 'self._param_constant244' to 'self.stages/2/blocks/2/mlp/fc1/bias', normalized from original parameter name 'stages.2.blocks.2.mlp.fc1.bias'.\nRenamed 'self._param_constant245' to 'self.stages/2/blocks/2/mlp/fc2/weight', normalized from original parameter name 'stages.2.blocks.2.mlp.fc2.weight'.\nRenamed 'self._param_constant246' to 'self.stages/2/blocks/2/mlp/fc2/bias', normalized from original parameter name 'stages.2.blocks.2.mlp.fc2.bias'.\nRenamed 'self._param_constant247' to 'self.stages/2/blocks/2/layer_scale/gamma', normalized from original parameter name 'stages.2.blocks.2.layer_scale.gamma'.\nRenamed 'self._param_constant248' to 'self.stages/2/blocks/3/token_mixer/mixer/identity/weight', normalized from original parameter name 'stages.2.blocks.3.token_mixer.mixer.identity.weight'.\nRenamed 'self._param_constant249' to 'self.stages/2/blocks/3/token_mixer/mixer/identity/bias', normalized from original parameter name 'stages.2.blocks.3.token_mixer.mixer.identity.bias'.\nRenamed 'self._tensor_constant138' to 'self.stages/2/blocks/3/token_mixer/mixer/identity/running_mean', normalized from original parameter name 'stages.2.blocks.3.token_mixer.mixer.identity.running_mean'.\nRenamed 'self._tensor_constant139' to 'self.stages/2/blocks/3/token_mixer/mixer/identity/running_var', normalized from original parameter name 'stages.2.blocks.3.token_mixer.mixer.identity.running_var'.\nRenamed 'self._param_constant250' to 'self.stages/2/blocks/3/token_mixer/mixer/conv_scale/conv/weight', normalized from original parameter name 'stages.2.blocks.3.token_mixer.mixer.conv_scale.conv.weight'.\nRenamed 'self._param_constant251' to 'self.stages/2/blocks/3/token_mixer/mixer/conv_scale/bn/weight', normalized from original parameter name 'stages.2.blocks.3.token_mixer.mixer.conv_scale.bn.weight'.\nRenamed 'self._param_constant252' to 'self.stages/2/blocks/3/token_mixer/mixer/conv_scale/bn/bias', normalized from original parameter name 'stages.2.blocks.3.token_mixer.mixer.conv_scale.bn.bias'.\nRenamed 'self._tensor_constant140' to 'self.stages/2/blocks/3/token_mixer/mixer/conv_scale/bn/running_mean', normalized from original parameter name 'stages.2.blocks.3.token_mixer.mixer.conv_scale.bn.running_mean'.\nRenamed 'self._tensor_constant141' to 'self.stages/2/blocks/3/token_mixer/mixer/conv_scale/bn/running_var', normalized from original parameter name 'stages.2.blocks.3.token_mixer.mixer.conv_scale.bn.running_var'.\nRenamed 'self._param_constant253' to 'self.stages/2/blocks/3/token_mixer/mixer/conv_kxk/0/conv/weight', normalized from original parameter name 'stages.2.blocks.3.token_mixer.mixer.conv_kxk.0.conv.weight'.\nRenamed 'self._param_constant254' to 'self.stages/2/blocks/3/token_mixer/mixer/conv_kxk/0/bn/weight', normalized from original parameter name 'stages.2.blocks.3.token_mixer.mixer.conv_kxk.0.bn.weight'.\nRenamed 'self._param_constant255' to 'self.stages/2/blocks/3/token_mixer/mixer/conv_kxk/0/bn/bias', normalized from original parameter name 'stages.2.blocks.3.token_mixer.mixer.conv_kxk.0.bn.bias'.\nRenamed 'self._tensor_constant142' to 'self.stages/2/blocks/3/token_mixer/mixer/conv_kxk/0/bn/running_mean', normalized from original parameter name 'stages.2.blocks.3.token_mixer.mixer.conv_kxk.0.bn.running_mean'.\nRenamed 'self._tensor_constant143' to 'self.stages/2/blocks/3/token_mixer/mixer/conv_kxk/0/bn/running_var', normalized from original parameter name 'stages.2.blocks.3.token_mixer.mixer.conv_kxk.0.bn.running_var'.\nRenamed 'self._param_constant256' to 'self.stages/2/blocks/3/token_mixer/norm/identity/weight', normalized from original parameter name 'stages.2.blocks.3.token_mixer.norm.identity.weight'.\nRenamed 'self._param_constant257' to 'self.stages/2/blocks/3/token_mixer/norm/identity/bias', normalized from original parameter name 'stages.2.blocks.3.token_mixer.norm.identity.bias'.\nRenamed 'self._tensor_constant144' to 'self.stages/2/blocks/3/token_mixer/norm/identity/running_mean', normalized from original parameter name 'stages.2.blocks.3.token_mixer.norm.identity.running_mean'.\nRenamed 'self._tensor_constant145' to 'self.stages/2/blocks/3/token_mixer/norm/identity/running_var', normalized from original parameter name 'stages.2.blocks.3.token_mixer.norm.identity.running_var'.\nRenamed 'self._param_constant258' to 'self.stages/2/blocks/3/token_mixer/layer_scale/gamma', normalized from original parameter name 'stages.2.blocks.3.token_mixer.layer_scale.gamma'.\nRenamed 'self._param_constant259' to 'self.stages/2/blocks/3/mlp/conv/conv/weight', normalized from original parameter name 'stages.2.blocks.3.mlp.conv.conv.weight'.\nRenamed 'self._param_constant260' to 'self.stages/2/blocks/3/mlp/conv/bn/weight', normalized from original parameter name 'stages.2.blocks.3.mlp.conv.bn.weight'.\nRenamed 'self._param_constant261' to 'self.stages/2/blocks/3/mlp/conv/bn/bias', normalized from original parameter name 'stages.2.blocks.3.mlp.conv.bn.bias'.\nRenamed 'self._tensor_constant146' to 'self.stages/2/blocks/3/mlp/conv/bn/running_mean', normalized from original parameter name 'stages.2.blocks.3.mlp.conv.bn.running_mean'.\nRenamed 'self._tensor_constant147' to 'self.stages/2/blocks/3/mlp/conv/bn/running_var', normalized from original parameter name 'stages.2.blocks.3.mlp.conv.bn.running_var'.\nRenamed 'self._param_constant262' to 'self.stages/2/blocks/3/mlp/fc1/weight', normalized from original parameter name 'stages.2.blocks.3.mlp.fc1.weight'.\nRenamed 'self._param_constant263' to 'self.stages/2/blocks/3/mlp/fc1/bias', normalized from original parameter name 'stages.2.blocks.3.mlp.fc1.bias'.\nRenamed 'self._param_constant264' to 'self.stages/2/blocks/3/mlp/fc2/weight', normalized from original parameter name 'stages.2.blocks.3.mlp.fc2.weight'.\nRenamed 'self._param_constant265' to 'self.stages/2/blocks/3/mlp/fc2/bias', normalized from original parameter name 'stages.2.blocks.3.mlp.fc2.bias'.\nRenamed 'self._param_constant266' to 'self.stages/2/blocks/3/layer_scale/gamma', normalized from original parameter name 'stages.2.blocks.3.layer_scale.gamma'.\nRenamed 'self._param_constant267' to 'self.stages/2/blocks/4/token_mixer/mixer/identity/weight', normalized from original parameter name 'stages.2.blocks.4.token_mixer.mixer.identity.weight'.\nRenamed 'self._param_constant268' to 'self.stages/2/blocks/4/token_mixer/mixer/identity/bias', normalized from original parameter name 'stages.2.blocks.4.token_mixer.mixer.identity.bias'.\nRenamed 'self._tensor_constant148' to 'self.stages/2/blocks/4/token_mixer/mixer/identity/running_mean', normalized from original parameter name 'stages.2.blocks.4.token_mixer.mixer.identity.running_mean'.\nRenamed 'self._tensor_constant149' to 'self.stages/2/blocks/4/token_mixer/mixer/identity/running_var', normalized from original parameter name 'stages.2.blocks.4.token_mixer.mixer.identity.running_var'.\nRenamed 'self._param_constant269' to 'self.stages/2/blocks/4/token_mixer/mixer/conv_scale/conv/weight', normalized from original parameter name 'stages.2.blocks.4.token_mixer.mixer.conv_scale.conv.weight'.\nRenamed 'self._param_constant270' to 'self.stages/2/blocks/4/token_mixer/mixer/conv_scale/bn/weight', normalized from original parameter name 'stages.2.blocks.4.token_mixer.mixer.conv_scale.bn.weight'.\nRenamed 'self._param_constant271' to 'self.stages/2/blocks/4/token_mixer/mixer/conv_scale/bn/bias', normalized from original parameter name 'stages.2.blocks.4.token_mixer.mixer.conv_scale.bn.bias'.\nRenamed 'self._tensor_constant150' to 'self.stages/2/blocks/4/token_mixer/mixer/conv_scale/bn/running_mean', normalized from original parameter name 'stages.2.blocks.4.token_mixer.mixer.conv_scale.bn.running_mean'.\nRenamed 'self._tensor_constant151' to 'self.stages/2/blocks/4/token_mixer/mixer/conv_scale/bn/running_var', normalized from original parameter name 'stages.2.blocks.4.token_mixer.mixer.conv_scale.bn.running_var'.\nRenamed 'self._param_constant272' to 'self.stages/2/blocks/4/token_mixer/mixer/conv_kxk/0/conv/weight', normalized from original parameter name 'stages.2.blocks.4.token_mixer.mixer.conv_kxk.0.conv.weight'.\nRenamed 'self._param_constant273' to 'self.stages/2/blocks/4/token_mixer/mixer/conv_kxk/0/bn/weight', normalized from original parameter name 'stages.2.blocks.4.token_mixer.mixer.conv_kxk.0.bn.weight'.\nRenamed 'self._param_constant274' to 'self.stages/2/blocks/4/token_mixer/mixer/conv_kxk/0/bn/bias', normalized from original parameter name 'stages.2.blocks.4.token_mixer.mixer.conv_kxk.0.bn.bias'.\nRenamed 'self._tensor_constant152' to 'self.stages/2/blocks/4/token_mixer/mixer/conv_kxk/0/bn/running_mean', normalized from original parameter name 'stages.2.blocks.4.token_mixer.mixer.conv_kxk.0.bn.running_mean'.\nRenamed 'self._tensor_constant153' to 'self.stages/2/blocks/4/token_mixer/mixer/conv_kxk/0/bn/running_var', normalized from original parameter name 'stages.2.blocks.4.token_mixer.mixer.conv_kxk.0.bn.running_var'.\nRenamed 'self._param_constant275' to 'self.stages/2/blocks/4/token_mixer/norm/identity/weight', normalized from original parameter name 'stages.2.blocks.4.token_mixer.norm.identity.weight'.\nRenamed 'self._param_constant276' to 'self.stages/2/blocks/4/token_mixer/norm/identity/bias', normalized from original parameter name 'stages.2.blocks.4.token_mixer.norm.identity.bias'.\nRenamed 'self._tensor_constant154' to 'self.stages/2/blocks/4/token_mixer/norm/identity/running_mean', normalized from original parameter name 'stages.2.blocks.4.token_mixer.norm.identity.running_mean'.\nRenamed 'self._tensor_constant155' to 'self.stages/2/blocks/4/token_mixer/norm/identity/running_var', normalized from original parameter name 'stages.2.blocks.4.token_mixer.norm.identity.running_var'.\nRenamed 'self._param_constant277' to 'self.stages/2/blocks/4/token_mixer/layer_scale/gamma', normalized from original parameter name 'stages.2.blocks.4.token_mixer.layer_scale.gamma'.\nRenamed 'self._param_constant278' to 'self.stages/2/blocks/4/mlp/conv/conv/weight', normalized from original parameter name 'stages.2.blocks.4.mlp.conv.conv.weight'.\nRenamed 'self._param_constant279' to 'self.stages/2/blocks/4/mlp/conv/bn/weight', normalized from original parameter name 'stages.2.blocks.4.mlp.conv.bn.weight'.\nRenamed 'self._param_constant280' to 'self.stages/2/blocks/4/mlp/conv/bn/bias', normalized from original parameter name 'stages.2.blocks.4.mlp.conv.bn.bias'.\nRenamed 'self._tensor_constant156' to 'self.stages/2/blocks/4/mlp/conv/bn/running_mean', normalized from original parameter name 'stages.2.blocks.4.mlp.conv.bn.running_mean'.\nRenamed 'self._tensor_constant157' to 'self.stages/2/blocks/4/mlp/conv/bn/running_var', normalized from original parameter name 'stages.2.blocks.4.mlp.conv.bn.running_var'.\nRenamed 'self._param_constant281' to 'self.stages/2/blocks/4/mlp/fc1/weight', normalized from original parameter name 'stages.2.blocks.4.mlp.fc1.weight'.\nRenamed 'self._param_constant282' to 'self.stages/2/blocks/4/mlp/fc1/bias', normalized from original parameter name 'stages.2.blocks.4.mlp.fc1.bias'.\nRenamed 'self._param_constant283' to 'self.stages/2/blocks/4/mlp/fc2/weight', normalized from original parameter name 'stages.2.blocks.4.mlp.fc2.weight'.\nRenamed 'self._param_constant284' to 'self.stages/2/blocks/4/mlp/fc2/bias', normalized from original parameter name 'stages.2.blocks.4.mlp.fc2.bias'.\nRenamed 'self._param_constant285' to 'self.stages/2/blocks/4/layer_scale/gamma', normalized from original parameter name 'stages.2.blocks.4.layer_scale.gamma'.\nRenamed 'self._param_constant286' to 'self.stages/2/blocks/5/token_mixer/mixer/identity/weight', normalized from original parameter name 'stages.2.blocks.5.token_mixer.mixer.identity.weight'.\nRenamed 'self._param_constant287' to 'self.stages/2/blocks/5/token_mixer/mixer/identity/bias', normalized from original parameter name 'stages.2.blocks.5.token_mixer.mixer.identity.bias'.\nRenamed 'self._tensor_constant158' to 'self.stages/2/blocks/5/token_mixer/mixer/identity/running_mean', normalized from original parameter name 'stages.2.blocks.5.token_mixer.mixer.identity.running_mean'.\nRenamed 'self._tensor_constant159' to 'self.stages/2/blocks/5/token_mixer/mixer/identity/running_var', normalized from original parameter name 'stages.2.blocks.5.token_mixer.mixer.identity.running_var'.\nRenamed 'self._param_constant288' to 'self.stages/2/blocks/5/token_mixer/mixer/conv_scale/conv/weight', normalized from original parameter name 'stages.2.blocks.5.token_mixer.mixer.conv_scale.conv.weight'.\nRenamed 'self._param_constant289' to 'self.stages/2/blocks/5/token_mixer/mixer/conv_scale/bn/weight', normalized from original parameter name 'stages.2.blocks.5.token_mixer.mixer.conv_scale.bn.weight'.\nRenamed 'self._param_constant290' to 'self.stages/2/blocks/5/token_mixer/mixer/conv_scale/bn/bias', normalized from original parameter name 'stages.2.blocks.5.token_mixer.mixer.conv_scale.bn.bias'.\nRenamed 'self._tensor_constant160' to 'self.stages/2/blocks/5/token_mixer/mixer/conv_scale/bn/running_mean', normalized from original parameter name 'stages.2.blocks.5.token_mixer.mixer.conv_scale.bn.running_mean'.\nRenamed 'self._tensor_constant161' to 'self.stages/2/blocks/5/token_mixer/mixer/conv_scale/bn/running_var', normalized from original parameter name 'stages.2.blocks.5.token_mixer.mixer.conv_scale.bn.running_var'.\nRenamed 'self._param_constant291' to 'self.stages/2/blocks/5/token_mixer/mixer/conv_kxk/0/conv/weight', normalized from original parameter name 'stages.2.blocks.5.token_mixer.mixer.conv_kxk.0.conv.weight'.\nRenamed 'self._param_constant292' to 'self.stages/2/blocks/5/token_mixer/mixer/conv_kxk/0/bn/weight', normalized from original parameter name 'stages.2.blocks.5.token_mixer.mixer.conv_kxk.0.bn.weight'.\nRenamed 'self._param_constant293' to 'self.stages/2/blocks/5/token_mixer/mixer/conv_kxk/0/bn/bias', normalized from original parameter name 'stages.2.blocks.5.token_mixer.mixer.conv_kxk.0.bn.bias'.\nRenamed 'self._tensor_constant162' to 'self.stages/2/blocks/5/token_mixer/mixer/conv_kxk/0/bn/running_mean', normalized from original parameter name 'stages.2.blocks.5.token_mixer.mixer.conv_kxk.0.bn.running_mean'.\nRenamed 'self._tensor_constant163' to 'self.stages/2/blocks/5/token_mixer/mixer/conv_kxk/0/bn/running_var', normalized from original parameter name 'stages.2.blocks.5.token_mixer.mixer.conv_kxk.0.bn.running_var'.\nRenamed 'self._param_constant294' to 'self.stages/2/blocks/5/token_mixer/norm/identity/weight', normalized from original parameter name 'stages.2.blocks.5.token_mixer.norm.identity.weight'.\nRenamed 'self._param_constant295' to 'self.stages/2/blocks/5/token_mixer/norm/identity/bias', normalized from original parameter name 'stages.2.blocks.5.token_mixer.norm.identity.bias'.\nRenamed 'self._tensor_constant164' to 'self.stages/2/blocks/5/token_mixer/norm/identity/running_mean', normalized from original parameter name 'stages.2.blocks.5.token_mixer.norm.identity.running_mean'.\nRenamed 'self._tensor_constant165' to 'self.stages/2/blocks/5/token_mixer/norm/identity/running_var', normalized from original parameter name 'stages.2.blocks.5.token_mixer.norm.identity.running_var'.\nRenamed 'self._param_constant296' to 'self.stages/2/blocks/5/token_mixer/layer_scale/gamma', normalized from original parameter name 'stages.2.blocks.5.token_mixer.layer_scale.gamma'.\nRenamed 'self._param_constant297' to 'self.stages/2/blocks/5/mlp/conv/conv/weight', normalized from original parameter name 'stages.2.blocks.5.mlp.conv.conv.weight'.\nRenamed 'self._param_constant298' to 'self.stages/2/blocks/5/mlp/conv/bn/weight', normalized from original parameter name 'stages.2.blocks.5.mlp.conv.bn.weight'.\nRenamed 'self._param_constant299' to 'self.stages/2/blocks/5/mlp/conv/bn/bias', normalized from original parameter name 'stages.2.blocks.5.mlp.conv.bn.bias'.\nRenamed 'self._tensor_constant166' to 'self.stages/2/blocks/5/mlp/conv/bn/running_mean', normalized from original parameter name 'stages.2.blocks.5.mlp.conv.bn.running_mean'.\nRenamed 'self._tensor_constant167' to 'self.stages/2/blocks/5/mlp/conv/bn/running_var', normalized from original parameter name 'stages.2.blocks.5.mlp.conv.bn.running_var'.\nRenamed 'self._param_constant300' to 'self.stages/2/blocks/5/mlp/fc1/weight', normalized from original parameter name 'stages.2.blocks.5.mlp.fc1.weight'.\nRenamed 'self._param_constant301' to 'self.stages/2/blocks/5/mlp/fc1/bias', normalized from original parameter name 'stages.2.blocks.5.mlp.fc1.bias'.\nRenamed 'self._param_constant302' to 'self.stages/2/blocks/5/mlp/fc2/weight', normalized from original parameter name 'stages.2.blocks.5.mlp.fc2.weight'.\nRenamed 'self._param_constant303' to 'self.stages/2/blocks/5/mlp/fc2/bias', normalized from original parameter name 'stages.2.blocks.5.mlp.fc2.bias'.\nRenamed 'self._param_constant304' to 'self.stages/2/blocks/5/layer_scale/gamma', normalized from original parameter name 'stages.2.blocks.5.layer_scale.gamma'.\nRenamed 'self._param_constant305' to 'self.stages/2/blocks/6/token_mixer/mixer/identity/weight', normalized from original parameter name 'stages.2.blocks.6.token_mixer.mixer.identity.weight'.\nRenamed 'self._param_constant306' to 'self.stages/2/blocks/6/token_mixer/mixer/identity/bias', normalized from original parameter name 'stages.2.blocks.6.token_mixer.mixer.identity.bias'.\nRenamed 'self._tensor_constant168' to 'self.stages/2/blocks/6/token_mixer/mixer/identity/running_mean', normalized from original parameter name 'stages.2.blocks.6.token_mixer.mixer.identity.running_mean'.\nRenamed 'self._tensor_constant169' to 'self.stages/2/blocks/6/token_mixer/mixer/identity/running_var', normalized from original parameter name 'stages.2.blocks.6.token_mixer.mixer.identity.running_var'.\nRenamed 'self._param_constant307' to 'self.stages/2/blocks/6/token_mixer/mixer/conv_scale/conv/weight', normalized from original parameter name 'stages.2.blocks.6.token_mixer.mixer.conv_scale.conv.weight'.\nRenamed 'self._param_constant308' to 'self.stages/2/blocks/6/token_mixer/mixer/conv_scale/bn/weight', normalized from original parameter name 'stages.2.blocks.6.token_mixer.mixer.conv_scale.bn.weight'.\nRenamed 'self._param_constant309' to 'self.stages/2/blocks/6/token_mixer/mixer/conv_scale/bn/bias', normalized from original parameter name 'stages.2.blocks.6.token_mixer.mixer.conv_scale.bn.bias'.\nRenamed 'self._tensor_constant170' to 'self.stages/2/blocks/6/token_mixer/mixer/conv_scale/bn/running_mean', normalized from original parameter name 'stages.2.blocks.6.token_mixer.mixer.conv_scale.bn.running_mean'.\nRenamed 'self._tensor_constant171' to 'self.stages/2/blocks/6/token_mixer/mixer/conv_scale/bn/running_var', normalized from original parameter name 'stages.2.blocks.6.token_mixer.mixer.conv_scale.bn.running_var'.\nRenamed 'self._param_constant310' to 'self.stages/2/blocks/6/token_mixer/mixer/conv_kxk/0/conv/weight', normalized from original parameter name 'stages.2.blocks.6.token_mixer.mixer.conv_kxk.0.conv.weight'.\nRenamed 'self._param_constant311' to 'self.stages/2/blocks/6/token_mixer/mixer/conv_kxk/0/bn/weight', normalized from original parameter name 'stages.2.blocks.6.token_mixer.mixer.conv_kxk.0.bn.weight'.\nRenamed 'self._param_constant312' to 'self.stages/2/blocks/6/token_mixer/mixer/conv_kxk/0/bn/bias', normalized from original parameter name 'stages.2.blocks.6.token_mixer.mixer.conv_kxk.0.bn.bias'.\nRenamed 'self._tensor_constant172' to 'self.stages/2/blocks/6/token_mixer/mixer/conv_kxk/0/bn/running_mean', normalized from original parameter name 'stages.2.blocks.6.token_mixer.mixer.conv_kxk.0.bn.running_mean'.\nRenamed 'self._tensor_constant173' to 'self.stages/2/blocks/6/token_mixer/mixer/conv_kxk/0/bn/running_var', normalized from original parameter name 'stages.2.blocks.6.token_mixer.mixer.conv_kxk.0.bn.running_var'.\nRenamed 'self._param_constant313' to 'self.stages/2/blocks/6/token_mixer/norm/identity/weight', normalized from original parameter name 'stages.2.blocks.6.token_mixer.norm.identity.weight'.\nRenamed 'self._param_constant314' to 'self.stages/2/blocks/6/token_mixer/norm/identity/bias', normalized from original parameter name 'stages.2.blocks.6.token_mixer.norm.identity.bias'.\nRenamed 'self._tensor_constant174' to 'self.stages/2/blocks/6/token_mixer/norm/identity/running_mean', normalized from original parameter name 'stages.2.blocks.6.token_mixer.norm.identity.running_mean'.\nRenamed 'self._tensor_constant175' to 'self.stages/2/blocks/6/token_mixer/norm/identity/running_var', normalized from original parameter name 'stages.2.blocks.6.token_mixer.norm.identity.running_var'.\nRenamed 'self._param_constant315' to 'self.stages/2/blocks/6/token_mixer/layer_scale/gamma', normalized from original parameter name 'stages.2.blocks.6.token_mixer.layer_scale.gamma'.\nRenamed 'self._param_constant316' to 'self.stages/2/blocks/6/mlp/conv/conv/weight', normalized from original parameter name 'stages.2.blocks.6.mlp.conv.conv.weight'.\nRenamed 'self._param_constant317' to 'self.stages/2/blocks/6/mlp/conv/bn/weight', normalized from original parameter name 'stages.2.blocks.6.mlp.conv.bn.weight'.\nRenamed 'self._param_constant318' to 'self.stages/2/blocks/6/mlp/conv/bn/bias', normalized from original parameter name 'stages.2.blocks.6.mlp.conv.bn.bias'.\nRenamed 'self._tensor_constant176' to 'self.stages/2/blocks/6/mlp/conv/bn/running_mean', normalized from original parameter name 'stages.2.blocks.6.mlp.conv.bn.running_mean'.\nRenamed 'self._tensor_constant177' to 'self.stages/2/blocks/6/mlp/conv/bn/running_var', normalized from original parameter name 'stages.2.blocks.6.mlp.conv.bn.running_var'.\nRenamed 'self._param_constant319' to 'self.stages/2/blocks/6/mlp/fc1/weight', normalized from original parameter name 'stages.2.blocks.6.mlp.fc1.weight'.\nRenamed 'self._param_constant320' to 'self.stages/2/blocks/6/mlp/fc1/bias', normalized from original parameter name 'stages.2.blocks.6.mlp.fc1.bias'.\nRenamed 'self._param_constant321' to 'self.stages/2/blocks/6/mlp/fc2/weight', normalized from original parameter name 'stages.2.blocks.6.mlp.fc2.weight'.\nRenamed 'self._param_constant322' to 'self.stages/2/blocks/6/mlp/fc2/bias', normalized from original parameter name 'stages.2.blocks.6.mlp.fc2.bias'.\nRenamed 'self._param_constant323' to 'self.stages/2/blocks/6/layer_scale/gamma', normalized from original parameter name 'stages.2.blocks.6.layer_scale.gamma'.\nRenamed 'self._param_constant324' to 'self.stages/2/blocks/7/token_mixer/mixer/identity/weight', normalized from original parameter name 'stages.2.blocks.7.token_mixer.mixer.identity.weight'.\nRenamed 'self._param_constant325' to 'self.stages/2/blocks/7/token_mixer/mixer/identity/bias', normalized from original parameter name 'stages.2.blocks.7.token_mixer.mixer.identity.bias'.\nRenamed 'self._tensor_constant178' to 'self.stages/2/blocks/7/token_mixer/mixer/identity/running_mean', normalized from original parameter name 'stages.2.blocks.7.token_mixer.mixer.identity.running_mean'.\nRenamed 'self._tensor_constant179' to 'self.stages/2/blocks/7/token_mixer/mixer/identity/running_var', normalized from original parameter name 'stages.2.blocks.7.token_mixer.mixer.identity.running_var'.\nRenamed 'self._param_constant326' to 'self.stages/2/blocks/7/token_mixer/mixer/conv_scale/conv/weight', normalized from original parameter name 'stages.2.blocks.7.token_mixer.mixer.conv_scale.conv.weight'.\nRenamed 'self._param_constant327' to 'self.stages/2/blocks/7/token_mixer/mixer/conv_scale/bn/weight', normalized from original parameter name 'stages.2.blocks.7.token_mixer.mixer.conv_scale.bn.weight'.\nRenamed 'self._param_constant328' to 'self.stages/2/blocks/7/token_mixer/mixer/conv_scale/bn/bias', normalized from original parameter name 'stages.2.blocks.7.token_mixer.mixer.conv_scale.bn.bias'.\nRenamed 'self._tensor_constant180' to 'self.stages/2/blocks/7/token_mixer/mixer/conv_scale/bn/running_mean', normalized from original parameter name 'stages.2.blocks.7.token_mixer.mixer.conv_scale.bn.running_mean'.\nRenamed 'self._tensor_constant181' to 'self.stages/2/blocks/7/token_mixer/mixer/conv_scale/bn/running_var', normalized from original parameter name 'stages.2.blocks.7.token_mixer.mixer.conv_scale.bn.running_var'.\nRenamed 'self._param_constant329' to 'self.stages/2/blocks/7/token_mixer/mixer/conv_kxk/0/conv/weight', normalized from original parameter name 'stages.2.blocks.7.token_mixer.mixer.conv_kxk.0.conv.weight'.\nRenamed 'self._param_constant330' to 'self.stages/2/blocks/7/token_mixer/mixer/conv_kxk/0/bn/weight', normalized from original parameter name 'stages.2.blocks.7.token_mixer.mixer.conv_kxk.0.bn.weight'.\nRenamed 'self._param_constant331' to 'self.stages/2/blocks/7/token_mixer/mixer/conv_kxk/0/bn/bias', normalized from original parameter name 'stages.2.blocks.7.token_mixer.mixer.conv_kxk.0.bn.bias'.\nRenamed 'self._tensor_constant182' to 'self.stages/2/blocks/7/token_mixer/mixer/conv_kxk/0/bn/running_mean', normalized from original parameter name 'stages.2.blocks.7.token_mixer.mixer.conv_kxk.0.bn.running_mean'.\nRenamed 'self._tensor_constant183' to 'self.stages/2/blocks/7/token_mixer/mixer/conv_kxk/0/bn/running_var', normalized from original parameter name 'stages.2.blocks.7.token_mixer.mixer.conv_kxk.0.bn.running_var'.\nRenamed 'self._param_constant332' to 'self.stages/2/blocks/7/token_mixer/norm/identity/weight', normalized from original parameter name 'stages.2.blocks.7.token_mixer.norm.identity.weight'.\nRenamed 'self._param_constant333' to 'self.stages/2/blocks/7/token_mixer/norm/identity/bias', normalized from original parameter name 'stages.2.blocks.7.token_mixer.norm.identity.bias'.\nRenamed 'self._tensor_constant184' to 'self.stages/2/blocks/7/token_mixer/norm/identity/running_mean', normalized from original parameter name 'stages.2.blocks.7.token_mixer.norm.identity.running_mean'.\nRenamed 'self._tensor_constant185' to 'self.stages/2/blocks/7/token_mixer/norm/identity/running_var', normalized from original parameter name 'stages.2.blocks.7.token_mixer.norm.identity.running_var'.\nRenamed 'self._param_constant334' to 'self.stages/2/blocks/7/token_mixer/layer_scale/gamma', normalized from original parameter name 'stages.2.blocks.7.token_mixer.layer_scale.gamma'.\nRenamed 'self._param_constant335' to 'self.stages/2/blocks/7/mlp/conv/conv/weight', normalized from original parameter name 'stages.2.blocks.7.mlp.conv.conv.weight'.\nRenamed 'self._param_constant336' to 'self.stages/2/blocks/7/mlp/conv/bn/weight', normalized from original parameter name 'stages.2.blocks.7.mlp.conv.bn.weight'.\nRenamed 'self._param_constant337' to 'self.stages/2/blocks/7/mlp/conv/bn/bias', normalized from original parameter name 'stages.2.blocks.7.mlp.conv.bn.bias'.\nRenamed 'self._tensor_constant186' to 'self.stages/2/blocks/7/mlp/conv/bn/running_mean', normalized from original parameter name 'stages.2.blocks.7.mlp.conv.bn.running_mean'.\nRenamed 'self._tensor_constant187' to 'self.stages/2/blocks/7/mlp/conv/bn/running_var', normalized from original parameter name 'stages.2.blocks.7.mlp.conv.bn.running_var'.\nRenamed 'self._param_constant338' to 'self.stages/2/blocks/7/mlp/fc1/weight', normalized from original parameter name 'stages.2.blocks.7.mlp.fc1.weight'.\nRenamed 'self._param_constant339' to 'self.stages/2/blocks/7/mlp/fc1/bias', normalized from original parameter name 'stages.2.blocks.7.mlp.fc1.bias'.\nRenamed 'self._param_constant340' to 'self.stages/2/blocks/7/mlp/fc2/weight', normalized from original parameter name 'stages.2.blocks.7.mlp.fc2.weight'.\nRenamed 'self._param_constant341' to 'self.stages/2/blocks/7/mlp/fc2/bias', normalized from original parameter name 'stages.2.blocks.7.mlp.fc2.bias'.\nRenamed 'self._param_constant342' to 'self.stages/2/blocks/7/layer_scale/gamma', normalized from original parameter name 'stages.2.blocks.7.layer_scale.gamma'.\nRenamed 'self._param_constant343' to 'self.stages/2/blocks/8/token_mixer/mixer/identity/weight', normalized from original parameter name 'stages.2.blocks.8.token_mixer.mixer.identity.weight'.\nRenamed 'self._param_constant344' to 'self.stages/2/blocks/8/token_mixer/mixer/identity/bias', normalized from original parameter name 'stages.2.blocks.8.token_mixer.mixer.identity.bias'.\nRenamed 'self._tensor_constant188' to 'self.stages/2/blocks/8/token_mixer/mixer/identity/running_mean', normalized from original parameter name 'stages.2.blocks.8.token_mixer.mixer.identity.running_mean'.\nRenamed 'self._tensor_constant189' to 'self.stages/2/blocks/8/token_mixer/mixer/identity/running_var', normalized from original parameter name 'stages.2.blocks.8.token_mixer.mixer.identity.running_var'.\nRenamed 'self._param_constant345' to 'self.stages/2/blocks/8/token_mixer/mixer/conv_scale/conv/weight', normalized from original parameter name 'stages.2.blocks.8.token_mixer.mixer.conv_scale.conv.weight'.\nRenamed 'self._param_constant346' to 'self.stages/2/blocks/8/token_mixer/mixer/conv_scale/bn/weight', normalized from original parameter name 'stages.2.blocks.8.token_mixer.mixer.conv_scale.bn.weight'.\nRenamed 'self._param_constant347' to 'self.stages/2/blocks/8/token_mixer/mixer/conv_scale/bn/bias', normalized from original parameter name 'stages.2.blocks.8.token_mixer.mixer.conv_scale.bn.bias'.\nRenamed 'self._tensor_constant190' to 'self.stages/2/blocks/8/token_mixer/mixer/conv_scale/bn/running_mean', normalized from original parameter name 'stages.2.blocks.8.token_mixer.mixer.conv_scale.bn.running_mean'.\nRenamed 'self._tensor_constant191' to 'self.stages/2/blocks/8/token_mixer/mixer/conv_scale/bn/running_var', normalized from original parameter name 'stages.2.blocks.8.token_mixer.mixer.conv_scale.bn.running_var'.\nRenamed 'self._param_constant348' to 'self.stages/2/blocks/8/token_mixer/mixer/conv_kxk/0/conv/weight', normalized from original parameter name 'stages.2.blocks.8.token_mixer.mixer.conv_kxk.0.conv.weight'.\nRenamed 'self._param_constant349' to 'self.stages/2/blocks/8/token_mixer/mixer/conv_kxk/0/bn/weight', normalized from original parameter name 'stages.2.blocks.8.token_mixer.mixer.conv_kxk.0.bn.weight'.\nRenamed 'self._param_constant350' to 'self.stages/2/blocks/8/token_mixer/mixer/conv_kxk/0/bn/bias', normalized from original parameter name 'stages.2.blocks.8.token_mixer.mixer.conv_kxk.0.bn.bias'.\nRenamed 'self._tensor_constant192' to 'self.stages/2/blocks/8/token_mixer/mixer/conv_kxk/0/bn/running_mean', normalized from original parameter name 'stages.2.blocks.8.token_mixer.mixer.conv_kxk.0.bn.running_mean'.\nRenamed 'self._tensor_constant193' to 'self.stages/2/blocks/8/token_mixer/mixer/conv_kxk/0/bn/running_var', normalized from original parameter name 'stages.2.blocks.8.token_mixer.mixer.conv_kxk.0.bn.running_var'.\nRenamed 'self._param_constant351' to 'self.stages/2/blocks/8/token_mixer/norm/identity/weight', normalized from original parameter name 'stages.2.blocks.8.token_mixer.norm.identity.weight'.\nRenamed 'self._param_constant352' to 'self.stages/2/blocks/8/token_mixer/norm/identity/bias', normalized from original parameter name 'stages.2.blocks.8.token_mixer.norm.identity.bias'.\nRenamed 'self._tensor_constant194' to 'self.stages/2/blocks/8/token_mixer/norm/identity/running_mean', normalized from original parameter name 'stages.2.blocks.8.token_mixer.norm.identity.running_mean'.\nRenamed 'self._tensor_constant195' to 'self.stages/2/blocks/8/token_mixer/norm/identity/running_var', normalized from original parameter name 'stages.2.blocks.8.token_mixer.norm.identity.running_var'.\nRenamed 'self._param_constant353' to 'self.stages/2/blocks/8/token_mixer/layer_scale/gamma', normalized from original parameter name 'stages.2.blocks.8.token_mixer.layer_scale.gamma'.\nRenamed 'self._param_constant354' to 'self.stages/2/blocks/8/mlp/conv/conv/weight', normalized from original parameter name 'stages.2.blocks.8.mlp.conv.conv.weight'.\nRenamed 'self._param_constant355' to 'self.stages/2/blocks/8/mlp/conv/bn/weight', normalized from original parameter name 'stages.2.blocks.8.mlp.conv.bn.weight'.\nRenamed 'self._param_constant356' to 'self.stages/2/blocks/8/mlp/conv/bn/bias', normalized from original parameter name 'stages.2.blocks.8.mlp.conv.bn.bias'.\nRenamed 'self._tensor_constant196' to 'self.stages/2/blocks/8/mlp/conv/bn/running_mean', normalized from original parameter name 'stages.2.blocks.8.mlp.conv.bn.running_mean'.\nRenamed 'self._tensor_constant197' to 'self.stages/2/blocks/8/mlp/conv/bn/running_var', normalized from original parameter name 'stages.2.blocks.8.mlp.conv.bn.running_var'.\nRenamed 'self._param_constant357' to 'self.stages/2/blocks/8/mlp/fc1/weight', normalized from original parameter name 'stages.2.blocks.8.mlp.fc1.weight'.\nRenamed 'self._param_constant358' to 'self.stages/2/blocks/8/mlp/fc1/bias', normalized from original parameter name 'stages.2.blocks.8.mlp.fc1.bias'.\nRenamed 'self._param_constant359' to 'self.stages/2/blocks/8/mlp/fc2/weight', normalized from original parameter name 'stages.2.blocks.8.mlp.fc2.weight'.\nRenamed 'self._param_constant360' to 'self.stages/2/blocks/8/mlp/fc2/bias', normalized from original parameter name 'stages.2.blocks.8.mlp.fc2.bias'.\nRenamed 'self._param_constant361' to 'self.stages/2/blocks/8/layer_scale/gamma', normalized from original parameter name 'stages.2.blocks.8.layer_scale.gamma'.\nRenamed 'self._param_constant362' to 'self.stages/2/blocks/9/token_mixer/mixer/identity/weight', normalized from original parameter name 'stages.2.blocks.9.token_mixer.mixer.identity.weight'.\nRenamed 'self._param_constant363' to 'self.stages/2/blocks/9/token_mixer/mixer/identity/bias', normalized from original parameter name 'stages.2.blocks.9.token_mixer.mixer.identity.bias'.\nRenamed 'self._tensor_constant198' to 'self.stages/2/blocks/9/token_mixer/mixer/identity/running_mean', normalized from original parameter name 'stages.2.blocks.9.token_mixer.mixer.identity.running_mean'.\nRenamed 'self._tensor_constant199' to 'self.stages/2/blocks/9/token_mixer/mixer/identity/running_var', normalized from original parameter name 'stages.2.blocks.9.token_mixer.mixer.identity.running_var'.\nRenamed 'self._param_constant364' to 'self.stages/2/blocks/9/token_mixer/mixer/conv_scale/conv/weight', normalized from original parameter name 'stages.2.blocks.9.token_mixer.mixer.conv_scale.conv.weight'.\nRenamed 'self._param_constant365' to 'self.stages/2/blocks/9/token_mixer/mixer/conv_scale/bn/weight', normalized from original parameter name 'stages.2.blocks.9.token_mixer.mixer.conv_scale.bn.weight'.\nRenamed 'self._param_constant366' to 'self.stages/2/blocks/9/token_mixer/mixer/conv_scale/bn/bias', normalized from original parameter name 'stages.2.blocks.9.token_mixer.mixer.conv_scale.bn.bias'.\nRenamed 'self._tensor_constant200' to 'self.stages/2/blocks/9/token_mixer/mixer/conv_scale/bn/running_mean', normalized from original parameter name 'stages.2.blocks.9.token_mixer.mixer.conv_scale.bn.running_mean'.\nRenamed 'self._tensor_constant201' to 'self.stages/2/blocks/9/token_mixer/mixer/conv_scale/bn/running_var', normalized from original parameter name 'stages.2.blocks.9.token_mixer.mixer.conv_scale.bn.running_var'.\nRenamed 'self._param_constant367' to 'self.stages/2/blocks/9/token_mixer/mixer/conv_kxk/0/conv/weight', normalized from original parameter name 'stages.2.blocks.9.token_mixer.mixer.conv_kxk.0.conv.weight'.\nRenamed 'self._param_constant368' to 'self.stages/2/blocks/9/token_mixer/mixer/conv_kxk/0/bn/weight', normalized from original parameter name 'stages.2.blocks.9.token_mixer.mixer.conv_kxk.0.bn.weight'.\nRenamed 'self._param_constant369' to 'self.stages/2/blocks/9/token_mixer/mixer/conv_kxk/0/bn/bias', normalized from original parameter name 'stages.2.blocks.9.token_mixer.mixer.conv_kxk.0.bn.bias'.\nRenamed 'self._tensor_constant202' to 'self.stages/2/blocks/9/token_mixer/mixer/conv_kxk/0/bn/running_mean', normalized from original parameter name 'stages.2.blocks.9.token_mixer.mixer.conv_kxk.0.bn.running_mean'.\nRenamed 'self._tensor_constant203' to 'self.stages/2/blocks/9/token_mixer/mixer/conv_kxk/0/bn/running_var', normalized from original parameter name 'stages.2.blocks.9.token_mixer.mixer.conv_kxk.0.bn.running_var'.\nRenamed 'self._param_constant370' to 'self.stages/2/blocks/9/token_mixer/norm/identity/weight', normalized from original parameter name 'stages.2.blocks.9.token_mixer.norm.identity.weight'.\nRenamed 'self._param_constant371' to 'self.stages/2/blocks/9/token_mixer/norm/identity/bias', normalized from original parameter name 'stages.2.blocks.9.token_mixer.norm.identity.bias'.\nRenamed 'self._tensor_constant204' to 'self.stages/2/blocks/9/token_mixer/norm/identity/running_mean', normalized from original parameter name 'stages.2.blocks.9.token_mixer.norm.identity.running_mean'.\nRenamed 'self._tensor_constant205' to 'self.stages/2/blocks/9/token_mixer/norm/identity/running_var', normalized from original parameter name 'stages.2.blocks.9.token_mixer.norm.identity.running_var'.\nRenamed 'self._param_constant372' to 'self.stages/2/blocks/9/token_mixer/layer_scale/gamma', normalized from original parameter name 'stages.2.blocks.9.token_mixer.layer_scale.gamma'.\nRenamed 'self._param_constant373' to 'self.stages/2/blocks/9/mlp/conv/conv/weight', normalized from original parameter name 'stages.2.blocks.9.mlp.conv.conv.weight'.\nRenamed 'self._param_constant374' to 'self.stages/2/blocks/9/mlp/conv/bn/weight', normalized from original parameter name 'stages.2.blocks.9.mlp.conv.bn.weight'.\nRenamed 'self._param_constant375' to 'self.stages/2/blocks/9/mlp/conv/bn/bias', normalized from original parameter name 'stages.2.blocks.9.mlp.conv.bn.bias'.\nRenamed 'self._tensor_constant206' to 'self.stages/2/blocks/9/mlp/conv/bn/running_mean', normalized from original parameter name 'stages.2.blocks.9.mlp.conv.bn.running_mean'.\nRenamed 'self._tensor_constant207' to 'self.stages/2/blocks/9/mlp/conv/bn/running_var', normalized from original parameter name 'stages.2.blocks.9.mlp.conv.bn.running_var'.\nRenamed 'self._param_constant376' to 'self.stages/2/blocks/9/mlp/fc1/weight', normalized from original parameter name 'stages.2.blocks.9.mlp.fc1.weight'.\nRenamed 'self._param_constant377' to 'self.stages/2/blocks/9/mlp/fc1/bias', normalized from original parameter name 'stages.2.blocks.9.mlp.fc1.bias'.\nRenamed 'self._param_constant378' to 'self.stages/2/blocks/9/mlp/fc2/weight', normalized from original parameter name 'stages.2.blocks.9.mlp.fc2.weight'.\nRenamed 'self._param_constant379' to 'self.stages/2/blocks/9/mlp/fc2/bias', normalized from original parameter name 'stages.2.blocks.9.mlp.fc2.bias'.\nRenamed 'self._param_constant380' to 'self.stages/2/blocks/9/layer_scale/gamma', normalized from original parameter name 'stages.2.blocks.9.layer_scale.gamma'.\nRenamed 'self._param_constant381' to 'self.stages/2/blocks/10/token_mixer/mixer/identity/weight', normalized from original parameter name 'stages.2.blocks.10.token_mixer.mixer.identity.weight'.\nRenamed 'self._param_constant382' to 'self.stages/2/blocks/10/token_mixer/mixer/identity/bias', normalized from original parameter name 'stages.2.blocks.10.token_mixer.mixer.identity.bias'.\nRenamed 'self._tensor_constant208' to 'self.stages/2/blocks/10/token_mixer/mixer/identity/running_mean', normalized from original parameter name 'stages.2.blocks.10.token_mixer.mixer.identity.running_mean'.\nRenamed 'self._tensor_constant209' to 'self.stages/2/blocks/10/token_mixer/mixer/identity/running_var', normalized from original parameter name 'stages.2.blocks.10.token_mixer.mixer.identity.running_var'.\nRenamed 'self._param_constant383' to 'self.stages/2/blocks/10/token_mixer/mixer/conv_scale/conv/weight', normalized from original parameter name 'stages.2.blocks.10.token_mixer.mixer.conv_scale.conv.weight'.\nRenamed 'self._param_constant384' to 'self.stages/2/blocks/10/token_mixer/mixer/conv_scale/bn/weight', normalized from original parameter name 'stages.2.blocks.10.token_mixer.mixer.conv_scale.bn.weight'.\nRenamed 'self._param_constant385' to 'self.stages/2/blocks/10/token_mixer/mixer/conv_scale/bn/bias', normalized from original parameter name 'stages.2.blocks.10.token_mixer.mixer.conv_scale.bn.bias'.\nRenamed 'self._tensor_constant210' to 'self.stages/2/blocks/10/token_mixer/mixer/conv_scale/bn/running_mean', normalized from original parameter name 'stages.2.blocks.10.token_mixer.mixer.conv_scale.bn.running_mean'.\nRenamed 'self._tensor_constant211' to 'self.stages/2/blocks/10/token_mixer/mixer/conv_scale/bn/running_var', normalized from original parameter name 'stages.2.blocks.10.token_mixer.mixer.conv_scale.bn.running_var'.\nRenamed 'self._param_constant386' to 'self.stages/2/blocks/10/token_mixer/mixer/conv_kxk/0/conv/weight', normalized from original parameter name 'stages.2.blocks.10.token_mixer.mixer.conv_kxk.0.conv.weight'.\nRenamed 'self._param_constant387' to 'self.stages/2/blocks/10/token_mixer/mixer/conv_kxk/0/bn/weight', normalized from original parameter name 'stages.2.blocks.10.token_mixer.mixer.conv_kxk.0.bn.weight'.\nRenamed 'self._param_constant388' to 'self.stages/2/blocks/10/token_mixer/mixer/conv_kxk/0/bn/bias', normalized from original parameter name 'stages.2.blocks.10.token_mixer.mixer.conv_kxk.0.bn.bias'.\nRenamed 'self._tensor_constant212' to 'self.stages/2/blocks/10/token_mixer/mixer/conv_kxk/0/bn/running_mean', normalized from original parameter name 'stages.2.blocks.10.token_mixer.mixer.conv_kxk.0.bn.running_mean'.\nRenamed 'self._tensor_constant213' to 'self.stages/2/blocks/10/token_mixer/mixer/conv_kxk/0/bn/running_var', normalized from original parameter name 'stages.2.blocks.10.token_mixer.mixer.conv_kxk.0.bn.running_var'.\nRenamed 'self._param_constant389' to 'self.stages/2/blocks/10/token_mixer/norm/identity/weight', normalized from original parameter name 'stages.2.blocks.10.token_mixer.norm.identity.weight'.\nRenamed 'self._param_constant390' to 'self.stages/2/blocks/10/token_mixer/norm/identity/bias', normalized from original parameter name 'stages.2.blocks.10.token_mixer.norm.identity.bias'.\nRenamed 'self._tensor_constant214' to 'self.stages/2/blocks/10/token_mixer/norm/identity/running_mean', normalized from original parameter name 'stages.2.blocks.10.token_mixer.norm.identity.running_mean'.\nRenamed 'self._tensor_constant215' to 'self.stages/2/blocks/10/token_mixer/norm/identity/running_var', normalized from original parameter name 'stages.2.blocks.10.token_mixer.norm.identity.running_var'.\nRenamed 'self._param_constant391' to 'self.stages/2/blocks/10/token_mixer/layer_scale/gamma', normalized from original parameter name 'stages.2.blocks.10.token_mixer.layer_scale.gamma'.\nRenamed 'self._param_constant392' to 'self.stages/2/blocks/10/mlp/conv/conv/weight', normalized from original parameter name 'stages.2.blocks.10.mlp.conv.conv.weight'.\nRenamed 'self._param_constant393' to 'self.stages/2/blocks/10/mlp/conv/bn/weight', normalized from original parameter name 'stages.2.blocks.10.mlp.conv.bn.weight'.\nRenamed 'self._param_constant394' to 'self.stages/2/blocks/10/mlp/conv/bn/bias', normalized from original parameter name 'stages.2.blocks.10.mlp.conv.bn.bias'.\nRenamed 'self._tensor_constant216' to 'self.stages/2/blocks/10/mlp/conv/bn/running_mean', normalized from original parameter name 'stages.2.blocks.10.mlp.conv.bn.running_mean'.\nRenamed 'self._tensor_constant217' to 'self.stages/2/blocks/10/mlp/conv/bn/running_var', normalized from original parameter name 'stages.2.blocks.10.mlp.conv.bn.running_var'.\nRenamed 'self._param_constant395' to 'self.stages/2/blocks/10/mlp/fc1/weight', normalized from original parameter name 'stages.2.blocks.10.mlp.fc1.weight'.\nRenamed 'self._param_constant396' to 'self.stages/2/blocks/10/mlp/fc1/bias', normalized from original parameter name 'stages.2.blocks.10.mlp.fc1.bias'.\nRenamed 'self._param_constant397' to 'self.stages/2/blocks/10/mlp/fc2/weight', normalized from original parameter name 'stages.2.blocks.10.mlp.fc2.weight'.\nRenamed 'self._param_constant398' to 'self.stages/2/blocks/10/mlp/fc2/bias', normalized from original parameter name 'stages.2.blocks.10.mlp.fc2.bias'.\nRenamed 'self._param_constant399' to 'self.stages/2/blocks/10/layer_scale/gamma', normalized from original parameter name 'stages.2.blocks.10.layer_scale.gamma'.\nRenamed 'self._param_constant400' to 'self.stages/2/blocks/11/token_mixer/mixer/identity/weight', normalized from original parameter name 'stages.2.blocks.11.token_mixer.mixer.identity.weight'.\nRenamed 'self._param_constant401' to 'self.stages/2/blocks/11/token_mixer/mixer/identity/bias', normalized from original parameter name 'stages.2.blocks.11.token_mixer.mixer.identity.bias'.\nRenamed 'self._tensor_constant218' to 'self.stages/2/blocks/11/token_mixer/mixer/identity/running_mean', normalized from original parameter name 'stages.2.blocks.11.token_mixer.mixer.identity.running_mean'.\nRenamed 'self._tensor_constant219' to 'self.stages/2/blocks/11/token_mixer/mixer/identity/running_var', normalized from original parameter name 'stages.2.blocks.11.token_mixer.mixer.identity.running_var'.\nRenamed 'self._param_constant402' to 'self.stages/2/blocks/11/token_mixer/mixer/conv_scale/conv/weight', normalized from original parameter name 'stages.2.blocks.11.token_mixer.mixer.conv_scale.conv.weight'.\nRenamed 'self._param_constant403' to 'self.stages/2/blocks/11/token_mixer/mixer/conv_scale/bn/weight', normalized from original parameter name 'stages.2.blocks.11.token_mixer.mixer.conv_scale.bn.weight'.\nRenamed 'self._param_constant404' to 'self.stages/2/blocks/11/token_mixer/mixer/conv_scale/bn/bias', normalized from original parameter name 'stages.2.blocks.11.token_mixer.mixer.conv_scale.bn.bias'.\nRenamed 'self._tensor_constant220' to 'self.stages/2/blocks/11/token_mixer/mixer/conv_scale/bn/running_mean', normalized from original parameter name 'stages.2.blocks.11.token_mixer.mixer.conv_scale.bn.running_mean'.\nRenamed 'self._tensor_constant221' to 'self.stages/2/blocks/11/token_mixer/mixer/conv_scale/bn/running_var', normalized from original parameter name 'stages.2.blocks.11.token_mixer.mixer.conv_scale.bn.running_var'.\nRenamed 'self._param_constant405' to 'self.stages/2/blocks/11/token_mixer/mixer/conv_kxk/0/conv/weight', normalized from original parameter name 'stages.2.blocks.11.token_mixer.mixer.conv_kxk.0.conv.weight'.\nRenamed 'self._param_constant406' to 'self.stages/2/blocks/11/token_mixer/mixer/conv_kxk/0/bn/weight', normalized from original parameter name 'stages.2.blocks.11.token_mixer.mixer.conv_kxk.0.bn.weight'.\nRenamed 'self._param_constant407' to 'self.stages/2/blocks/11/token_mixer/mixer/conv_kxk/0/bn/bias', normalized from original parameter name 'stages.2.blocks.11.token_mixer.mixer.conv_kxk.0.bn.bias'.\nRenamed 'self._tensor_constant222' to 'self.stages/2/blocks/11/token_mixer/mixer/conv_kxk/0/bn/running_mean', normalized from original parameter name 'stages.2.blocks.11.token_mixer.mixer.conv_kxk.0.bn.running_mean'.\nRenamed 'self._tensor_constant223' to 'self.stages/2/blocks/11/token_mixer/mixer/conv_kxk/0/bn/running_var', normalized from original parameter name 'stages.2.blocks.11.token_mixer.mixer.conv_kxk.0.bn.running_var'.\nRenamed 'self._param_constant408' to 'self.stages/2/blocks/11/token_mixer/norm/identity/weight', normalized from original parameter name 'stages.2.blocks.11.token_mixer.norm.identity.weight'.\nRenamed 'self._param_constant409' to 'self.stages/2/blocks/11/token_mixer/norm/identity/bias', normalized from original parameter name 'stages.2.blocks.11.token_mixer.norm.identity.bias'.\nRenamed 'self._tensor_constant224' to 'self.stages/2/blocks/11/token_mixer/norm/identity/running_mean', normalized from original parameter name 'stages.2.blocks.11.token_mixer.norm.identity.running_mean'.\nRenamed 'self._tensor_constant225' to 'self.stages/2/blocks/11/token_mixer/norm/identity/running_var', normalized from original parameter name 'stages.2.blocks.11.token_mixer.norm.identity.running_var'.\nRenamed 'self._param_constant410' to 'self.stages/2/blocks/11/token_mixer/layer_scale/gamma', normalized from original parameter name 'stages.2.blocks.11.token_mixer.layer_scale.gamma'.\nRenamed 'self._param_constant411' to 'self.stages/2/blocks/11/mlp/conv/conv/weight', normalized from original parameter name 'stages.2.blocks.11.mlp.conv.conv.weight'.\nRenamed 'self._param_constant412' to 'self.stages/2/blocks/11/mlp/conv/bn/weight', normalized from original parameter name 'stages.2.blocks.11.mlp.conv.bn.weight'.\nRenamed 'self._param_constant413' to 'self.stages/2/blocks/11/mlp/conv/bn/bias', normalized from original parameter name 'stages.2.blocks.11.mlp.conv.bn.bias'.\nRenamed 'self._tensor_constant226' to 'self.stages/2/blocks/11/mlp/conv/bn/running_mean', normalized from original parameter name 'stages.2.blocks.11.mlp.conv.bn.running_mean'.\nRenamed 'self._tensor_constant227' to 'self.stages/2/blocks/11/mlp/conv/bn/running_var', normalized from original parameter name 'stages.2.blocks.11.mlp.conv.bn.running_var'.\nRenamed 'self._param_constant414' to 'self.stages/2/blocks/11/mlp/fc1/weight', normalized from original parameter name 'stages.2.blocks.11.mlp.fc1.weight'.\nRenamed 'self._param_constant415' to 'self.stages/2/blocks/11/mlp/fc1/bias', normalized from original parameter name 'stages.2.blocks.11.mlp.fc1.bias'.\nRenamed 'self._param_constant416' to 'self.stages/2/blocks/11/mlp/fc2/weight', normalized from original parameter name 'stages.2.blocks.11.mlp.fc2.weight'.\nRenamed 'self._param_constant417' to 'self.stages/2/blocks/11/mlp/fc2/bias', normalized from original parameter name 'stages.2.blocks.11.mlp.fc2.bias'.\nRenamed 'self._param_constant418' to 'self.stages/2/blocks/11/layer_scale/gamma', normalized from original parameter name 'stages.2.blocks.11.layer_scale.gamma'.\nRenamed 'self._param_constant419' to 'self.stages/3/downsample/proj/0/large_conv/conv/weight', normalized from original parameter name 'stages.3.downsample.proj.0.large_conv.conv.weight'.\nRenamed 'self._param_constant420' to 'self.stages/3/downsample/proj/0/large_conv/bn/weight', normalized from original parameter name 'stages.3.downsample.proj.0.large_conv.bn.weight'.\nRenamed 'self._param_constant421' to 'self.stages/3/downsample/proj/0/large_conv/bn/bias', normalized from original parameter name 'stages.3.downsample.proj.0.large_conv.bn.bias'.\nRenamed 'self._tensor_constant228' to 'self.stages/3/downsample/proj/0/large_conv/bn/running_mean', normalized from original parameter name 'stages.3.downsample.proj.0.large_conv.bn.running_mean'.\nRenamed 'self._tensor_constant229' to 'self.stages/3/downsample/proj/0/large_conv/bn/running_var', normalized from original parameter name 'stages.3.downsample.proj.0.large_conv.bn.running_var'.\nRenamed 'self._param_constant422' to 'self.stages/3/downsample/proj/0/small_conv/conv/weight', normalized from original parameter name 'stages.3.downsample.proj.0.small_conv.conv.weight'.\nRenamed 'self._param_constant423' to 'self.stages/3/downsample/proj/0/small_conv/bn/weight', normalized from original parameter name 'stages.3.downsample.proj.0.small_conv.bn.weight'.\nRenamed 'self._param_constant424' to 'self.stages/3/downsample/proj/0/small_conv/bn/bias', normalized from original parameter name 'stages.3.downsample.proj.0.small_conv.bn.bias'.\nRenamed 'self._tensor_constant230' to 'self.stages/3/downsample/proj/0/small_conv/bn/running_mean', normalized from original parameter name 'stages.3.downsample.proj.0.small_conv.bn.running_mean'.\nRenamed 'self._tensor_constant231' to 'self.stages/3/downsample/proj/0/small_conv/bn/running_var', normalized from original parameter name 'stages.3.downsample.proj.0.small_conv.bn.running_var'.\nRenamed 'self._param_constant425' to 'self.stages/3/downsample/proj/1/identity/weight', normalized from original parameter name 'stages.3.downsample.proj.1.identity.weight'.\nRenamed 'self._param_constant426' to 'self.stages/3/downsample/proj/1/identity/bias', normalized from original parameter name 'stages.3.downsample.proj.1.identity.bias'.\nRenamed 'self._tensor_constant232' to 'self.stages/3/downsample/proj/1/identity/running_mean', normalized from original parameter name 'stages.3.downsample.proj.1.identity.running_mean'.\nRenamed 'self._tensor_constant233' to 'self.stages/3/downsample/proj/1/identity/running_var', normalized from original parameter name 'stages.3.downsample.proj.1.identity.running_var'.\nRenamed 'self._param_constant427' to 'self.stages/3/downsample/proj/1/conv_kxk/0/conv/weight', normalized from original parameter name 'stages.3.downsample.proj.1.conv_kxk.0.conv.weight'.\nRenamed 'self._param_constant428' to 'self.stages/3/downsample/proj/1/conv_kxk/0/bn/weight', normalized from original parameter name 'stages.3.downsample.proj.1.conv_kxk.0.bn.weight'.\nRenamed 'self._param_constant429' to 'self.stages/3/downsample/proj/1/conv_kxk/0/bn/bias', normalized from original parameter name 'stages.3.downsample.proj.1.conv_kxk.0.bn.bias'.\nRenamed 'self._tensor_constant234' to 'self.stages/3/downsample/proj/1/conv_kxk/0/bn/running_mean', normalized from original parameter name 'stages.3.downsample.proj.1.conv_kxk.0.bn.running_mean'.\nRenamed 'self._tensor_constant235' to 'self.stages/3/downsample/proj/1/conv_kxk/0/bn/running_var', normalized from original parameter name 'stages.3.downsample.proj.1.conv_kxk.0.bn.running_var'.\nRenamed 'self._param_constant430' to 'self.stages/3/pos_emb/pos_enc/weight', normalized from original parameter name 'stages.3.pos_emb.pos_enc.weight'.\nRenamed 'self._param_constant431' to 'self.stages/3/pos_emb/pos_enc/bias', normalized from original parameter name 'stages.3.pos_emb.pos_enc.bias'.\nRenamed 'self._param_constant432' to 'self.stages/3/blocks/0/norm/weight', normalized from original parameter name 'stages.3.blocks.0.norm.weight'.\nRenamed 'self._param_constant433' to 'self.stages/3/blocks/0/norm/bias', normalized from original parameter name 'stages.3.blocks.0.norm.bias'.\nRenamed 'self._tensor_constant236' to 'self.stages/3/blocks/0/norm/running_mean', normalized from original parameter name 'stages.3.blocks.0.norm.running_mean'.\nRenamed 'self._tensor_constant237' to 'self.stages/3/blocks/0/norm/running_var', normalized from original parameter name 'stages.3.blocks.0.norm.running_var'.\nRenamed 'self._param_constant434' to 'self.stages/3/blocks/0/token_mixer/qkv/weight', normalized from original parameter name 'stages.3.blocks.0.token_mixer.qkv.weight'.\nRenamed 'self._param_constant435' to 'self.stages/3/blocks/0/token_mixer/proj/weight', normalized from original parameter name 'stages.3.blocks.0.token_mixer.proj.weight'.\nRenamed 'self._param_constant436' to 'self.stages/3/blocks/0/token_mixer/proj/bias', normalized from original parameter name 'stages.3.blocks.0.token_mixer.proj.bias'.\nRenamed 'self._param_constant437' to 'self.stages/3/blocks/0/layer_scale_1/gamma', normalized from original parameter name 'stages.3.blocks.0.layer_scale_1.gamma'.\nRenamed 'self._param_constant438' to 'self.stages/3/blocks/0/mlp/conv/conv/weight', normalized from original parameter name 'stages.3.blocks.0.mlp.conv.conv.weight'.\nRenamed 'self._param_constant439' to 'self.stages/3/blocks/0/mlp/conv/bn/weight', normalized from original parameter name 'stages.3.blocks.0.mlp.conv.bn.weight'.\nRenamed 'self._param_constant440' to 'self.stages/3/blocks/0/mlp/conv/bn/bias', normalized from original parameter name 'stages.3.blocks.0.mlp.conv.bn.bias'.\nRenamed 'self._tensor_constant238' to 'self.stages/3/blocks/0/mlp/conv/bn/running_mean', normalized from original parameter name 'stages.3.blocks.0.mlp.conv.bn.running_mean'.\nRenamed 'self._tensor_constant239' to 'self.stages/3/blocks/0/mlp/conv/bn/running_var', normalized from original parameter name 'stages.3.blocks.0.mlp.conv.bn.running_var'.\nRenamed 'self._param_constant441' to 'self.stages/3/blocks/0/mlp/fc1/weight', normalized from original parameter name 'stages.3.blocks.0.mlp.fc1.weight'.\nRenamed 'self._param_constant442' to 'self.stages/3/blocks/0/mlp/fc1/bias', normalized from original parameter name 'stages.3.blocks.0.mlp.fc1.bias'.\nRenamed 'self._param_constant443' to 'self.stages/3/blocks/0/mlp/fc2/weight', normalized from original parameter name 'stages.3.blocks.0.mlp.fc2.weight'.\nRenamed 'self._param_constant444' to 'self.stages/3/blocks/0/mlp/fc2/bias', normalized from original parameter name 'stages.3.blocks.0.mlp.fc2.bias'.\nRenamed 'self._param_constant445' to 'self.stages/3/blocks/0/layer_scale_2/gamma', normalized from original parameter name 'stages.3.blocks.0.layer_scale_2.gamma'.\nRenamed 'self._param_constant446' to 'self.stages/3/blocks/1/norm/weight', normalized from original parameter name 'stages.3.blocks.1.norm.weight'.\nRenamed 'self._param_constant447' to 'self.stages/3/blocks/1/norm/bias', normalized from original parameter name 'stages.3.blocks.1.norm.bias'.\nRenamed 'self._tensor_constant240' to 'self.stages/3/blocks/1/norm/running_mean', normalized from original parameter name 'stages.3.blocks.1.norm.running_mean'.\nRenamed 'self._tensor_constant241' to 'self.stages/3/blocks/1/norm/running_var', normalized from original parameter name 'stages.3.blocks.1.norm.running_var'.\nRenamed 'self._param_constant448' to 'self.stages/3/blocks/1/token_mixer/qkv/weight', normalized from original parameter name 'stages.3.blocks.1.token_mixer.qkv.weight'.\nRenamed 'self._param_constant449' to 'self.stages/3/blocks/1/token_mixer/proj/weight', normalized from original parameter name 'stages.3.blocks.1.token_mixer.proj.weight'.\nRenamed 'self._param_constant450' to 'self.stages/3/blocks/1/token_mixer/proj/bias', normalized from original parameter name 'stages.3.blocks.1.token_mixer.proj.bias'.\nRenamed 'self._param_constant451' to 'self.stages/3/blocks/1/layer_scale_1/gamma', normalized from original parameter name 'stages.3.blocks.1.layer_scale_1.gamma'.\nRenamed 'self._param_constant452' to 'self.stages/3/blocks/1/mlp/conv/conv/weight', normalized from original parameter name 'stages.3.blocks.1.mlp.conv.conv.weight'.\nRenamed 'self._param_constant453' to 'self.stages/3/blocks/1/mlp/conv/bn/weight', normalized from original parameter name 'stages.3.blocks.1.mlp.conv.bn.weight'.\nRenamed 'self._param_constant454' to 'self.stages/3/blocks/1/mlp/conv/bn/bias', normalized from original parameter name 'stages.3.blocks.1.mlp.conv.bn.bias'.\nRenamed 'self._tensor_constant242' to 'self.stages/3/blocks/1/mlp/conv/bn/running_mean', normalized from original parameter name 'stages.3.blocks.1.mlp.conv.bn.running_mean'.\nRenamed 'self._tensor_constant243' to 'self.stages/3/blocks/1/mlp/conv/bn/running_var', normalized from original parameter name 'stages.3.blocks.1.mlp.conv.bn.running_var'.\nRenamed 'self._param_constant455' to 'self.stages/3/blocks/1/mlp/fc1/weight', normalized from original parameter name 'stages.3.blocks.1.mlp.fc1.weight'.\nRenamed 'self._param_constant456' to 'self.stages/3/blocks/1/mlp/fc1/bias', normalized from original parameter name 'stages.3.blocks.1.mlp.fc1.bias'.\nRenamed 'self._param_constant457' to 'self.stages/3/blocks/1/mlp/fc2/weight', normalized from original parameter name 'stages.3.blocks.1.mlp.fc2.weight'.\nRenamed 'self._param_constant458' to 'self.stages/3/blocks/1/mlp/fc2/bias', normalized from original parameter name 'stages.3.blocks.1.mlp.fc2.bias'.\nRenamed 'self._param_constant459' to 'self.stages/3/blocks/1/layer_scale_2/gamma', normalized from original parameter name 'stages.3.blocks.1.layer_scale_2.gamma'.\nRenamed 'self._param_constant460' to 'self.stages/3/blocks/2/norm/weight', normalized from original parameter name 'stages.3.blocks.2.norm.weight'.\nRenamed 'self._param_constant461' to 'self.stages/3/blocks/2/norm/bias', normalized from original parameter name 'stages.3.blocks.2.norm.bias'.\nRenamed 'self._tensor_constant244' to 'self.stages/3/blocks/2/norm/running_mean', normalized from original parameter name 'stages.3.blocks.2.norm.running_mean'.\nRenamed 'self._tensor_constant245' to 'self.stages/3/blocks/2/norm/running_var', normalized from original parameter name 'stages.3.blocks.2.norm.running_var'.\nRenamed 'self._param_constant462' to 'self.stages/3/blocks/2/token_mixer/qkv/weight', normalized from original parameter name 'stages.3.blocks.2.token_mixer.qkv.weight'.\nRenamed 'self._param_constant463' to 'self.stages/3/blocks/2/token_mixer/proj/weight', normalized from original parameter name 'stages.3.blocks.2.token_mixer.proj.weight'.\nRenamed 'self._param_constant464' to 'self.stages/3/blocks/2/token_mixer/proj/bias', normalized from original parameter name 'stages.3.blocks.2.token_mixer.proj.bias'.\nRenamed 'self._param_constant465' to 'self.stages/3/blocks/2/layer_scale_1/gamma', normalized from original parameter name 'stages.3.blocks.2.layer_scale_1.gamma'.\nRenamed 'self._param_constant466' to 'self.stages/3/blocks/2/mlp/conv/conv/weight', normalized from original parameter name 'stages.3.blocks.2.mlp.conv.conv.weight'.\nRenamed 'self._param_constant467' to 'self.stages/3/blocks/2/mlp/conv/bn/weight', normalized from original parameter name 'stages.3.blocks.2.mlp.conv.bn.weight'.\nRenamed 'self._param_constant468' to 'self.stages/3/blocks/2/mlp/conv/bn/bias', normalized from original parameter name 'stages.3.blocks.2.mlp.conv.bn.bias'.\nRenamed 'self._tensor_constant246' to 'self.stages/3/blocks/2/mlp/conv/bn/running_mean', normalized from original parameter name 'stages.3.blocks.2.mlp.conv.bn.running_mean'.\nRenamed 'self._tensor_constant247' to 'self.stages/3/blocks/2/mlp/conv/bn/running_var', normalized from original parameter name 'stages.3.blocks.2.mlp.conv.bn.running_var'.\nRenamed 'self._param_constant469' to 'self.stages/3/blocks/2/mlp/fc1/weight', normalized from original parameter name 'stages.3.blocks.2.mlp.fc1.weight'.\nRenamed 'self._param_constant470' to 'self.stages/3/blocks/2/mlp/fc1/bias', normalized from original parameter name 'stages.3.blocks.2.mlp.fc1.bias'.\nRenamed 'self._param_constant471' to 'self.stages/3/blocks/2/mlp/fc2/weight', normalized from original parameter name 'stages.3.blocks.2.mlp.fc2.weight'.\nRenamed 'self._param_constant472' to 'self.stages/3/blocks/2/mlp/fc2/bias', normalized from original parameter name 'stages.3.blocks.2.mlp.fc2.bias'.\nRenamed 'self._param_constant473' to 'self.stages/3/blocks/2/layer_scale_2/gamma', normalized from original parameter name 'stages.3.blocks.2.layer_scale_2.gamma'.\nRenamed 'self._param_constant474' to 'self.stages/3/blocks/3/norm/weight', normalized from original parameter name 'stages.3.blocks.3.norm.weight'.\nRenamed 'self._param_constant475' to 'self.stages/3/blocks/3/norm/bias', normalized from original parameter name 'stages.3.blocks.3.norm.bias'.\nRenamed 'self._tensor_constant248' to 'self.stages/3/blocks/3/norm/running_mean', normalized from original parameter name 'stages.3.blocks.3.norm.running_mean'.\nRenamed 'self._tensor_constant249' to 'self.stages/3/blocks/3/norm/running_var', normalized from original parameter name 'stages.3.blocks.3.norm.running_var'.\nRenamed 'self._param_constant476' to 'self.stages/3/blocks/3/token_mixer/qkv/weight', normalized from original parameter name 'stages.3.blocks.3.token_mixer.qkv.weight'.\nRenamed 'self._param_constant477' to 'self.stages/3/blocks/3/token_mixer/proj/weight', normalized from original parameter name 'stages.3.blocks.3.token_mixer.proj.weight'.\nRenamed 'self._param_constant478' to 'self.stages/3/blocks/3/token_mixer/proj/bias', normalized from original parameter name 'stages.3.blocks.3.token_mixer.proj.bias'.\nRenamed 'self._param_constant479' to 'self.stages/3/blocks/3/layer_scale_1/gamma', normalized from original parameter name 'stages.3.blocks.3.layer_scale_1.gamma'.\nRenamed 'self._param_constant480' to 'self.stages/3/blocks/3/mlp/conv/conv/weight', normalized from original parameter name 'stages.3.blocks.3.mlp.conv.conv.weight'.\nRenamed 'self._param_constant481' to 'self.stages/3/blocks/3/mlp/conv/bn/weight', normalized from original parameter name 'stages.3.blocks.3.mlp.conv.bn.weight'.\nRenamed 'self._param_constant482' to 'self.stages/3/blocks/3/mlp/conv/bn/bias', normalized from original parameter name 'stages.3.blocks.3.mlp.conv.bn.bias'.\nRenamed 'self._tensor_constant250' to 'self.stages/3/blocks/3/mlp/conv/bn/running_mean', normalized from original parameter name 'stages.3.blocks.3.mlp.conv.bn.running_mean'.\nRenamed 'self._tensor_constant251' to 'self.stages/3/blocks/3/mlp/conv/bn/running_var', normalized from original parameter name 'stages.3.blocks.3.mlp.conv.bn.running_var'.\nRenamed 'self._param_constant483' to 'self.stages/3/blocks/3/mlp/fc1/weight', normalized from original parameter name 'stages.3.blocks.3.mlp.fc1.weight'.\nRenamed 'self._param_constant484' to 'self.stages/3/blocks/3/mlp/fc1/bias', normalized from original parameter name 'stages.3.blocks.3.mlp.fc1.bias'.\nRenamed 'self._param_constant485' to 'self.stages/3/blocks/3/mlp/fc2/weight', normalized from original parameter name 'stages.3.blocks.3.mlp.fc2.weight'.\nRenamed 'self._param_constant486' to 'self.stages/3/blocks/3/mlp/fc2/bias', normalized from original parameter name 'stages.3.blocks.3.mlp.fc2.bias'.\nRenamed 'self._param_constant487' to 'self.stages/3/blocks/3/layer_scale_2/gamma', normalized from original parameter name 'stages.3.blocks.3.layer_scale_2.gamma'.\nRenamed 'self._param_constant488' to 'self.final_conv/conv_scale/conv/weight', normalized from original parameter name 'final_conv.conv_scale.conv.weight'.\nRenamed 'self._param_constant489' to 'self.final_conv/conv_scale/bn/weight', normalized from original parameter name 'final_conv.conv_scale.bn.weight'.\nRenamed 'self._param_constant490' to 'self.final_conv/conv_scale/bn/bias', normalized from original parameter name 'final_conv.conv_scale.bn.bias'.\nRenamed 'self._tensor_constant252' to 'self.final_conv/conv_scale/bn/running_mean', normalized from original parameter name 'final_conv.conv_scale.bn.running_mean'.\nRenamed 'self._tensor_constant253' to 'self.final_conv/conv_scale/bn/running_var', normalized from original parameter name 'final_conv.conv_scale.bn.running_var'.\nRenamed 'self._param_constant491' to 'self.final_conv/conv_kxk/0/conv/weight', normalized from original parameter name 'final_conv.conv_kxk.0.conv.weight'.\nRenamed 'self._param_constant492' to 'self.final_conv/conv_kxk/0/bn/weight', normalized from original parameter name 'final_conv.conv_kxk.0.bn.weight'.\nRenamed 'self._param_constant493' to 'self.final_conv/conv_kxk/0/bn/bias', normalized from original parameter name 'final_conv.conv_kxk.0.bn.bias'.\nRenamed 'self._tensor_constant254' to 'self.final_conv/conv_kxk/0/bn/running_mean', normalized from original parameter name 'final_conv.conv_kxk.0.bn.running_mean'.\nRenamed 'self._tensor_constant255' to 'self.final_conv/conv_kxk/0/bn/running_var', normalized from original parameter name 'final_conv.conv_kxk.0.bn.running_var'.\nRenamed 'self._param_constant494' to 'self.final_conv/se/fc1/weight', normalized from original parameter name 'final_conv.se.fc1.weight'.\nRenamed 'self._param_constant495' to 'self.final_conv/se/fc1/bias', normalized from original parameter name 'final_conv.se.fc1.bias'.\nRenamed 'self._param_constant496' to 'self.final_conv/se/fc2/weight', normalized from original parameter name 'final_conv.se.fc2.weight'.\nRenamed 'self._param_constant497' to 'self.final_conv/se/fc2/bias', normalized from original parameter name 'final_conv.se.fc2.bias'.\nRenamed 'self._param_constant498' to 'self.head/fc/weight', normalized from original parameter name 'head.fc.weight'.\nRenamed 'self._param_constant499' to 'self.head/fc/bias', normalized from original parameter name 'head.fc.bias'.\n## Return values\ntorch.fx.GraphModule(<lambda>)",
      "text":"Running RestoreParameterAndBufferNames pass. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"Transform.run"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/_pass.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":240
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0010",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Running Modularize pass. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature Transform.run\n- self: <class 'torch.onnx._internal.fx.passes.modularization.Modularize'>\nFor detailed logging of graph modifications by this pass, either set `DiagnosticOptions.verbosity_level` to `logging.DEBUG` or use the environment variable `TORCH_LOGS='onnx_diagnostics'`.\n## Return values\ntorch.fx.GraphModule()",
      "text":"Running Modularize pass. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"Transform.run"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/_pass.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":240
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0010",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"FX Node: placeholder:arg0[name=l_x_]. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature FxOnnxInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.fx_onnx_interpreter.FxOnnxInterpreter'>\n- node: fx.Node(arg0)[placeholder]:Tensor(f32[1, 3, 400, 400])\n- fx_graph_module: torch.fx.GraphModule()\n- onnxfunction_dispatcher: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- onnxscript_graph: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptGraph'>\n- onnxscript_tracer: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptTracingEvaluator'>\n- fx_name_to_onnxscript_value: Dict[length=0](\nNone)\n## Return values\n<class 'NoneType'>",
      "text":"FX Node: placeholder:arg0[name=l_x_]. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"FxOnnxInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":393
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0008",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"FX Node: placeholder:l_x_[name=l_x_]. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature FxOnnxInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.fx_onnx_interpreter.FxOnnxInterpreter'>\n- node: fx.Node(l_x_)[placeholder]:Tensor(f32[1, 3, 400, 400])\n- fx_graph_module: torch.fx.GraphModule(torch_nn_modules_container_Sequential)\n- onnxfunction_dispatcher: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- onnxscript_graph: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptGraph'>\n- onnxscript_tracer: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptTracingEvaluator'>\n- fx_name_to_onnxscript_value: Dict[length=0](\nNone)\n## Return values\n<class 'NoneType'>",
      "text":"FX Node: placeholder:l_x_[name=l_x_]. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"FxOnnxInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":393
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0008",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"FX Node: placeholder:l_x_[name=l_x_]. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature FxOnnxInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.fx_onnx_interpreter.FxOnnxInterpreter'>\n- node: fx.Node(l_x_)[placeholder]:Tensor(f32[1, 3, 400, 400])\n- fx_graph_module: torch.fx.GraphModule(timm_models_fastvit_MobileOneBlock)\n- onnxfunction_dispatcher: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- onnxscript_graph: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptGraph'>\n- onnxscript_tracer: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptTracingEvaluator'>\n- fx_name_to_onnxscript_value: Dict[length=0](\nNone)\n## Return values\n<class 'NoneType'>",
      "text":"FX Node: placeholder:l_x_[name=l_x_]. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"FxOnnxInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":393
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0008",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"FX Node: placeholder:l_x_[name=l_x_]. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature FxOnnxInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.fx_onnx_interpreter.FxOnnxInterpreter'>\n- node: fx.Node(l_x_)[placeholder]:Tensor(f32[1, 3, 400, 400])\n- fx_graph_module: torch.fx.GraphModule(timm_layers_conv_bn_act_ConvNormAct)\n- onnxfunction_dispatcher: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- onnxscript_graph: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptGraph'>\n- onnxscript_tracer: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptTracingEvaluator'>\n- fx_name_to_onnxscript_value: Dict[length=0](\nNone)\n## Return values\n<class 'NoneType'>",
      "text":"FX Node: placeholder:l_x_[name=l_x_]. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"FxOnnxInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":393
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0008",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"FX Node: placeholder:l_x_[name=l_x_]. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature FxOnnxInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.fx_onnx_interpreter.FxOnnxInterpreter'>\n- node: fx.Node(l_x_)[placeholder]:Tensor(f32[1, 3, 400, 400])\n- fx_graph_module: torch.fx.GraphModule(torch_nn_modules_conv_Conv2d)\n- onnxfunction_dispatcher: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- onnxscript_graph: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptGraph'>\n- onnxscript_tracer: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptTracingEvaluator'>\n- fx_name_to_onnxscript_value: Dict[length=0](\nNone)\n## Return values\n<class 'NoneType'>",
      "text":"FX Node: placeholder:l_x_[name=l_x_]. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"FxOnnxInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":393
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0008",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"FX Node: get_attr:stem/0/conv_scale/conv/weight[name=stem_0_conv_scale_conv_weight]. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature FxOnnxInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.fx_onnx_interpreter.FxOnnxInterpreter'>\n- node: fx.Node(stem/0/conv_scale/conv/weight)[get_attr]:None\n- fx_graph_module: torch.fx.GraphModule(torch_nn_modules_conv_Conv2d)\n- onnxfunction_dispatcher: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- onnxscript_graph: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptGraph'>\n- onnxscript_tracer: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptTracingEvaluator'>\n- fx_name_to_onnxscript_value: Dict[length=1](\nl_x_: `TorchScriptTensor(f32[1, 3, 400, 400])`,\n)\n## PyTorch source information\n```\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 1333, in forward\n    x = self.forward_features(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 1314, in forward_features\n    x = self.stem(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 151, in forward\n    scale_out = self.conv_scale(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/layers/conv_bn_act.py\", line 83, in forward\n    x = self.conv(x)\n\n```\n## Return values\n<class 'NoneType'>",
      "text":"FX Node: get_attr:stem/0/conv_scale/conv/weight[name=stem_0_conv_scale_conv_weight]. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"FxOnnxInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":393
        }
       }
      },
      {
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py"
        },
        "region":{
         "snippet":{
          "text":"x = self.forward_features(x)"
         },
         "startLine":1333
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0008",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Searching operator overload: 'aten.convolution.default' in onnx registry...\n\n\n## Additional Message:\n\n## Function Signature\n### Function Signature OnnxFunctionDispatcher.get_function_overloads\n- self: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 200, 200])\n- diagnostic_context: <class 'torch.onnx._internal.fx.diagnostics.DiagnosticContext'>\n## Return values\nList[length=1](\nregistration.ONNXFunction(aten::convolution.default, is_custom=False, is_complex=False),\n)",
      "text":"Searching operator overload: 'aten.convolution.default' in onnx registry...\n"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"OnnxFunctionDispatcher.get_function_overloads"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/onnxfunction_dispatcher.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":329
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0016",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"FX Node: aten.convolution.default. \nONNX Node: aten_convolution[opset=pkg.onnxscript.torch_lib;is_custom=False]. \n\n\n## Additional Message:\n\n## Function Signature\n### Function Signature OnnxFunctionDispatcher._find_the_perfect_or_nearest_match_onnxfunction\n- self: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 200, 200])\n- default_and_custom_functions: List[length=1](\nregistration.ONNXFunction(aten::convolution.default, is_custom=False, is_complex=False),\n)\n- onnx_args: Tuple[length=9](\n`TorchScriptTensor(f32[1, 3, 400, 400])`,\n`TorchScriptTensor(f32[64, 3, 1, 1])`,\n<class 'NoneType'>,\nList[length=2](\n2,\n2,\n),\nList[length=2](\n0,\n0,\n),\nList[length=2](\n1,\n1,\n),\nFalse,\nList[length=2](\n0,\n0,\n),\n1,\n)\n- onnx_kwargs: Dict[length=0](\nNone)\n- diagnostic_context: <class 'torch.onnx._internal.fx.diagnostics.DiagnosticContext'>\n## Checking perfect match...\n`TracedOnnxFunction(aten_convolution)`\nmatch score: -2\n## Return values\n`TracedOnnxFunction(aten_convolution)`",
      "text":"FX Node: aten.convolution.default. \nONNX Node: aten_convolution[opset=pkg.onnxscript.torch_lib;is_custom=False]. \n"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"OnnxFunctionDispatcher._find_the_perfect_or_nearest_match_onnxfunction"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/onnxfunction_dispatcher.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":179
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0014",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"FX Node: call_function:aten.convolution.default[name=convolution]. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature FxOnnxInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.fx_onnx_interpreter.FxOnnxInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 200, 200])\n- fx_graph_module: torch.fx.GraphModule(torch_nn_modules_conv_Conv2d)\n- onnxfunction_dispatcher: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- onnxscript_graph: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptGraph'>\n- onnxscript_tracer: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptTracingEvaluator'>\n- fx_name_to_onnxscript_value: Dict[length=2](\nl_x_: `TorchScriptTensor(f32[1, 3, 400, 400])`,\nstem_0_conv_scale_conv_weight: `TorchScriptTensor(f32[64, 3, 1, 1])`,\n)\n## PyTorch source information\n```\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 1333, in forward\n    x = self.forward_features(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 1314, in forward_features\n    x = self.stem(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 151, in forward\n    scale_out = self.conv_scale(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/layers/conv_bn_act.py\", line 83, in forward\n    x = self.conv(x)\n\n```\n## Return values\n<class 'NoneType'>",
      "text":"FX Node: call_function:aten.convolution.default[name=convolution]. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"FxOnnxInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":393
        }
       }
      },
      {
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py"
        },
        "region":{
         "snippet":{
          "text":"x = self.forward_features(x)"
         },
         "startLine":1333
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0008",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"FX Node: output:output[name=output]. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature FxOnnxInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.fx_onnx_interpreter.FxOnnxInterpreter'>\n- node: fx.Node(output)[output]:None\n- fx_graph_module: torch.fx.GraphModule(torch_nn_modules_conv_Conv2d)\n- onnxfunction_dispatcher: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- onnxscript_graph: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptGraph'>\n- onnxscript_tracer: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptTracingEvaluator'>\n- fx_name_to_onnxscript_value: Dict[length=3](\nl_x_: `TorchScriptTensor(f32[1, 3, 400, 400])`,\nstem_0_conv_scale_conv_weight: `TorchScriptTensor(f32[64, 3, 1, 1])`,\nconvolution: `TorchScriptTensor(f32[1, 64, 200, 200])`,\n)\n## Return values\n<class 'NoneType'>",
      "text":"FX Node: output:output[name=output]. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"FxOnnxInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":393
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0008",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"FX Graph: torch_nn_modules_conv_Conv2d. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature FxOnnxInterpreter.run\n- self: <class 'torch.onnx._internal.fx.fx_onnx_interpreter.FxOnnxInterpreter'>\n- fx_graph_module: torch.fx.GraphModule(torch_nn_modules_conv_Conv2d)\n- onnxfunction_dispatcher: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- parent_onnxscript_graph: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptGraph'>\n## Return values\n<class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptGraph'>",
      "text":"FX Graph: torch_nn_modules_conv_Conv2d. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"FxOnnxInterpreter.run"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":468
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0007",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"FX Node: call_module:getattr_L__self___stem___0___conv_scale_conv_1[name=getattr_l__self___stem___0___conv_scale_conv_1]. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature FxOnnxInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.fx_onnx_interpreter.FxOnnxInterpreter'>\n- node: fx.Node(getattr_L__self___stem___0___conv_scale_conv_1)[call_module]:Tensor(f32[1, 64, 200, 200])\n- fx_graph_module: torch.fx.GraphModule(timm_layers_conv_bn_act_ConvNormAct)\n- onnxfunction_dispatcher: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- onnxscript_graph: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptGraph'>\n- onnxscript_tracer: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptTracingEvaluator'>\n- fx_name_to_onnxscript_value: Dict[length=1](\nl_x_: `TorchScriptTensor(f32[1, 3, 400, 400])`,\n)\n## PyTorch source information\n```\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 1333, in forward\n    x = self.forward_features(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 1314, in forward_features\n    x = self.stem(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 151, in forward\n    scale_out = self.conv_scale(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/layers/conv_bn_act.py\", line 83, in forward\n    x = self.conv(x)\n\n```\n## Return values\n<class 'NoneType'>",
      "text":"FX Node: call_module:getattr_L__self___stem___0___conv_scale_conv_1[name=getattr_l__self___stem___0___conv_scale_conv_1]. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"FxOnnxInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":393
        }
       }
      },
      {
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py"
        },
        "region":{
         "snippet":{
          "text":"x = self.forward_features(x)"
         },
         "startLine":1333
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0008",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"FX Node: placeholder:convolution[name=convolution]. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature FxOnnxInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.fx_onnx_interpreter.FxOnnxInterpreter'>\n- node: fx.Node(convolution)[placeholder]:Tensor(f32[1, 64, 200, 200])\n- fx_graph_module: torch.fx.GraphModule(timm_layers_norm_act_BatchNormAct2d)\n- onnxfunction_dispatcher: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- onnxscript_graph: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptGraph'>\n- onnxscript_tracer: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptTracingEvaluator'>\n- fx_name_to_onnxscript_value: Dict[length=0](\nNone)\n## PyTorch source information\n```\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 1333, in forward\n    x = self.forward_features(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 1314, in forward_features\n    x = self.stem(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 151, in forward\n    scale_out = self.conv_scale(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/layers/conv_bn_act.py\", line 83, in forward\n    x = self.conv(x)\n\n```\n## Return values\n<class 'NoneType'>",
      "text":"FX Node: placeholder:convolution[name=convolution]. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"FxOnnxInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":393
        }
       }
      },
      {
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py"
        },
        "region":{
         "snippet":{
          "text":"x = self.forward_features(x)"
         },
         "startLine":1333
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0008",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"FX Node: get_attr:stem/0/conv_scale/bn/weight[name=stem_0_conv_scale_bn_weight]. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature FxOnnxInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.fx_onnx_interpreter.FxOnnxInterpreter'>\n- node: fx.Node(stem/0/conv_scale/bn/weight)[get_attr]:None\n- fx_graph_module: torch.fx.GraphModule(timm_layers_norm_act_BatchNormAct2d)\n- onnxfunction_dispatcher: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- onnxscript_graph: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptGraph'>\n- onnxscript_tracer: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptTracingEvaluator'>\n- fx_name_to_onnxscript_value: Dict[length=1](\nconvolution: `TorchScriptTensor(f32[1, 64, 200, 200])`,\n)\n## PyTorch source information\n```\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 1333, in forward\n    x = self.forward_features(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 1314, in forward_features\n    x = self.stem(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 151, in forward\n    scale_out = self.conv_scale(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/layers/conv_bn_act.py\", line 84, in forward\n    x = self.bn(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/layers/norm_act.py\", line 136, in forward\n    x = F.batch_norm(\n\n```\n## Return values\n<class 'NoneType'>",
      "text":"FX Node: get_attr:stem/0/conv_scale/bn/weight[name=stem_0_conv_scale_bn_weight]. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"FxOnnxInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":393
        }
       }
      },
      {
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py"
        },
        "region":{
         "snippet":{
          "text":"x = self.forward_features(x)"
         },
         "startLine":1333
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0008",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"FX Node: get_attr:stem/0/conv_scale/bn/bias[name=stem_0_conv_scale_bn_bias]. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature FxOnnxInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.fx_onnx_interpreter.FxOnnxInterpreter'>\n- node: fx.Node(stem/0/conv_scale/bn/bias)[get_attr]:None\n- fx_graph_module: torch.fx.GraphModule(timm_layers_norm_act_BatchNormAct2d)\n- onnxfunction_dispatcher: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- onnxscript_graph: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptGraph'>\n- onnxscript_tracer: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptTracingEvaluator'>\n- fx_name_to_onnxscript_value: Dict[length=2](\nconvolution: `TorchScriptTensor(f32[1, 64, 200, 200])`,\nstem_0_conv_scale_bn_weight: `TorchScriptTensor(f32[64])`,\n)\n## PyTorch source information\n```\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 1333, in forward\n    x = self.forward_features(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 1314, in forward_features\n    x = self.stem(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 151, in forward\n    scale_out = self.conv_scale(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/layers/conv_bn_act.py\", line 84, in forward\n    x = self.bn(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/layers/norm_act.py\", line 136, in forward\n    x = F.batch_norm(\n\n```\n## Return values\n<class 'NoneType'>",
      "text":"FX Node: get_attr:stem/0/conv_scale/bn/bias[name=stem_0_conv_scale_bn_bias]. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"FxOnnxInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":393
        }
       }
      },
      {
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py"
        },
        "region":{
         "snippet":{
          "text":"x = self.forward_features(x)"
         },
         "startLine":1333
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0008",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"FX Node: get_attr:stem/0/conv_scale/bn/running_mean[name=stem_0_conv_scale_bn_running_mean]. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature FxOnnxInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.fx_onnx_interpreter.FxOnnxInterpreter'>\n- node: fx.Node(stem/0/conv_scale/bn/running_mean)[get_attr]:None\n- fx_graph_module: torch.fx.GraphModule(timm_layers_norm_act_BatchNormAct2d)\n- onnxfunction_dispatcher: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- onnxscript_graph: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptGraph'>\n- onnxscript_tracer: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptTracingEvaluator'>\n- fx_name_to_onnxscript_value: Dict[length=3](\nconvolution: `TorchScriptTensor(f32[1, 64, 200, 200])`,\nstem_0_conv_scale_bn_weight: `TorchScriptTensor(f32[64])`,\nstem_0_conv_scale_bn_bias: `TorchScriptTensor(f32[64])`,\n)\n## PyTorch source information\n```\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 1333, in forward\n    x = self.forward_features(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 1314, in forward_features\n    x = self.stem(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 151, in forward\n    scale_out = self.conv_scale(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/layers/conv_bn_act.py\", line 84, in forward\n    x = self.bn(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/layers/norm_act.py\", line 136, in forward\n    x = F.batch_norm(\n\n```\n## Return values\n<class 'NoneType'>",
      "text":"FX Node: get_attr:stem/0/conv_scale/bn/running_mean[name=stem_0_conv_scale_bn_running_mean]. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"FxOnnxInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":393
        }
       }
      },
      {
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py"
        },
        "region":{
         "snippet":{
          "text":"x = self.forward_features(x)"
         },
         "startLine":1333
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0008",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"FX Node: get_attr:stem/0/conv_scale/bn/running_var[name=stem_0_conv_scale_bn_running_var]. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature FxOnnxInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.fx_onnx_interpreter.FxOnnxInterpreter'>\n- node: fx.Node(stem/0/conv_scale/bn/running_var)[get_attr]:None\n- fx_graph_module: torch.fx.GraphModule(timm_layers_norm_act_BatchNormAct2d)\n- onnxfunction_dispatcher: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- onnxscript_graph: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptGraph'>\n- onnxscript_tracer: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptTracingEvaluator'>\n- fx_name_to_onnxscript_value: Dict[length=4](\nconvolution: `TorchScriptTensor(f32[1, 64, 200, 200])`,\nstem_0_conv_scale_bn_weight: `TorchScriptTensor(f32[64])`,\nstem_0_conv_scale_bn_bias: `TorchScriptTensor(f32[64])`,\nstem_0_conv_scale_bn_running_mean: `TorchScriptTensor(f32[64])`,\n)\n## PyTorch source information\n```\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 1333, in forward\n    x = self.forward_features(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 1314, in forward_features\n    x = self.stem(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 151, in forward\n    scale_out = self.conv_scale(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/layers/conv_bn_act.py\", line 84, in forward\n    x = self.bn(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/layers/norm_act.py\", line 136, in forward\n    x = F.batch_norm(\n\n```\n## Return values\n<class 'NoneType'>",
      "text":"FX Node: get_attr:stem/0/conv_scale/bn/running_var[name=stem_0_conv_scale_bn_running_var]. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"FxOnnxInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":393
        }
       }
      },
      {
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py"
        },
        "region":{
         "snippet":{
          "text":"x = self.forward_features(x)"
         },
         "startLine":1333
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0008",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Searching operator overload: 'aten._native_batch_norm_legit_no_training.default' in onnx registry...\n\n\n## Additional Message:\n\n## Function Signature\n### Function Signature OnnxFunctionDispatcher.get_function_overloads\n- self: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 200, 200]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n- diagnostic_context: <class 'torch.onnx._internal.fx.diagnostics.DiagnosticContext'>\n## Return values\nList[length=1](\nregistration.ONNXFunction(aten::_native_batch_norm_legit_no_training.default, is_custom=False, is_complex=False),\n)",
      "text":"Searching operator overload: 'aten._native_batch_norm_legit_no_training.default' in onnx registry...\n"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"OnnxFunctionDispatcher.get_function_overloads"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/onnxfunction_dispatcher.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":329
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0016",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"FX Node: aten._native_batch_norm_legit_no_training.default. \nONNX Node: aten__native_batch_norm_no_training[opset=pkg.onnxscript.torch_lib;is_custom=False]. \n\n\n## Additional Message:\n\n## Function Signature\n### Function Signature OnnxFunctionDispatcher._find_the_perfect_or_nearest_match_onnxfunction\n- self: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 200, 200]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n- default_and_custom_functions: List[length=1](\nregistration.ONNXFunction(aten::_native_batch_norm_legit_no_training.default, is_custom=False, is_complex=False),\n)\n- onnx_args: Tuple[length=7](\n`TorchScriptTensor(f32[1, 64, 200, 200])`,\n`TorchScriptTensor(f32[64])`,\n`TorchScriptTensor(f32[64])`,\n`TorchScriptTensor(f32[64])`,\n`TorchScriptTensor(f32[64])`,\n0.1,\n1e-05,\n)\n- onnx_kwargs: Dict[length=0](\nNone)\n- diagnostic_context: <class 'torch.onnx._internal.fx.diagnostics.DiagnosticContext'>\n## Checking perfect match...\n`TracedOnnxFunction(aten__native_batch_norm_no_training)`\nmatch score: 5\n## Return values\n`TracedOnnxFunction(aten__native_batch_norm_no_training)`",
      "text":"FX Node: aten._native_batch_norm_legit_no_training.default. \nONNX Node: aten__native_batch_norm_no_training[opset=pkg.onnxscript.torch_lib;is_custom=False]. \n"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"OnnxFunctionDispatcher._find_the_perfect_or_nearest_match_onnxfunction"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/onnxfunction_dispatcher.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":179
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0014",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"FX Node: call_function:aten._native_batch_norm_legit_no_training.default[name=_native_batch_norm_legit_no_training]. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature FxOnnxInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.fx_onnx_interpreter.FxOnnxInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 200, 200]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n- fx_graph_module: torch.fx.GraphModule(timm_layers_norm_act_BatchNormAct2d)\n- onnxfunction_dispatcher: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- onnxscript_graph: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptGraph'>\n- onnxscript_tracer: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptTracingEvaluator'>\n- fx_name_to_onnxscript_value: Dict[length=5](\nconvolution: `TorchScriptTensor(f32[1, 64, 200, 200])`,\nstem_0_conv_scale_bn_weight: `TorchScriptTensor(f32[64])`,\nstem_0_conv_scale_bn_bias: `TorchScriptTensor(f32[64])`,\nstem_0_conv_scale_bn_running_mean: `TorchScriptTensor(f32[64])`,\nstem_0_conv_scale_bn_running_var: `TorchScriptTensor(f32[64])`,\n)\n## PyTorch source information\n```\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 1333, in forward\n    x = self.forward_features(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 1314, in forward_features\n    x = self.stem(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 151, in forward\n    scale_out = self.conv_scale(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/layers/conv_bn_act.py\", line 84, in forward\n    x = self.bn(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/layers/norm_act.py\", line 136, in forward\n    x = F.batch_norm(\n\n```\n## Return values\n<class 'NoneType'>",
      "text":"FX Node: call_function:aten._native_batch_norm_legit_no_training.default[name=_native_batch_norm_legit_no_training]. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"FxOnnxInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":393
        }
       }
      },
      {
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py"
        },
        "region":{
         "snippet":{
          "text":"x = self.forward_features(x)"
         },
         "startLine":1333
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0008",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"FX Node: call_function:<built-in function getitem>[name=getitem]. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature FxOnnxInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.fx_onnx_interpreter.FxOnnxInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 200, 200])\n- fx_graph_module: torch.fx.GraphModule(timm_layers_norm_act_BatchNormAct2d)\n- onnxfunction_dispatcher: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- onnxscript_graph: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptGraph'>\n- onnxscript_tracer: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptTracingEvaluator'>\n- fx_name_to_onnxscript_value: Dict[length=6](\nconvolution: `TorchScriptTensor(f32[1, 64, 200, 200])`,\nstem_0_conv_scale_bn_weight: `TorchScriptTensor(f32[64])`,\nstem_0_conv_scale_bn_bias: `TorchScriptTensor(f32[64])`,\nstem_0_conv_scale_bn_running_mean: `TorchScriptTensor(f32[64])`,\nstem_0_conv_scale_bn_running_var: `TorchScriptTensor(f32[64])`,\n_native_batch_norm_legit_no_training: Tuple[length=3](\n`TorchScriptTensor(f32[1, 64, 200, 200])`,\n`TorchScriptTensor(f32[0])`,\n`TorchScriptTensor(f32[0])`,\n),\n)\n## PyTorch source information\n```\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 1333, in forward\n    x = self.forward_features(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 1314, in forward_features\n    x = self.stem(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 151, in forward\n    scale_out = self.conv_scale(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/layers/conv_bn_act.py\", line 84, in forward\n    x = self.bn(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/layers/norm_act.py\", line 136, in forward\n    x = F.batch_norm(\n\n```\n## Return values\n<class 'NoneType'>",
      "text":"FX Node: call_function:<built-in function getitem>[name=getitem]. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"FxOnnxInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":393
        }
       }
      },
      {
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py"
        },
        "region":{
         "snippet":{
          "text":"x = self.forward_features(x)"
         },
         "startLine":1333
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0008",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"FX Node: output:output[name=output]. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature FxOnnxInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.fx_onnx_interpreter.FxOnnxInterpreter'>\n- node: fx.Node(output)[output]:None\n- fx_graph_module: torch.fx.GraphModule(timm_layers_norm_act_BatchNormAct2d)\n- onnxfunction_dispatcher: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- onnxscript_graph: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptGraph'>\n- onnxscript_tracer: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptTracingEvaluator'>\n- fx_name_to_onnxscript_value: Dict[length=7](\nconvolution: `TorchScriptTensor(f32[1, 64, 200, 200])`,\nstem_0_conv_scale_bn_weight: `TorchScriptTensor(f32[64])`,\nstem_0_conv_scale_bn_bias: `TorchScriptTensor(f32[64])`,\nstem_0_conv_scale_bn_running_mean: `TorchScriptTensor(f32[64])`,\nstem_0_conv_scale_bn_running_var: `TorchScriptTensor(f32[64])`,\n_native_batch_norm_legit_no_training: Tuple[length=3](\n`TorchScriptTensor(f32[1, 64, 200, 200])`,\n`TorchScriptTensor(f32[0])`,\n`TorchScriptTensor(f32[0])`,\n),\ngetitem: `TorchScriptTensor(f32[1, 64, 200, 200])`,\n)\n## Return values\n<class 'NoneType'>",
      "text":"FX Node: output:output[name=output]. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"FxOnnxInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":393
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0008",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"FX Graph: timm_layers_norm_act_BatchNormAct2d. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature FxOnnxInterpreter.run\n- self: <class 'torch.onnx._internal.fx.fx_onnx_interpreter.FxOnnxInterpreter'>\n- fx_graph_module: torch.fx.GraphModule(timm_layers_norm_act_BatchNormAct2d)\n- onnxfunction_dispatcher: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- parent_onnxscript_graph: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptGraph'>\n## Return values\n<class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptGraph'>",
      "text":"FX Graph: timm_layers_norm_act_BatchNormAct2d. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"FxOnnxInterpreter.run"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":468
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0007",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"FX Node: call_module:getattr_L__self___stem___0___conv_scale_bn_1[name=getattr_l__self___stem___0___conv_scale_bn_1]. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature FxOnnxInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.fx_onnx_interpreter.FxOnnxInterpreter'>\n- node: fx.Node(getattr_L__self___stem___0___conv_scale_bn_1)[call_module]:Tensor(f32[1, 64, 200, 200])\n- fx_graph_module: torch.fx.GraphModule(timm_layers_conv_bn_act_ConvNormAct)\n- onnxfunction_dispatcher: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- onnxscript_graph: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptGraph'>\n- onnxscript_tracer: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptTracingEvaluator'>\n- fx_name_to_onnxscript_value: Dict[length=2](\nl_x_: `TorchScriptTensor(f32[1, 3, 400, 400])`,\ngetattr_l__self___stem___0___conv_scale_conv_1: `TorchScriptTensor(f32[1, 64, 200, 200])`,\n)\n## PyTorch source information\n```\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 1333, in forward\n    x = self.forward_features(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 1314, in forward_features\n    x = self.stem(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 151, in forward\n    scale_out = self.conv_scale(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/layers/conv_bn_act.py\", line 84, in forward\n    x = self.bn(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/layers/norm_act.py\", line 136, in forward\n    x = F.batch_norm(\n\n```\n## Return values\n<class 'NoneType'>",
      "text":"FX Node: call_module:getattr_L__self___stem___0___conv_scale_bn_1[name=getattr_l__self___stem___0___conv_scale_bn_1]. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"FxOnnxInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":393
        }
       }
      },
      {
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py"
        },
        "region":{
         "snippet":{
          "text":"x = self.forward_features(x)"
         },
         "startLine":1333
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0008",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"FX Node: output:output[name=output]. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature FxOnnxInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.fx_onnx_interpreter.FxOnnxInterpreter'>\n- node: fx.Node(output)[output]:None\n- fx_graph_module: torch.fx.GraphModule(timm_layers_conv_bn_act_ConvNormAct)\n- onnxfunction_dispatcher: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- onnxscript_graph: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptGraph'>\n- onnxscript_tracer: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptTracingEvaluator'>\n- fx_name_to_onnxscript_value: Dict[length=3](\nl_x_: `TorchScriptTensor(f32[1, 3, 400, 400])`,\ngetattr_l__self___stem___0___conv_scale_conv_1: `TorchScriptTensor(f32[1, 64, 200, 200])`,\ngetattr_l__self___stem___0___conv_scale_bn_1: `TorchScriptTensor(f32[1, 64, 200, 200])`,\n)\n## Return values\n<class 'NoneType'>",
      "text":"FX Node: output:output[name=output]. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"FxOnnxInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":393
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0008",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"FX Graph: timm_layers_conv_bn_act_ConvNormAct. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature FxOnnxInterpreter.run\n- self: <class 'torch.onnx._internal.fx.fx_onnx_interpreter.FxOnnxInterpreter'>\n- fx_graph_module: torch.fx.GraphModule(timm_layers_conv_bn_act_ConvNormAct)\n- onnxfunction_dispatcher: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- parent_onnxscript_graph: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptGraph'>\n## Return values\n<class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptGraph'>",
      "text":"FX Graph: timm_layers_conv_bn_act_ConvNormAct. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"FxOnnxInterpreter.run"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":468
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0007",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"FX Node: call_module:getattr_L__self___stem___0___conv_scale_1[name=getattr_l__self___stem___0___conv_scale_1]. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature FxOnnxInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.fx_onnx_interpreter.FxOnnxInterpreter'>\n- node: fx.Node(getattr_L__self___stem___0___conv_scale_1)[call_module]:Tensor(f32[1, 64, 200, 200])\n- fx_graph_module: torch.fx.GraphModule(timm_models_fastvit_MobileOneBlock)\n- onnxfunction_dispatcher: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- onnxscript_graph: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptGraph'>\n- onnxscript_tracer: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptTracingEvaluator'>\n- fx_name_to_onnxscript_value: Dict[length=1](\nl_x_: `TorchScriptTensor(f32[1, 3, 400, 400])`,\n)\n## PyTorch source information\n```\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 1333, in forward\n    x = self.forward_features(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 1314, in forward_features\n    x = self.stem(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 151, in forward\n    scale_out = self.conv_scale(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/layers/conv_bn_act.py\", line 83, in forward\n    x = self.conv(x)\n\n```\n## Return values\n<class 'NoneType'>",
      "text":"FX Node: call_module:getattr_L__self___stem___0___conv_scale_1[name=getattr_l__self___stem___0___conv_scale_1]. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"FxOnnxInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":393
        }
       }
      },
      {
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py"
        },
        "region":{
         "snippet":{
          "text":"x = self.forward_features(x)"
         },
         "startLine":1333
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0008",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Searching operator overload: 'aten.scalar_tensor.default' in onnx registry...\n\n\n## Additional Message:\n\n## Function Signature\n### Function Signature OnnxFunctionDispatcher.get_function_overloads\n- self: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- node: fx.Node(aten.scalar_tensor.default)[call_function]:Tensor(f32[])\n- diagnostic_context: <class 'torch.onnx._internal.fx.diagnostics.DiagnosticContext'>\n## Return values\nList[length=2](\nregistration.ONNXFunction(aten::scalar_tensor.default, is_custom=False, is_complex=False),\nregistration.ONNXFunction(aten::scalar_tensor.default, is_custom=False, is_complex=False),\n)",
      "text":"Searching operator overload: 'aten.scalar_tensor.default' in onnx registry...\n"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"OnnxFunctionDispatcher.get_function_overloads"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/onnxfunction_dispatcher.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":329
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0016",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"FX Node: aten.scalar_tensor.default. \nONNX Node: aten_scalar_tensor[opset=pkg.onnxscript.torch_lib;is_custom=False]. \nONNX Node: aten_scalar_tensor_sym_number[opset=pkg.onnxscript.torch_lib;is_custom=False]. \n\n\n## Additional Message:\n\n## Function Signature\n### Function Signature OnnxFunctionDispatcher._find_the_perfect_or_nearest_match_onnxfunction\n- self: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- node: fx.Node(aten.scalar_tensor.default)[call_function]:Tensor(f32[])\n- default_and_custom_functions: List[length=2](\nregistration.ONNXFunction(aten::scalar_tensor.default, is_custom=False, is_complex=False),\nregistration.ONNXFunction(aten::scalar_tensor.default, is_custom=False, is_complex=False),\n)\n- onnx_args: Tuple[length=1](\n0,\n)\n- onnx_kwargs: Dict[length=1](\ndtype: 1,\n)\n- diagnostic_context: <class 'torch.onnx._internal.fx.diagnostics.DiagnosticContext'>\n## Checking perfect match...\n`TracedOnnxFunction(aten_scalar_tensor_sym_number)`\nmatch score: 1\n## Return values\n`TracedOnnxFunction(aten_scalar_tensor_sym_number)`",
      "text":"FX Node: aten.scalar_tensor.default. \nONNX Node: aten_scalar_tensor[opset=pkg.onnxscript.torch_lib;is_custom=False]. \nONNX Node: aten_scalar_tensor_sym_number[opset=pkg.onnxscript.torch_lib;is_custom=False]. \n"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"OnnxFunctionDispatcher._find_the_perfect_or_nearest_match_onnxfunction"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/onnxfunction_dispatcher.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":179
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0014",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"FX Node: call_function:aten.scalar_tensor.default[name=scalar_tensor_default]. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature FxOnnxInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.fx_onnx_interpreter.FxOnnxInterpreter'>\n- node: fx.Node(aten.scalar_tensor.default)[call_function]:Tensor(f32[])\n- fx_graph_module: torch.fx.GraphModule(timm_models_fastvit_MobileOneBlock)\n- onnxfunction_dispatcher: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- onnxscript_graph: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptGraph'>\n- onnxscript_tracer: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptTracingEvaluator'>\n- fx_name_to_onnxscript_value: Dict[length=2](\nl_x_: `TorchScriptTensor(f32[1, 3, 400, 400])`,\ngetattr_l__self___stem___0___conv_scale_1: `TorchScriptTensor(f32[1, 64, 200, 200])`,\n)\n## PyTorch source information\n```\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 1333, in forward\n    x = self.forward_features(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 1314, in forward_features\n    x = self.stem(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 154, in forward\n    out = scale_out + identity_out\n\n```\n## Return values\n<class 'NoneType'>",
      "text":"FX Node: call_function:aten.scalar_tensor.default[name=scalar_tensor_default]. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"FxOnnxInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":393
        }
       }
      },
      {
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py"
        },
        "region":{
         "snippet":{
          "text":"x = self.forward_features(x)"
         },
         "startLine":1333
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0008",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Searching operator overload: 'aten.add.Tensor' in onnx registry...\n\n\n## Additional Message:\n\n## Function Signature\n### Function Signature OnnxFunctionDispatcher.get_function_overloads\n- self: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 64, 200, 200])\n- diagnostic_context: <class 'torch.onnx._internal.fx.diagnostics.DiagnosticContext'>\n## Return values\nList[length=2](\nregistration.ONNXFunction(aten::add.Tensor, is_custom=False, is_complex=False),\nregistration.ONNXFunction(aten::add.Tensor, is_custom=False, is_complex=False),\n)",
      "text":"Searching operator overload: 'aten.add.Tensor' in onnx registry...\n"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"OnnxFunctionDispatcher.get_function_overloads"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/onnxfunction_dispatcher.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":329
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0016",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"FX Node: aten.add.Tensor. \nONNX Node: aten_add[opset=pkg.onnxscript.torch_lib;is_custom=False]. \nONNX Node: aten_logical_or[opset=pkg.onnxscript.torch_lib;is_custom=False]. \n\n\n## Additional Message:\n\n## Function Signature\n### Function Signature OnnxFunctionDispatcher._find_the_perfect_or_nearest_match_onnxfunction\n- self: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 64, 200, 200])\n- default_and_custom_functions: List[length=2](\nregistration.ONNXFunction(aten::add.Tensor, is_custom=False, is_complex=False),\nregistration.ONNXFunction(aten::add.Tensor, is_custom=False, is_complex=False),\n)\n- onnx_args: Tuple[length=2](\n`TorchScriptTensor(f32[1, 64, 200, 200])`,\n`TorchScriptTensor(f32[])`,\n)\n- onnx_kwargs: Dict[length=1](\nalpha: 1,\n)\n- diagnostic_context: <class 'torch.onnx._internal.fx.diagnostics.DiagnosticContext'>\n## Checking perfect match...\n`TracedOnnxFunction(aten_logical_or)`\n### Failed: attribute mismatch!\nActual {'alpha'} vs expected set()\nThe function is not a nearest match candidate.\n## Checking perfect match...\n`TracedOnnxFunction(aten_add)`\n### Failed: attribute 'alpha' type mismatch!\nActual <class 'int'> vs\nExpected AttrType.FLOAT\nmatch score: 1\n### Exact match is not found!\nCannot find a perfect match of symbolic overload, a nearest match is found. Please check the ONNX output carefully. \n\n## Return values\n`TracedOnnxFunction(aten_add)`",
      "text":"FX Node: aten.add.Tensor. \nONNX Node: aten_add[opset=pkg.onnxscript.torch_lib;is_custom=False]. \nONNX Node: aten_logical_or[opset=pkg.onnxscript.torch_lib;is_custom=False]. \n"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"fail",
     "level":"warning",
     "locations":[
      {
       "message":{
        "text":"OnnxFunctionDispatcher._find_the_perfect_or_nearest_match_onnxfunction"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/onnxfunction_dispatcher.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":179
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0014",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"FX Node: call_function:aten.add.Tensor[name=add]. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature FxOnnxInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.fx_onnx_interpreter.FxOnnxInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 64, 200, 200])\n- fx_graph_module: torch.fx.GraphModule(timm_models_fastvit_MobileOneBlock)\n- onnxfunction_dispatcher: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- onnxscript_graph: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptGraph'>\n- onnxscript_tracer: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptTracingEvaluator'>\n- fx_name_to_onnxscript_value: Dict[length=3](\nl_x_: `TorchScriptTensor(f32[1, 3, 400, 400])`,\ngetattr_l__self___stem___0___conv_scale_1: `TorchScriptTensor(f32[1, 64, 200, 200])`,\nscalar_tensor_default: `TorchScriptTensor(f32[])`,\n)\n## PyTorch source information\n```\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 1333, in forward\n    x = self.forward_features(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 1314, in forward_features\n    x = self.stem(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 154, in forward\n    out = scale_out + identity_out\n\n```\n## Return values\n<class 'NoneType'>",
      "text":"FX Node: call_function:aten.add.Tensor[name=add]. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"FxOnnxInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":393
        }
       }
      },
      {
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py"
        },
        "region":{
         "snippet":{
          "text":"x = self.forward_features(x)"
         },
         "startLine":1333
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0008",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"FX Node: placeholder:l_x_[name=l_x_]. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature FxOnnxInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.fx_onnx_interpreter.FxOnnxInterpreter'>\n- node: fx.Node(l_x_)[placeholder]:Tensor(f32[1, 3, 400, 400])\n- fx_graph_module: torch.fx.GraphModule(timm_layers_conv_bn_act_ConvNormAct)\n- onnxfunction_dispatcher: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- onnxscript_graph: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptGraph'>\n- onnxscript_tracer: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptTracingEvaluator'>\n- fx_name_to_onnxscript_value: Dict[length=0](\nNone)\n## Return values\n<class 'NoneType'>",
      "text":"FX Node: placeholder:l_x_[name=l_x_]. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"FxOnnxInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":393
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0008",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"FX Node: placeholder:l_x_[name=l_x_]. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature FxOnnxInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.fx_onnx_interpreter.FxOnnxInterpreter'>\n- node: fx.Node(l_x_)[placeholder]:Tensor(f32[1, 3, 400, 400])\n- fx_graph_module: torch.fx.GraphModule(torch_nn_modules_conv_Conv2d)\n- onnxfunction_dispatcher: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- onnxscript_graph: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptGraph'>\n- onnxscript_tracer: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptTracingEvaluator'>\n- fx_name_to_onnxscript_value: Dict[length=0](\nNone)\n## Return values\n<class 'NoneType'>",
      "text":"FX Node: placeholder:l_x_[name=l_x_]. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"FxOnnxInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":393
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0008",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"FX Node: get_attr:stem/0/conv_kxk/0/conv/weight[name=stem_0_conv_kxk_0_conv_weight]. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature FxOnnxInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.fx_onnx_interpreter.FxOnnxInterpreter'>\n- node: fx.Node(stem/0/conv_kxk/0/conv/weight)[get_attr]:None\n- fx_graph_module: torch.fx.GraphModule(torch_nn_modules_conv_Conv2d)\n- onnxfunction_dispatcher: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- onnxscript_graph: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptGraph'>\n- onnxscript_tracer: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptTracingEvaluator'>\n- fx_name_to_onnxscript_value: Dict[length=1](\nl_x_: `TorchScriptTensor(f32[1, 3, 400, 400])`,\n)\n## PyTorch source information\n```\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 1333, in forward\n    x = self.forward_features(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 1314, in forward_features\n    x = self.stem(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 157, in forward\n    out += rc(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/layers/conv_bn_act.py\", line 83, in forward\n    x = self.conv(x)\n\n```\n## Return values\n<class 'NoneType'>",
      "text":"FX Node: get_attr:stem/0/conv_kxk/0/conv/weight[name=stem_0_conv_kxk_0_conv_weight]. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"FxOnnxInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":393
        }
       }
      },
      {
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py"
        },
        "region":{
         "snippet":{
          "text":"x = self.forward_features(x)"
         },
         "startLine":1333
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0008",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Searching operator overload: 'aten.convolution.default' in onnx registry...\n\n\n## Additional Message:\n\n## Function Signature\n### Function Signature OnnxFunctionDispatcher.get_function_overloads\n- self: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 200, 200])\n- diagnostic_context: <class 'torch.onnx._internal.fx.diagnostics.DiagnosticContext'>\n## Return values\nList[length=1](\nregistration.ONNXFunction(aten::convolution.default, is_custom=False, is_complex=False),\n)",
      "text":"Searching operator overload: 'aten.convolution.default' in onnx registry...\n"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"OnnxFunctionDispatcher.get_function_overloads"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/onnxfunction_dispatcher.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":329
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0016",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"FX Node: aten.convolution.default. \nONNX Node: aten_convolution[opset=pkg.onnxscript.torch_lib;is_custom=False]. \n\n\n## Additional Message:\n\n## Function Signature\n### Function Signature OnnxFunctionDispatcher._find_the_perfect_or_nearest_match_onnxfunction\n- self: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 200, 200])\n- default_and_custom_functions: List[length=1](\nregistration.ONNXFunction(aten::convolution.default, is_custom=False, is_complex=False),\n)\n- onnx_args: Tuple[length=9](\n`TorchScriptTensor(f32[1, 3, 400, 400])`,\n`TorchScriptTensor(f32[64, 3, 3, 3])`,\n<class 'NoneType'>,\nList[length=2](\n2,\n2,\n),\nList[length=2](\n1,\n1,\n),\nList[length=2](\n1,\n1,\n),\nFalse,\nList[length=2](\n0,\n0,\n),\n1,\n)\n- onnx_kwargs: Dict[length=0](\nNone)\n- diagnostic_context: <class 'torch.onnx._internal.fx.diagnostics.DiagnosticContext'>\n## Checking perfect match...\n`TracedOnnxFunction(aten_convolution)`\nmatch score: -2\n## Return values\n`TracedOnnxFunction(aten_convolution)`",
      "text":"FX Node: aten.convolution.default. \nONNX Node: aten_convolution[opset=pkg.onnxscript.torch_lib;is_custom=False]. \n"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"OnnxFunctionDispatcher._find_the_perfect_or_nearest_match_onnxfunction"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/onnxfunction_dispatcher.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":179
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0014",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"FX Node: call_function:aten.convolution.default[name=convolution_1]. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature FxOnnxInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.fx_onnx_interpreter.FxOnnxInterpreter'>\n- node: fx.Node(aten.convolution.default)[call_function]:Tensor(f32[1, 64, 200, 200])\n- fx_graph_module: torch.fx.GraphModule(torch_nn_modules_conv_Conv2d)\n- onnxfunction_dispatcher: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- onnxscript_graph: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptGraph'>\n- onnxscript_tracer: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptTracingEvaluator'>\n- fx_name_to_onnxscript_value: Dict[length=2](\nl_x_: `TorchScriptTensor(f32[1, 3, 400, 400])`,\nstem_0_conv_kxk_0_conv_weight: `TorchScriptTensor(f32[64, 3, 3, 3])`,\n)\n## PyTorch source information\n```\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 1333, in forward\n    x = self.forward_features(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 1314, in forward_features\n    x = self.stem(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 157, in forward\n    out += rc(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/layers/conv_bn_act.py\", line 83, in forward\n    x = self.conv(x)\n\n```\n## Return values\n<class 'NoneType'>",
      "text":"FX Node: call_function:aten.convolution.default[name=convolution_1]. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"FxOnnxInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":393
        }
       }
      },
      {
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py"
        },
        "region":{
         "snippet":{
          "text":"x = self.forward_features(x)"
         },
         "startLine":1333
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0008",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"FX Node: output:output[name=output]. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature FxOnnxInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.fx_onnx_interpreter.FxOnnxInterpreter'>\n- node: fx.Node(output)[output]:None\n- fx_graph_module: torch.fx.GraphModule(torch_nn_modules_conv_Conv2d)\n- onnxfunction_dispatcher: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- onnxscript_graph: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptGraph'>\n- onnxscript_tracer: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptTracingEvaluator'>\n- fx_name_to_onnxscript_value: Dict[length=3](\nl_x_: `TorchScriptTensor(f32[1, 3, 400, 400])`,\nstem_0_conv_kxk_0_conv_weight: `TorchScriptTensor(f32[64, 3, 3, 3])`,\nconvolution_1: `TorchScriptTensor(f32[1, 64, 200, 200])`,\n)\n## Return values\n<class 'NoneType'>",
      "text":"FX Node: output:output[name=output]. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"FxOnnxInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":393
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0008",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"FX Graph: torch_nn_modules_conv_Conv2d. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature FxOnnxInterpreter.run\n- self: <class 'torch.onnx._internal.fx.fx_onnx_interpreter.FxOnnxInterpreter'>\n- fx_graph_module: torch.fx.GraphModule(torch_nn_modules_conv_Conv2d)\n- onnxfunction_dispatcher: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- parent_onnxscript_graph: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptGraph'>\n## Return values\n<class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptGraph'>",
      "text":"FX Graph: torch_nn_modules_conv_Conv2d. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"FxOnnxInterpreter.run"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":468
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0007",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"FX Node: call_module:getattr_L__self___stem___0___conv_kxk_0_conv_1[name=getattr_l__self___stem___0___conv_kxk_0_conv_1]. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature FxOnnxInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.fx_onnx_interpreter.FxOnnxInterpreter'>\n- node: fx.Node(getattr_L__self___stem___0___conv_kxk_0_conv_1)[call_module]:Tensor(f32[1, 64, 200, 200])\n- fx_graph_module: torch.fx.GraphModule(timm_layers_conv_bn_act_ConvNormAct)\n- onnxfunction_dispatcher: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- onnxscript_graph: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptGraph'>\n- onnxscript_tracer: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptTracingEvaluator'>\n- fx_name_to_onnxscript_value: Dict[length=1](\nl_x_: `TorchScriptTensor(f32[1, 3, 400, 400])`,\n)\n## PyTorch source information\n```\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 1333, in forward\n    x = self.forward_features(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 1314, in forward_features\n    x = self.stem(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 157, in forward\n    out += rc(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/layers/conv_bn_act.py\", line 83, in forward\n    x = self.conv(x)\n\n```\n## Return values\n<class 'NoneType'>",
      "text":"FX Node: call_module:getattr_L__self___stem___0___conv_kxk_0_conv_1[name=getattr_l__self___stem___0___conv_kxk_0_conv_1]. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"FxOnnxInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":393
        }
       }
      },
      {
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py"
        },
        "region":{
         "snippet":{
          "text":"x = self.forward_features(x)"
         },
         "startLine":1333
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0008",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"FX Node: placeholder:convolution_1[name=convolution_1]. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature FxOnnxInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.fx_onnx_interpreter.FxOnnxInterpreter'>\n- node: fx.Node(convolution_1)[placeholder]:Tensor(f32[1, 64, 200, 200])\n- fx_graph_module: torch.fx.GraphModule(timm_layers_norm_act_BatchNormAct2d)\n- onnxfunction_dispatcher: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- onnxscript_graph: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptGraph'>\n- onnxscript_tracer: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptTracingEvaluator'>\n- fx_name_to_onnxscript_value: Dict[length=0](\nNone)\n## PyTorch source information\n```\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 1333, in forward\n    x = self.forward_features(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 1314, in forward_features\n    x = self.stem(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 157, in forward\n    out += rc(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/layers/conv_bn_act.py\", line 83, in forward\n    x = self.conv(x)\n\n```\n## Return values\n<class 'NoneType'>",
      "text":"FX Node: placeholder:convolution_1[name=convolution_1]. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"FxOnnxInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":393
        }
       }
      },
      {
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py"
        },
        "region":{
         "snippet":{
          "text":"x = self.forward_features(x)"
         },
         "startLine":1333
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0008",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"FX Node: get_attr:stem/0/conv_kxk/0/bn/weight[name=stem_0_conv_kxk_0_bn_weight]. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature FxOnnxInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.fx_onnx_interpreter.FxOnnxInterpreter'>\n- node: fx.Node(stem/0/conv_kxk/0/bn/weight)[get_attr]:None\n- fx_graph_module: torch.fx.GraphModule(timm_layers_norm_act_BatchNormAct2d)\n- onnxfunction_dispatcher: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- onnxscript_graph: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptGraph'>\n- onnxscript_tracer: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptTracingEvaluator'>\n- fx_name_to_onnxscript_value: Dict[length=1](\nconvolution_1: `TorchScriptTensor(f32[1, 64, 200, 200])`,\n)\n## PyTorch source information\n```\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 1333, in forward\n    x = self.forward_features(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 1314, in forward_features\n    x = self.stem(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 157, in forward\n    out += rc(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/layers/conv_bn_act.py\", line 84, in forward\n    x = self.bn(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/layers/norm_act.py\", line 136, in forward\n    x = F.batch_norm(\n\n```\n## Return values\n<class 'NoneType'>",
      "text":"FX Node: get_attr:stem/0/conv_kxk/0/bn/weight[name=stem_0_conv_kxk_0_bn_weight]. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"FxOnnxInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":393
        }
       }
      },
      {
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py"
        },
        "region":{
         "snippet":{
          "text":"x = self.forward_features(x)"
         },
         "startLine":1333
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0008",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"FX Node: get_attr:stem/0/conv_kxk/0/bn/bias[name=stem_0_conv_kxk_0_bn_bias]. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature FxOnnxInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.fx_onnx_interpreter.FxOnnxInterpreter'>\n- node: fx.Node(stem/0/conv_kxk/0/bn/bias)[get_attr]:None\n- fx_graph_module: torch.fx.GraphModule(timm_layers_norm_act_BatchNormAct2d)\n- onnxfunction_dispatcher: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- onnxscript_graph: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptGraph'>\n- onnxscript_tracer: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptTracingEvaluator'>\n- fx_name_to_onnxscript_value: Dict[length=2](\nconvolution_1: `TorchScriptTensor(f32[1, 64, 200, 200])`,\nstem_0_conv_kxk_0_bn_weight: `TorchScriptTensor(f32[64])`,\n)\n## PyTorch source information\n```\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 1333, in forward\n    x = self.forward_features(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 1314, in forward_features\n    x = self.stem(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 157, in forward\n    out += rc(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/layers/conv_bn_act.py\", line 84, in forward\n    x = self.bn(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/layers/norm_act.py\", line 136, in forward\n    x = F.batch_norm(\n\n```\n## Return values\n<class 'NoneType'>",
      "text":"FX Node: get_attr:stem/0/conv_kxk/0/bn/bias[name=stem_0_conv_kxk_0_bn_bias]. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"FxOnnxInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":393
        }
       }
      },
      {
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py"
        },
        "region":{
         "snippet":{
          "text":"x = self.forward_features(x)"
         },
         "startLine":1333
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0008",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"FX Node: get_attr:stem/0/conv_kxk/0/bn/running_mean[name=stem_0_conv_kxk_0_bn_running_mean]. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature FxOnnxInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.fx_onnx_interpreter.FxOnnxInterpreter'>\n- node: fx.Node(stem/0/conv_kxk/0/bn/running_mean)[get_attr]:None\n- fx_graph_module: torch.fx.GraphModule(timm_layers_norm_act_BatchNormAct2d)\n- onnxfunction_dispatcher: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- onnxscript_graph: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptGraph'>\n- onnxscript_tracer: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptTracingEvaluator'>\n- fx_name_to_onnxscript_value: Dict[length=3](\nconvolution_1: `TorchScriptTensor(f32[1, 64, 200, 200])`,\nstem_0_conv_kxk_0_bn_weight: `TorchScriptTensor(f32[64])`,\nstem_0_conv_kxk_0_bn_bias: `TorchScriptTensor(f32[64])`,\n)\n## PyTorch source information\n```\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 1333, in forward\n    x = self.forward_features(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 1314, in forward_features\n    x = self.stem(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 157, in forward\n    out += rc(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/layers/conv_bn_act.py\", line 84, in forward\n    x = self.bn(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/layers/norm_act.py\", line 136, in forward\n    x = F.batch_norm(\n\n```\n## Return values\n<class 'NoneType'>",
      "text":"FX Node: get_attr:stem/0/conv_kxk/0/bn/running_mean[name=stem_0_conv_kxk_0_bn_running_mean]. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"FxOnnxInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":393
        }
       }
      },
      {
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py"
        },
        "region":{
         "snippet":{
          "text":"x = self.forward_features(x)"
         },
         "startLine":1333
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0008",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"FX Node: get_attr:stem/0/conv_kxk/0/bn/running_var[name=stem_0_conv_kxk_0_bn_running_var]. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature FxOnnxInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.fx_onnx_interpreter.FxOnnxInterpreter'>\n- node: fx.Node(stem/0/conv_kxk/0/bn/running_var)[get_attr]:None\n- fx_graph_module: torch.fx.GraphModule(timm_layers_norm_act_BatchNormAct2d)\n- onnxfunction_dispatcher: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- onnxscript_graph: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptGraph'>\n- onnxscript_tracer: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptTracingEvaluator'>\n- fx_name_to_onnxscript_value: Dict[length=4](\nconvolution_1: `TorchScriptTensor(f32[1, 64, 200, 200])`,\nstem_0_conv_kxk_0_bn_weight: `TorchScriptTensor(f32[64])`,\nstem_0_conv_kxk_0_bn_bias: `TorchScriptTensor(f32[64])`,\nstem_0_conv_kxk_0_bn_running_mean: `TorchScriptTensor(f32[64])`,\n)\n## PyTorch source information\n```\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 1333, in forward\n    x = self.forward_features(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 1314, in forward_features\n    x = self.stem(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 157, in forward\n    out += rc(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/layers/conv_bn_act.py\", line 84, in forward\n    x = self.bn(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/layers/norm_act.py\", line 136, in forward\n    x = F.batch_norm(\n\n```\n## Return values\n<class 'NoneType'>",
      "text":"FX Node: get_attr:stem/0/conv_kxk/0/bn/running_var[name=stem_0_conv_kxk_0_bn_running_var]. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"FxOnnxInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":393
        }
       }
      },
      {
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py"
        },
        "region":{
         "snippet":{
          "text":"x = self.forward_features(x)"
         },
         "startLine":1333
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0008",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Searching operator overload: 'aten._native_batch_norm_legit_no_training.default' in onnx registry...\n\n\n## Additional Message:\n\n## Function Signature\n### Function Signature OnnxFunctionDispatcher.get_function_overloads\n- self: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 200, 200]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n- diagnostic_context: <class 'torch.onnx._internal.fx.diagnostics.DiagnosticContext'>\n## Return values\nList[length=1](\nregistration.ONNXFunction(aten::_native_batch_norm_legit_no_training.default, is_custom=False, is_complex=False),\n)",
      "text":"Searching operator overload: 'aten._native_batch_norm_legit_no_training.default' in onnx registry...\n"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"OnnxFunctionDispatcher.get_function_overloads"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/onnxfunction_dispatcher.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":329
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0016",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"FX Node: aten._native_batch_norm_legit_no_training.default. \nONNX Node: aten__native_batch_norm_no_training[opset=pkg.onnxscript.torch_lib;is_custom=False]. \n\n\n## Additional Message:\n\n## Function Signature\n### Function Signature OnnxFunctionDispatcher._find_the_perfect_or_nearest_match_onnxfunction\n- self: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 200, 200]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n- default_and_custom_functions: List[length=1](\nregistration.ONNXFunction(aten::_native_batch_norm_legit_no_training.default, is_custom=False, is_complex=False),\n)\n- onnx_args: Tuple[length=7](\n`TorchScriptTensor(f32[1, 64, 200, 200])`,\n`TorchScriptTensor(f32[64])`,\n`TorchScriptTensor(f32[64])`,\n`TorchScriptTensor(f32[64])`,\n`TorchScriptTensor(f32[64])`,\n0.1,\n1e-05,\n)\n- onnx_kwargs: Dict[length=0](\nNone)\n- diagnostic_context: <class 'torch.onnx._internal.fx.diagnostics.DiagnosticContext'>\n## Checking perfect match...\n`TracedOnnxFunction(aten__native_batch_norm_no_training)`\nmatch score: 5\n## Return values\n`TracedOnnxFunction(aten__native_batch_norm_no_training)`",
      "text":"FX Node: aten._native_batch_norm_legit_no_training.default. \nONNX Node: aten__native_batch_norm_no_training[opset=pkg.onnxscript.torch_lib;is_custom=False]. \n"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"OnnxFunctionDispatcher._find_the_perfect_or_nearest_match_onnxfunction"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/onnxfunction_dispatcher.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":179
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0014",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"FX Node: call_function:aten._native_batch_norm_legit_no_training.default[name=_native_batch_norm_legit_no_training_1]. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature FxOnnxInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.fx_onnx_interpreter.FxOnnxInterpreter'>\n- node: fx.Node(aten._native_batch_norm_legit_no_training.default)[call_function]:Tuple[length=3](\nTensor(f32[1, 64, 200, 200]),\nTensor(f32[0]),\nTensor(f32[0]),\n)\n- fx_graph_module: torch.fx.GraphModule(timm_layers_norm_act_BatchNormAct2d)\n- onnxfunction_dispatcher: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- onnxscript_graph: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptGraph'>\n- onnxscript_tracer: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptTracingEvaluator'>\n- fx_name_to_onnxscript_value: Dict[length=5](\nconvolution_1: `TorchScriptTensor(f32[1, 64, 200, 200])`,\nstem_0_conv_kxk_0_bn_weight: `TorchScriptTensor(f32[64])`,\nstem_0_conv_kxk_0_bn_bias: `TorchScriptTensor(f32[64])`,\nstem_0_conv_kxk_0_bn_running_mean: `TorchScriptTensor(f32[64])`,\nstem_0_conv_kxk_0_bn_running_var: `TorchScriptTensor(f32[64])`,\n)\n## PyTorch source information\n```\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 1333, in forward\n    x = self.forward_features(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 1314, in forward_features\n    x = self.stem(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 157, in forward\n    out += rc(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/layers/conv_bn_act.py\", line 84, in forward\n    x = self.bn(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/layers/norm_act.py\", line 136, in forward\n    x = F.batch_norm(\n\n```\n## Return values\n<class 'NoneType'>",
      "text":"FX Node: call_function:aten._native_batch_norm_legit_no_training.default[name=_native_batch_norm_legit_no_training_1]. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"FxOnnxInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":393
        }
       }
      },
      {
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py"
        },
        "region":{
         "snippet":{
          "text":"x = self.forward_features(x)"
         },
         "startLine":1333
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0008",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"FX Node: call_function:<built-in function getitem>[name=getitem_3]. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature FxOnnxInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.fx_onnx_interpreter.FxOnnxInterpreter'>\n- node: fx.Node(<built-in function getitem>)[call_function]:Tensor(f32[1, 64, 200, 200])\n- fx_graph_module: torch.fx.GraphModule(timm_layers_norm_act_BatchNormAct2d)\n- onnxfunction_dispatcher: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- onnxscript_graph: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptGraph'>\n- onnxscript_tracer: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptTracingEvaluator'>\n- fx_name_to_onnxscript_value: Dict[length=6](\nconvolution_1: `TorchScriptTensor(f32[1, 64, 200, 200])`,\nstem_0_conv_kxk_0_bn_weight: `TorchScriptTensor(f32[64])`,\nstem_0_conv_kxk_0_bn_bias: `TorchScriptTensor(f32[64])`,\nstem_0_conv_kxk_0_bn_running_mean: `TorchScriptTensor(f32[64])`,\nstem_0_conv_kxk_0_bn_running_var: `TorchScriptTensor(f32[64])`,\n_native_batch_norm_legit_no_training_1: Tuple[length=3](\n`TorchScriptTensor(f32[1, 64, 200, 200])`,\n`TorchScriptTensor(f32[0])`,\n`TorchScriptTensor(f32[0])`,\n),\n)\n## PyTorch source information\n```\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 1333, in forward\n    x = self.forward_features(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 1314, in forward_features\n    x = self.stem(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 157, in forward\n    out += rc(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/layers/conv_bn_act.py\", line 84, in forward\n    x = self.bn(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/layers/norm_act.py\", line 136, in forward\n    x = F.batch_norm(\n\n```\n## Return values\n<class 'NoneType'>",
      "text":"FX Node: call_function:<built-in function getitem>[name=getitem_3]. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"FxOnnxInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":393
        }
       }
      },
      {
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py"
        },
        "region":{
         "snippet":{
          "text":"x = self.forward_features(x)"
         },
         "startLine":1333
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0008",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"FX Node: output:output[name=output]. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature FxOnnxInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.fx_onnx_interpreter.FxOnnxInterpreter'>\n- node: fx.Node(output)[output]:None\n- fx_graph_module: torch.fx.GraphModule(timm_layers_norm_act_BatchNormAct2d)\n- onnxfunction_dispatcher: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- onnxscript_graph: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptGraph'>\n- onnxscript_tracer: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptTracingEvaluator'>\n- fx_name_to_onnxscript_value: Dict[length=7](\nconvolution_1: `TorchScriptTensor(f32[1, 64, 200, 200])`,\nstem_0_conv_kxk_0_bn_weight: `TorchScriptTensor(f32[64])`,\nstem_0_conv_kxk_0_bn_bias: `TorchScriptTensor(f32[64])`,\nstem_0_conv_kxk_0_bn_running_mean: `TorchScriptTensor(f32[64])`,\nstem_0_conv_kxk_0_bn_running_var: `TorchScriptTensor(f32[64])`,\n_native_batch_norm_legit_no_training_1: Tuple[length=3](\n`TorchScriptTensor(f32[1, 64, 200, 200])`,\n`TorchScriptTensor(f32[0])`,\n`TorchScriptTensor(f32[0])`,\n),\ngetitem_3: `TorchScriptTensor(f32[1, 64, 200, 200])`,\n)\n## Return values\n<class 'NoneType'>",
      "text":"FX Node: output:output[name=output]. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"FxOnnxInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":393
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0008",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"FX Graph: timm_layers_norm_act_BatchNormAct2d. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature FxOnnxInterpreter.run\n- self: <class 'torch.onnx._internal.fx.fx_onnx_interpreter.FxOnnxInterpreter'>\n- fx_graph_module: torch.fx.GraphModule(timm_layers_norm_act_BatchNormAct2d)\n- onnxfunction_dispatcher: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- parent_onnxscript_graph: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptGraph'>\n## Return values\n<class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptGraph'>",
      "text":"FX Graph: timm_layers_norm_act_BatchNormAct2d. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"FxOnnxInterpreter.run"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":468
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0007",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"FX Node: call_module:getattr_L__self___stem___0___conv_kxk_0_bn_1[name=getattr_l__self___stem___0___conv_kxk_0_bn_1]. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature FxOnnxInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.fx_onnx_interpreter.FxOnnxInterpreter'>\n- node: fx.Node(getattr_L__self___stem___0___conv_kxk_0_bn_1)[call_module]:Tensor(f32[1, 64, 200, 200])\n- fx_graph_module: torch.fx.GraphModule(timm_layers_conv_bn_act_ConvNormAct)\n- onnxfunction_dispatcher: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- onnxscript_graph: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptGraph'>\n- onnxscript_tracer: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptTracingEvaluator'>\n- fx_name_to_onnxscript_value: Dict[length=2](\nl_x_: `TorchScriptTensor(f32[1, 3, 400, 400])`,\ngetattr_l__self___stem___0___conv_kxk_0_conv_1: `TorchScriptTensor(f32[1, 64, 200, 200])`,\n)\n## PyTorch source information\n```\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 1333, in forward\n    x = self.forward_features(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 1314, in forward_features\n    x = self.stem(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 157, in forward\n    out += rc(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/layers/conv_bn_act.py\", line 84, in forward\n    x = self.bn(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/layers/norm_act.py\", line 136, in forward\n    x = F.batch_norm(\n\n```\n## Return values\n<class 'NoneType'>",
      "text":"FX Node: call_module:getattr_L__self___stem___0___conv_kxk_0_bn_1[name=getattr_l__self___stem___0___conv_kxk_0_bn_1]. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"FxOnnxInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":393
        }
       }
      },
      {
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py"
        },
        "region":{
         "snippet":{
          "text":"x = self.forward_features(x)"
         },
         "startLine":1333
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0008",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"FX Node: output:output[name=output]. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature FxOnnxInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.fx_onnx_interpreter.FxOnnxInterpreter'>\n- node: fx.Node(output)[output]:None\n- fx_graph_module: torch.fx.GraphModule(timm_layers_conv_bn_act_ConvNormAct)\n- onnxfunction_dispatcher: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- onnxscript_graph: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptGraph'>\n- onnxscript_tracer: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptTracingEvaluator'>\n- fx_name_to_onnxscript_value: Dict[length=3](\nl_x_: `TorchScriptTensor(f32[1, 3, 400, 400])`,\ngetattr_l__self___stem___0___conv_kxk_0_conv_1: `TorchScriptTensor(f32[1, 64, 200, 200])`,\ngetattr_l__self___stem___0___conv_kxk_0_bn_1: `TorchScriptTensor(f32[1, 64, 200, 200])`,\n)\n## Return values\n<class 'NoneType'>",
      "text":"FX Node: output:output[name=output]. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"FxOnnxInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":393
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0008",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"FX Graph: timm_layers_conv_bn_act_ConvNormAct. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature FxOnnxInterpreter.run\n- self: <class 'torch.onnx._internal.fx.fx_onnx_interpreter.FxOnnxInterpreter'>\n- fx_graph_module: torch.fx.GraphModule(timm_layers_conv_bn_act_ConvNormAct)\n- onnxfunction_dispatcher: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- parent_onnxscript_graph: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptGraph'>\n## Return values\n<class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptGraph'>",
      "text":"FX Graph: timm_layers_conv_bn_act_ConvNormAct. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"FxOnnxInterpreter.run"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":468
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0007",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"FX Node: call_module:getattr_L__self___stem___0___conv_kxk_0_1[name=getattr_l__self___stem___0___conv_kxk_0_1]. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature FxOnnxInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.fx_onnx_interpreter.FxOnnxInterpreter'>\n- node: fx.Node(getattr_L__self___stem___0___conv_kxk_0_1)[call_module]:Tensor(f32[1, 64, 200, 200])\n- fx_graph_module: torch.fx.GraphModule(timm_models_fastvit_MobileOneBlock)\n- onnxfunction_dispatcher: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- onnxscript_graph: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptGraph'>\n- onnxscript_tracer: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptTracingEvaluator'>\n- fx_name_to_onnxscript_value: Dict[length=4](\nl_x_: `TorchScriptTensor(f32[1, 3, 400, 400])`,\ngetattr_l__self___stem___0___conv_scale_1: `TorchScriptTensor(f32[1, 64, 200, 200])`,\nscalar_tensor_default: `TorchScriptTensor(f32[])`,\nadd: `TorchScriptTensor(f32[1, 64, 200, 200])`,\n)\n## PyTorch source information\n```\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 1333, in forward\n    x = self.forward_features(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 1314, in forward_features\n    x = self.stem(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 157, in forward\n    out += rc(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/layers/conv_bn_act.py\", line 83, in forward\n    x = self.conv(x)\n\n```\n## Return values\n<class 'NoneType'>",
      "text":"FX Node: call_module:getattr_L__self___stem___0___conv_kxk_0_1[name=getattr_l__self___stem___0___conv_kxk_0_1]. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"FxOnnxInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":393
        }
       }
      },
      {
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py"
        },
        "region":{
         "snippet":{
          "text":"x = self.forward_features(x)"
         },
         "startLine":1333
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0008",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Searching operator overload: 'aten.add.Tensor' in onnx registry...\n\n\n## Additional Message:\n\n## Function Signature\n### Function Signature OnnxFunctionDispatcher.get_function_overloads\n- self: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 64, 200, 200])\n- diagnostic_context: <class 'torch.onnx._internal.fx.diagnostics.DiagnosticContext'>\n## Return values\nList[length=2](\nregistration.ONNXFunction(aten::add.Tensor, is_custom=False, is_complex=False),\nregistration.ONNXFunction(aten::add.Tensor, is_custom=False, is_complex=False),\n)",
      "text":"Searching operator overload: 'aten.add.Tensor' in onnx registry...\n"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"OnnxFunctionDispatcher.get_function_overloads"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/onnxfunction_dispatcher.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":329
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0016",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"FX Node: aten.add.Tensor. \nONNX Node: aten_add[opset=pkg.onnxscript.torch_lib;is_custom=False]. \nONNX Node: aten_logical_or[opset=pkg.onnxscript.torch_lib;is_custom=False]. \n\n\n## Additional Message:\n\n## Function Signature\n### Function Signature OnnxFunctionDispatcher._find_the_perfect_or_nearest_match_onnxfunction\n- self: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 64, 200, 200])\n- default_and_custom_functions: List[length=2](\nregistration.ONNXFunction(aten::add.Tensor, is_custom=False, is_complex=False),\nregistration.ONNXFunction(aten::add.Tensor, is_custom=False, is_complex=False),\n)\n- onnx_args: Tuple[length=2](\n`TorchScriptTensor(f32[1, 64, 200, 200])`,\n`TorchScriptTensor(f32[1, 64, 200, 200])`,\n)\n- onnx_kwargs: Dict[length=1](\nalpha: 1,\n)\n- diagnostic_context: <class 'torch.onnx._internal.fx.diagnostics.DiagnosticContext'>\n## Checking perfect match...\n`TracedOnnxFunction(aten_logical_or)`\n### Failed: attribute mismatch!\nActual {'alpha'} vs expected set()\nThe function is not a nearest match candidate.\n## Checking perfect match...\n`TracedOnnxFunction(aten_add)`\n### Failed: attribute 'alpha' type mismatch!\nActual <class 'int'> vs\nExpected AttrType.FLOAT\nmatch score: 1\n### Exact match is not found!\nCannot find a perfect match of symbolic overload, a nearest match is found. Please check the ONNX output carefully. \n\n## Return values\n`TracedOnnxFunction(aten_add)`",
      "text":"FX Node: aten.add.Tensor. \nONNX Node: aten_add[opset=pkg.onnxscript.torch_lib;is_custom=False]. \nONNX Node: aten_logical_or[opset=pkg.onnxscript.torch_lib;is_custom=False]. \n"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"fail",
     "level":"warning",
     "locations":[
      {
       "message":{
        "text":"OnnxFunctionDispatcher._find_the_perfect_or_nearest_match_onnxfunction"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/onnxfunction_dispatcher.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":179
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0014",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"FX Node: call_function:aten.add.Tensor[name=add_1]. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature FxOnnxInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.fx_onnx_interpreter.FxOnnxInterpreter'>\n- node: fx.Node(aten.add.Tensor)[call_function]:Tensor(f32[1, 64, 200, 200])\n- fx_graph_module: torch.fx.GraphModule(timm_models_fastvit_MobileOneBlock)\n- onnxfunction_dispatcher: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- onnxscript_graph: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptGraph'>\n- onnxscript_tracer: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptTracingEvaluator'>\n- fx_name_to_onnxscript_value: Dict[length=5](\nl_x_: `TorchScriptTensor(f32[1, 3, 400, 400])`,\ngetattr_l__self___stem___0___conv_scale_1: `TorchScriptTensor(f32[1, 64, 200, 200])`,\nscalar_tensor_default: `TorchScriptTensor(f32[])`,\nadd: `TorchScriptTensor(f32[1, 64, 200, 200])`,\ngetattr_l__self___stem___0___conv_kxk_0_1: `TorchScriptTensor(f32[1, 64, 200, 200])`,\n)\n## PyTorch source information\n```\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 1333, in forward\n    x = self.forward_features(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 1314, in forward_features\n    x = self.stem(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 157, in forward\n    out += rc(x)\n\n```\n## Return values\n<class 'NoneType'>",
      "text":"FX Node: call_function:aten.add.Tensor[name=add_1]. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"FxOnnxInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":393
        }
       }
      },
      {
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py"
        },
        "region":{
         "snippet":{
          "text":"x = self.forward_features(x)"
         },
         "startLine":1333
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0008",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"FX Node: placeholder:add_1[name=add_1]. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature FxOnnxInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.fx_onnx_interpreter.FxOnnxInterpreter'>\n- node: fx.Node(add_1)[placeholder]:Tensor(f32[1, 64, 200, 200])\n- fx_graph_module: torch.fx.GraphModule(torch_nn_modules_activation_GELU)\n- onnxfunction_dispatcher: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- onnxscript_graph: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptGraph'>\n- onnxscript_tracer: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptTracingEvaluator'>\n- fx_name_to_onnxscript_value: Dict[length=0](\nNone)\n## PyTorch source information\n```\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 1333, in forward\n    x = self.forward_features(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 1314, in forward_features\n    x = self.stem(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 157, in forward\n    out += rc(x)\n\n```\n## Return values\n<class 'NoneType'>",
      "text":"FX Node: placeholder:add_1[name=add_1]. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"FxOnnxInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":393
        }
       }
      },
      {
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py"
        },
        "region":{
         "snippet":{
          "text":"x = self.forward_features(x)"
         },
         "startLine":1333
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0008",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Searching operator overload: 'aten.gelu.default' in onnx registry...\n\n\n## Additional Message:\n\n## Function Signature\n### Function Signature OnnxFunctionDispatcher.get_function_overloads\n- self: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- node: fx.Node(aten.gelu.default)[call_function]:Tensor(f32[1, 64, 200, 200])\n- diagnostic_context: <class 'torch.onnx._internal.fx.diagnostics.DiagnosticContext'>\n## Return values\nList[length=1](\nregistration.ONNXFunction(aten::gelu.default, is_custom=False, is_complex=False),\n)",
      "text":"Searching operator overload: 'aten.gelu.default' in onnx registry...\n"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"OnnxFunctionDispatcher.get_function_overloads"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/onnxfunction_dispatcher.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":329
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0016",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"FX Node: aten.gelu.default. \nONNX Node: aten_gelu[opset=pkg.onnxscript.torch_lib;is_custom=False]. \n\n\n## Additional Message:\n\n## Function Signature\n### Function Signature OnnxFunctionDispatcher._find_the_perfect_or_nearest_match_onnxfunction\n- self: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- node: fx.Node(aten.gelu.default)[call_function]:Tensor(f32[1, 64, 200, 200])\n- default_and_custom_functions: List[length=1](\nregistration.ONNXFunction(aten::gelu.default, is_custom=False, is_complex=False),\n)\n- onnx_args: Tuple[length=1](\n`TorchScriptTensor(f32[1, 64, 200, 200])`,\n)\n- onnx_kwargs: Dict[length=1](\napproximate: none,\n)\n- diagnostic_context: <class 'torch.onnx._internal.fx.diagnostics.DiagnosticContext'>\n## Checking perfect match...\n`TracedOnnxFunction(aten_gelu)`\nmatch score: 1\n## Return values\n`TracedOnnxFunction(aten_gelu)`",
      "text":"FX Node: aten.gelu.default. \nONNX Node: aten_gelu[opset=pkg.onnxscript.torch_lib;is_custom=False]. \n"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"OnnxFunctionDispatcher._find_the_perfect_or_nearest_match_onnxfunction"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/onnxfunction_dispatcher.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":179
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0014",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"FX Node: call_function:aten.gelu.default[name=gelu]. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature FxOnnxInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.fx_onnx_interpreter.FxOnnxInterpreter'>\n- node: fx.Node(aten.gelu.default)[call_function]:Tensor(f32[1, 64, 200, 200])\n- fx_graph_module: torch.fx.GraphModule(torch_nn_modules_activation_GELU)\n- onnxfunction_dispatcher: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- onnxscript_graph: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptGraph'>\n- onnxscript_tracer: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptTracingEvaluator'>\n- fx_name_to_onnxscript_value: Dict[length=1](\nadd_1: `TorchScriptTensor(f32[1, 64, 200, 200])`,\n)\n## PyTorch source information\n```\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 1333, in forward\n    x = self.forward_features(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 1314, in forward_features\n    x = self.stem(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 159, in forward\n    return self.act(self.se(out))\n\n```\n## Exception log\n```\nTraceback (most recent call last):\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 130, in wrapper\n    return_values = fn(*args, **kwargs)\n                    ^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py\", line 445, in run_node\n    self.call_function(\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py\", line 661, in call_function\n    ) = symbolic_fn(*onnx_args, **onnx_kwargs)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/onnxscript/values.py\", line 625, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/onnxscript/function_libs/torch_lib/ops/nn.py\", line 476, in aten_gelu\n    result = _aten_gelu_approximate_none(self)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/onnxscript/function_libs/torch_lib/ops/nn.py\", line 484, in _aten_gelu_approximate_none\n    inner = op.Div(self, ir.tensor(1.4142135623730951, dtype=self.dtype))\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/onnx_ir/_convenience/_constructors.py\", line 103, in tensor\n    raise TypeError(f\"dtype must be an instance of DataType. dtype={dtype}\")\n\nTypeError: dtype must be an instance of DataType. dtype=torch.float32\n\n```",
      "text":"FX Node: call_function:aten.gelu.default[name=gelu]. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"fail",
     "level":"error",
     "locations":[
      {
       "message":{
        "text":"FxOnnxInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":393
        }
       }
      },
      {
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py"
        },
        "region":{
         "snippet":{
          "text":"x = self.forward_features(x)"
         },
         "startLine":1333
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0008",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"FX Graph: torch_nn_modules_activation_GELU. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature FxOnnxInterpreter.run\n- self: <class 'torch.onnx._internal.fx.fx_onnx_interpreter.FxOnnxInterpreter'>\n- fx_graph_module: torch.fx.GraphModule(torch_nn_modules_activation_GELU)\n- onnxfunction_dispatcher: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- parent_onnxscript_graph: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptGraph'>\n## Exception log\n```\nTraceback (most recent call last):\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 130, in wrapper\n    return_values = fn(*args, **kwargs)\n                    ^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py\", line 542, in run\n    self.run_node(\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 146, in wrapper\n    ctx.log_and_raise_if_error(diag)\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/context.py\", line 355, in log_and_raise_if_error\n    raise diagnostic.source_exception\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 130, in wrapper\n    return_values = fn(*args, **kwargs)\n                    ^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py\", line 445, in run_node\n    self.call_function(\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py\", line 661, in call_function\n    ) = symbolic_fn(*onnx_args, **onnx_kwargs)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/onnxscript/values.py\", line 625, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/onnxscript/function_libs/torch_lib/ops/nn.py\", line 476, in aten_gelu\n    result = _aten_gelu_approximate_none(self)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/onnxscript/function_libs/torch_lib/ops/nn.py\", line 484, in _aten_gelu_approximate_none\n    inner = op.Div(self, ir.tensor(1.4142135623730951, dtype=self.dtype))\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/onnx_ir/_convenience/_constructors.py\", line 103, in tensor\n    raise TypeError(f\"dtype must be an instance of DataType. dtype={dtype}\")\n\nTypeError: dtype must be an instance of DataType. dtype=torch.float32\n\n```",
      "text":"FX Graph: torch_nn_modules_activation_GELU. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"fail",
     "level":"error",
     "locations":[
      {
       "message":{
        "text":"FxOnnxInterpreter.run"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":468
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0007",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"FX Node: call_module:getattr_L__self___stem___0___act_1[name=getattr_l__self___stem___0___act_1]. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature FxOnnxInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.fx_onnx_interpreter.FxOnnxInterpreter'>\n- node: fx.Node(getattr_L__self___stem___0___act_1)[call_module]:Tensor(f32[1, 64, 200, 200])\n- fx_graph_module: torch.fx.GraphModule(timm_models_fastvit_MobileOneBlock)\n- onnxfunction_dispatcher: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- onnxscript_graph: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptGraph'>\n- onnxscript_tracer: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptTracingEvaluator'>\n- fx_name_to_onnxscript_value: Dict[length=6](\nl_x_: `TorchScriptTensor(f32[1, 3, 400, 400])`,\ngetattr_l__self___stem___0___conv_scale_1: `TorchScriptTensor(f32[1, 64, 200, 200])`,\nscalar_tensor_default: `TorchScriptTensor(f32[])`,\nadd: `TorchScriptTensor(f32[1, 64, 200, 200])`,\ngetattr_l__self___stem___0___conv_kxk_0_1: `TorchScriptTensor(f32[1, 64, 200, 200])`,\nadd_1: `TorchScriptTensor(f32[1, 64, 200, 200])`,\n)\n## PyTorch source information\n```\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 1333, in forward\n    x = self.forward_features(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 1314, in forward_features\n    x = self.stem(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 159, in forward\n    return self.act(self.se(out))\n\n```\n## Exception log\n```\nTraceback (most recent call last):\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 130, in wrapper\n    return_values = fn(*args, **kwargs)\n                    ^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py\", line 455, in run_node\n    self.call_module(\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py\", line 743, in call_module\n    sub_onnxscript_graph = self.run(\n                           ^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 146, in wrapper\n    ctx.log_and_raise_if_error(diag)\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/context.py\", line 355, in log_and_raise_if_error\n    raise diagnostic.source_exception\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 130, in wrapper\n    return_values = fn(*args, **kwargs)\n                    ^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py\", line 542, in run\n    self.run_node(\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 146, in wrapper\n    ctx.log_and_raise_if_error(diag)\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/context.py\", line 355, in log_and_raise_if_error\n    raise diagnostic.source_exception\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 130, in wrapper\n    return_values = fn(*args, **kwargs)\n                    ^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py\", line 445, in run_node\n    self.call_function(\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py\", line 661, in call_function\n    ) = symbolic_fn(*onnx_args, **onnx_kwargs)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/onnxscript/values.py\", line 625, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/onnxscript/function_libs/torch_lib/ops/nn.py\", line 476, in aten_gelu\n    result = _aten_gelu_approximate_none(self)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/onnxscript/function_libs/torch_lib/ops/nn.py\", line 484, in _aten_gelu_approximate_none\n    inner = op.Div(self, ir.tensor(1.4142135623730951, dtype=self.dtype))\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/onnx_ir/_convenience/_constructors.py\", line 103, in tensor\n    raise TypeError(f\"dtype must be an instance of DataType. dtype={dtype}\")\n\nTypeError: dtype must be an instance of DataType. dtype=torch.float32\n\n```",
      "text":"FX Node: call_module:getattr_L__self___stem___0___act_1[name=getattr_l__self___stem___0___act_1]. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"fail",
     "level":"error",
     "locations":[
      {
       "message":{
        "text":"FxOnnxInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":393
        }
       }
      },
      {
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py"
        },
        "region":{
         "snippet":{
          "text":"x = self.forward_features(x)"
         },
         "startLine":1333
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0008",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"FX Graph: timm_models_fastvit_MobileOneBlock. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature FxOnnxInterpreter.run\n- self: <class 'torch.onnx._internal.fx.fx_onnx_interpreter.FxOnnxInterpreter'>\n- fx_graph_module: torch.fx.GraphModule(timm_models_fastvit_MobileOneBlock)\n- onnxfunction_dispatcher: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- parent_onnxscript_graph: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptGraph'>\n## Exception log\n```\nTraceback (most recent call last):\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 130, in wrapper\n    return_values = fn(*args, **kwargs)\n                    ^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py\", line 542, in run\n    self.run_node(\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 146, in wrapper\n    ctx.log_and_raise_if_error(diag)\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/context.py\", line 355, in log_and_raise_if_error\n    raise diagnostic.source_exception\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 130, in wrapper\n    return_values = fn(*args, **kwargs)\n                    ^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py\", line 455, in run_node\n    self.call_module(\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py\", line 743, in call_module\n    sub_onnxscript_graph = self.run(\n                           ^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 146, in wrapper\n    ctx.log_and_raise_if_error(diag)\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/context.py\", line 355, in log_and_raise_if_error\n    raise diagnostic.source_exception\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 130, in wrapper\n    return_values = fn(*args, **kwargs)\n                    ^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py\", line 542, in run\n    self.run_node(\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 146, in wrapper\n    ctx.log_and_raise_if_error(diag)\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/context.py\", line 355, in log_and_raise_if_error\n    raise diagnostic.source_exception\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 130, in wrapper\n    return_values = fn(*args, **kwargs)\n                    ^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py\", line 445, in run_node\n    self.call_function(\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py\", line 661, in call_function\n    ) = symbolic_fn(*onnx_args, **onnx_kwargs)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/onnxscript/values.py\", line 625, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/onnxscript/function_libs/torch_lib/ops/nn.py\", line 476, in aten_gelu\n    result = _aten_gelu_approximate_none(self)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/onnxscript/function_libs/torch_lib/ops/nn.py\", line 484, in _aten_gelu_approximate_none\n    inner = op.Div(self, ir.tensor(1.4142135623730951, dtype=self.dtype))\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/onnx_ir/_convenience/_constructors.py\", line 103, in tensor\n    raise TypeError(f\"dtype must be an instance of DataType. dtype={dtype}\")\n\nTypeError: dtype must be an instance of DataType. dtype=torch.float32\n\n```",
      "text":"FX Graph: timm_models_fastvit_MobileOneBlock. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"fail",
     "level":"error",
     "locations":[
      {
       "message":{
        "text":"FxOnnxInterpreter.run"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":468
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0007",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"FX Node: call_module:stem_0_1[name=stem_0_1]. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature FxOnnxInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.fx_onnx_interpreter.FxOnnxInterpreter'>\n- node: fx.Node(stem_0_1)[call_module]:Tensor(f32[1, 64, 200, 200])\n- fx_graph_module: torch.fx.GraphModule(torch_nn_modules_container_Sequential)\n- onnxfunction_dispatcher: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- onnxscript_graph: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptGraph'>\n- onnxscript_tracer: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptTracingEvaluator'>\n- fx_name_to_onnxscript_value: Dict[length=1](\nl_x_: `TorchScriptTensor(f32[1, 3, 400, 400])`,\n)\n## PyTorch source information\n```\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 1333, in forward\n    x = self.forward_features(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 1314, in forward_features\n    x = self.stem(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 151, in forward\n    scale_out = self.conv_scale(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/layers/conv_bn_act.py\", line 83, in forward\n    x = self.conv(x)\n\n```\n## Exception log\n```\nTraceback (most recent call last):\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 130, in wrapper\n    return_values = fn(*args, **kwargs)\n                    ^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py\", line 455, in run_node\n    self.call_module(\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py\", line 743, in call_module\n    sub_onnxscript_graph = self.run(\n                           ^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 146, in wrapper\n    ctx.log_and_raise_if_error(diag)\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/context.py\", line 355, in log_and_raise_if_error\n    raise diagnostic.source_exception\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 130, in wrapper\n    return_values = fn(*args, **kwargs)\n                    ^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py\", line 542, in run\n    self.run_node(\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 146, in wrapper\n    ctx.log_and_raise_if_error(diag)\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/context.py\", line 355, in log_and_raise_if_error\n    raise diagnostic.source_exception\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 130, in wrapper\n    return_values = fn(*args, **kwargs)\n                    ^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py\", line 455, in run_node\n    self.call_module(\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py\", line 743, in call_module\n    sub_onnxscript_graph = self.run(\n                           ^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 146, in wrapper\n    ctx.log_and_raise_if_error(diag)\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/context.py\", line 355, in log_and_raise_if_error\n    raise diagnostic.source_exception\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 130, in wrapper\n    return_values = fn(*args, **kwargs)\n                    ^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py\", line 542, in run\n    self.run_node(\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 146, in wrapper\n    ctx.log_and_raise_if_error(diag)\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/context.py\", line 355, in log_and_raise_if_error\n    raise diagnostic.source_exception\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 130, in wrapper\n    return_values = fn(*args, **kwargs)\n                    ^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py\", line 445, in run_node\n    self.call_function(\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py\", line 661, in call_function\n    ) = symbolic_fn(*onnx_args, **onnx_kwargs)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/onnxscript/values.py\", line 625, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/onnxscript/function_libs/torch_lib/ops/nn.py\", line 476, in aten_gelu\n    result = _aten_gelu_approximate_none(self)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/onnxscript/function_libs/torch_lib/ops/nn.py\", line 484, in _aten_gelu_approximate_none\n    inner = op.Div(self, ir.tensor(1.4142135623730951, dtype=self.dtype))\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/onnx_ir/_convenience/_constructors.py\", line 103, in tensor\n    raise TypeError(f\"dtype must be an instance of DataType. dtype={dtype}\")\n\nTypeError: dtype must be an instance of DataType. dtype=torch.float32\n\n```",
      "text":"FX Node: call_module:stem_0_1[name=stem_0_1]. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"fail",
     "level":"error",
     "locations":[
      {
       "message":{
        "text":"FxOnnxInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":393
        }
       }
      },
      {
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py"
        },
        "region":{
         "snippet":{
          "text":"x = self.forward_features(x)"
         },
         "startLine":1333
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0008",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"FX Graph: torch_nn_modules_container_Sequential. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature FxOnnxInterpreter.run\n- self: <class 'torch.onnx._internal.fx.fx_onnx_interpreter.FxOnnxInterpreter'>\n- fx_graph_module: torch.fx.GraphModule(torch_nn_modules_container_Sequential)\n- onnxfunction_dispatcher: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- parent_onnxscript_graph: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptGraph'>\n## Exception log\n```\nTraceback (most recent call last):\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 130, in wrapper\n    return_values = fn(*args, **kwargs)\n                    ^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py\", line 542, in run\n    self.run_node(\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 146, in wrapper\n    ctx.log_and_raise_if_error(diag)\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/context.py\", line 355, in log_and_raise_if_error\n    raise diagnostic.source_exception\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 130, in wrapper\n    return_values = fn(*args, **kwargs)\n                    ^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py\", line 455, in run_node\n    self.call_module(\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py\", line 743, in call_module\n    sub_onnxscript_graph = self.run(\n                           ^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 146, in wrapper\n    ctx.log_and_raise_if_error(diag)\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/context.py\", line 355, in log_and_raise_if_error\n    raise diagnostic.source_exception\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 130, in wrapper\n    return_values = fn(*args, **kwargs)\n                    ^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py\", line 542, in run\n    self.run_node(\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 146, in wrapper\n    ctx.log_and_raise_if_error(diag)\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/context.py\", line 355, in log_and_raise_if_error\n    raise diagnostic.source_exception\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 130, in wrapper\n    return_values = fn(*args, **kwargs)\n                    ^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py\", line 455, in run_node\n    self.call_module(\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py\", line 743, in call_module\n    sub_onnxscript_graph = self.run(\n                           ^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 146, in wrapper\n    ctx.log_and_raise_if_error(diag)\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/context.py\", line 355, in log_and_raise_if_error\n    raise diagnostic.source_exception\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 130, in wrapper\n    return_values = fn(*args, **kwargs)\n                    ^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py\", line 542, in run\n    self.run_node(\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 146, in wrapper\n    ctx.log_and_raise_if_error(diag)\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/context.py\", line 355, in log_and_raise_if_error\n    raise diagnostic.source_exception\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 130, in wrapper\n    return_values = fn(*args, **kwargs)\n                    ^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py\", line 445, in run_node\n    self.call_function(\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py\", line 661, in call_function\n    ) = symbolic_fn(*onnx_args, **onnx_kwargs)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/onnxscript/values.py\", line 625, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/onnxscript/function_libs/torch_lib/ops/nn.py\", line 476, in aten_gelu\n    result = _aten_gelu_approximate_none(self)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/onnxscript/function_libs/torch_lib/ops/nn.py\", line 484, in _aten_gelu_approximate_none\n    inner = op.Div(self, ir.tensor(1.4142135623730951, dtype=self.dtype))\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/onnx_ir/_convenience/_constructors.py\", line 103, in tensor\n    raise TypeError(f\"dtype must be an instance of DataType. dtype={dtype}\")\n\nTypeError: dtype must be an instance of DataType. dtype=torch.float32\n\n```",
      "text":"FX Graph: torch_nn_modules_container_Sequential. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"fail",
     "level":"error",
     "locations":[
      {
       "message":{
        "text":"FxOnnxInterpreter.run"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":468
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0007",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"FX Node: call_module:stem_1[name=stem_1]. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature FxOnnxInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.fx_onnx_interpreter.FxOnnxInterpreter'>\n- node: fx.Node(stem_1)[call_module]:Tensor(f32[1, 64, 100, 100])\n- fx_graph_module: torch.fx.GraphModule()\n- onnxfunction_dispatcher: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n- onnxscript_graph: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptGraph'>\n- onnxscript_tracer: <class 'onnxscript.function_libs.torch_lib.graph_building._graph_building_torch.TorchScriptTracingEvaluator'>\n- fx_name_to_onnxscript_value: Dict[length=1](\nl_x_: `TorchScriptTensor(f32[1, 3, 400, 400])`,\n)\n## PyTorch source information\n```\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 1333, in forward\n    x = self.forward_features(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 1314, in forward_features\n    x = self.stem(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py\", line 151, in forward\n    scale_out = self.conv_scale(x)\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/layers/conv_bn_act.py\", line 83, in forward\n    x = self.conv(x)\n\n```\n## Exception log\n```\nTraceback (most recent call last):\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 130, in wrapper\n    return_values = fn(*args, **kwargs)\n                    ^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py\", line 455, in run_node\n    self.call_module(\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py\", line 743, in call_module\n    sub_onnxscript_graph = self.run(\n                           ^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 146, in wrapper\n    ctx.log_and_raise_if_error(diag)\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/context.py\", line 355, in log_and_raise_if_error\n    raise diagnostic.source_exception\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 130, in wrapper\n    return_values = fn(*args, **kwargs)\n                    ^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py\", line 542, in run\n    self.run_node(\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 146, in wrapper\n    ctx.log_and_raise_if_error(diag)\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/context.py\", line 355, in log_and_raise_if_error\n    raise diagnostic.source_exception\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 130, in wrapper\n    return_values = fn(*args, **kwargs)\n                    ^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py\", line 455, in run_node\n    self.call_module(\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py\", line 743, in call_module\n    sub_onnxscript_graph = self.run(\n                           ^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 146, in wrapper\n    ctx.log_and_raise_if_error(diag)\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/context.py\", line 355, in log_and_raise_if_error\n    raise diagnostic.source_exception\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 130, in wrapper\n    return_values = fn(*args, **kwargs)\n                    ^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py\", line 542, in run\n    self.run_node(\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 146, in wrapper\n    ctx.log_and_raise_if_error(diag)\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/context.py\", line 355, in log_and_raise_if_error\n    raise diagnostic.source_exception\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 130, in wrapper\n    return_values = fn(*args, **kwargs)\n                    ^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py\", line 455, in run_node\n    self.call_module(\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py\", line 743, in call_module\n    sub_onnxscript_graph = self.run(\n                           ^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 146, in wrapper\n    ctx.log_and_raise_if_error(diag)\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/context.py\", line 355, in log_and_raise_if_error\n    raise diagnostic.source_exception\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 130, in wrapper\n    return_values = fn(*args, **kwargs)\n                    ^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py\", line 542, in run\n    self.run_node(\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 146, in wrapper\n    ctx.log_and_raise_if_error(diag)\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/context.py\", line 355, in log_and_raise_if_error\n    raise diagnostic.source_exception\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 130, in wrapper\n    return_values = fn(*args, **kwargs)\n                    ^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py\", line 445, in run_node\n    self.call_function(\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py\", line 661, in call_function\n    ) = symbolic_fn(*onnx_args, **onnx_kwargs)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/onnxscript/values.py\", line 625, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/onnxscript/function_libs/torch_lib/ops/nn.py\", line 476, in aten_gelu\n    result = _aten_gelu_approximate_none(self)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/onnxscript/function_libs/torch_lib/ops/nn.py\", line 484, in _aten_gelu_approximate_none\n    inner = op.Div(self, ir.tensor(1.4142135623730951, dtype=self.dtype))\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/onnx_ir/_convenience/_constructors.py\", line 103, in tensor\n    raise TypeError(f\"dtype must be an instance of DataType. dtype={dtype}\")\n\nTypeError: dtype must be an instance of DataType. dtype=torch.float32\n\n```",
      "text":"FX Node: call_module:stem_1[name=stem_1]. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"fail",
     "level":"error",
     "locations":[
      {
       "message":{
        "text":"FxOnnxInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":393
        }
       }
      },
      {
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/timm/models/fastvit.py"
        },
        "region":{
         "snippet":{
          "text":"x = self.forward_features(x)"
         },
         "startLine":1333
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0008",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"FX Graph: . \n\n## Additional Message:\n\n## Function Signature\n### Function Signature FxOnnxInterpreter.run\n- self: <class 'torch.onnx._internal.fx.fx_onnx_interpreter.FxOnnxInterpreter'>\n- fx_graph_module: torch.fx.GraphModule()\n- onnxfunction_dispatcher: <class 'torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher'>\n## Exception log\n```\nTraceback (most recent call last):\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 130, in wrapper\n    return_values = fn(*args, **kwargs)\n                    ^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py\", line 542, in run\n    self.run_node(\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 146, in wrapper\n    ctx.log_and_raise_if_error(diag)\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/context.py\", line 355, in log_and_raise_if_error\n    raise diagnostic.source_exception\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 130, in wrapper\n    return_values = fn(*args, **kwargs)\n                    ^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py\", line 455, in run_node\n    self.call_module(\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py\", line 743, in call_module\n    sub_onnxscript_graph = self.run(\n                           ^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 146, in wrapper\n    ctx.log_and_raise_if_error(diag)\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/context.py\", line 355, in log_and_raise_if_error\n    raise diagnostic.source_exception\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 130, in wrapper\n    return_values = fn(*args, **kwargs)\n                    ^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py\", line 542, in run\n    self.run_node(\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 146, in wrapper\n    ctx.log_and_raise_if_error(diag)\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/context.py\", line 355, in log_and_raise_if_error\n    raise diagnostic.source_exception\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 130, in wrapper\n    return_values = fn(*args, **kwargs)\n                    ^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py\", line 455, in run_node\n    self.call_module(\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py\", line 743, in call_module\n    sub_onnxscript_graph = self.run(\n                           ^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 146, in wrapper\n    ctx.log_and_raise_if_error(diag)\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/context.py\", line 355, in log_and_raise_if_error\n    raise diagnostic.source_exception\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 130, in wrapper\n    return_values = fn(*args, **kwargs)\n                    ^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py\", line 542, in run\n    self.run_node(\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 146, in wrapper\n    ctx.log_and_raise_if_error(diag)\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/context.py\", line 355, in log_and_raise_if_error\n    raise diagnostic.source_exception\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 130, in wrapper\n    return_values = fn(*args, **kwargs)\n                    ^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py\", line 455, in run_node\n    self.call_module(\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py\", line 743, in call_module\n    sub_onnxscript_graph = self.run(\n                           ^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 146, in wrapper\n    ctx.log_and_raise_if_error(diag)\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/context.py\", line 355, in log_and_raise_if_error\n    raise diagnostic.source_exception\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 130, in wrapper\n    return_values = fn(*args, **kwargs)\n                    ^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py\", line 542, in run\n    self.run_node(\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 146, in wrapper\n    ctx.log_and_raise_if_error(diag)\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/context.py\", line 355, in log_and_raise_if_error\n    raise diagnostic.source_exception\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 130, in wrapper\n    return_values = fn(*args, **kwargs)\n                    ^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py\", line 445, in run_node\n    self.call_function(\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py\", line 661, in call_function\n    ) = symbolic_fn(*onnx_args, **onnx_kwargs)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/onnxscript/values.py\", line 625, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/onnxscript/function_libs/torch_lib/ops/nn.py\", line 476, in aten_gelu\n    result = _aten_gelu_approximate_none(self)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/onnxscript/function_libs/torch_lib/ops/nn.py\", line 484, in _aten_gelu_approximate_none\n    inner = op.Div(self, ir.tensor(1.4142135623730951, dtype=self.dtype))\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/onnx_ir/_convenience/_constructors.py\", line 103, in tensor\n    raise TypeError(f\"dtype must be an instance of DataType. dtype={dtype}\")\n\nTypeError: dtype must be an instance of DataType. dtype=torch.float32\n\n```",
      "text":"FX Graph: . "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"fail",
     "level":"error",
     "locations":[
      {
       "message":{
        "text":"FxOnnxInterpreter.run"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/cineai/ViduSdk/python/vs_env/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":468
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0007",
     "stacks":[]
    }
   ]
  }
 ],
 "version":"2.1.0",
 "schemaUri":"https://docs.oasis-open.org/sarif/sarif/v2.1.0/cs01/schemas/sarif-schema-2.1.0.json"
}